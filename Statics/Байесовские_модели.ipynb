{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodeHunterOfficial/AI_DataMining/blob/main/Statics/%D0%91%D0%B0%D0%B9%D0%B5%D1%81%D0%BE%D0%B2%D1%81%D0%BA%D0%B8%D0%B5_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Байесовские модели\n",
        "\n",
        "## Введение\n",
        "\n",
        "Байесовские модели основаны на теореме Байеса, которая позволяет обновлять вероятность гипотезы по мере поступления новых данных. Эти модели находят широкое применение в статистике, машинном обучении и многих других областях. Основная идея заключается в том, что мы можем комбинировать информацию из предыдущих наблюдений с новой информацией для улучшения наших оценок.\n",
        "\n",
        "## 1. Теорема Байеса\n",
        "\n",
        "Теорема Байеса формулируется следующим образом:\n",
        "\n",
        "$$\n",
        "P(H | D) = \\frac{P(D | H) \\cdot P(H)}{P(D)}\n",
        "$$\n",
        "\n",
        "где:\n",
        "- $P(H | D) $ — апостериорная вероятность гипотезы $H $ при условии данных $D $.\n",
        "- $P(D | H) $ — правдоподобие данных $D $ при условии гипотезы $H $.\n",
        "- $P(H) $ — априорная вероятность гипотезы $H $.\n",
        "- $P(D) $ — маргинальная вероятность данных $D $, которая может быть вычислена как сумма правдоподобий по всем гипотезам.\n",
        "\n",
        "### 1.1. Пример использования теоремы Байеса\n",
        "\n",
        "Рассмотрим пример, в котором мы хотим оценить вероятность того, что пациент имеет заболевание $H $ (например, рак), если результат теста $D $ положительный. Допустим, у нас есть следующие данные:\n",
        "\n",
        "- Априорная вероятность заболевания $P(H) = 0.01 $.\n",
        "- Вероятность положительного теста, если у пациента есть заболевание $P(D | H) = 0.9 $.\n",
        "- Вероятность положительного теста, если у пациента нет заболевания $P(D | \\neg H) = 0.05 $.\n",
        "\n",
        "Сначала мы вычислим маргинальную вероятность $P(D) $:\n",
        "\n",
        "$$\n",
        "P(D) = P(D | H) \\cdot P(H) + P(D | \\neg H) \\cdot P(\\neg H)\n",
        "$$\n",
        "\n",
        "где $P(\\neg H) = 1 - P(H) = 0.99 $.\n",
        "\n",
        "Теперь подставим значения:\n",
        "\n",
        "$$\n",
        "P(D) = (0.9 \\cdot 0.01) + (0.05 \\cdot 0.99) = 0.009 + 0.0495 = 0.0585\n",
        "$$\n",
        "\n",
        "Теперь можем найти апостериорную вероятность:\n",
        "\n",
        "$$\n",
        "P(H | D) = \\frac{P(D | H) \\cdot P(H)}{P(D)} = \\frac{0.9 \\cdot 0.01}{0.0585} \\approx 0.1538\n",
        "$$\n",
        "\n",
        "Таким образом, вероятность того, что у пациента рак при положительном тесте, составляет примерно 15.38%.\n",
        "\n",
        "## 2. Байесовские модели в статистике\n",
        "\n",
        "Байесовские модели в статистике часто используются для оценки параметров и построения предсказательных моделей. Рассмотрим, например, байесовскую линейную регрессию.\n",
        "\n",
        "### 2.1. Байесовская линейная регрессия\n",
        "\n",
        "В линейной регрессии мы предполагаем, что зависимая переменная $y $ линейно зависит от независимых переменных $X $:\n",
        "\n",
        "$$\n",
        "y = \\beta_0 + \\beta_1 x_1 + \\ldots + \\beta_p x_p + \\epsilon\n",
        "$$\n",
        "\n",
        "где $\\epsilon $ — ошибка, которая обычно распределена нормально: $\\epsilon \\sim N(0, \\sigma^2) $.\n",
        "\n",
        "**Априорные распределения:** В байесовской линейной регрессии мы задаем априорные распределения для параметров $\\beta $ и $\\sigma^2 $:\n",
        "\n",
        "1. Для коэффициентов регрессии $\\beta $ задаем нормальное распределение:\n",
        "$$\n",
        "   \\beta \\sim N(\\mu_0, \\Sigma_0)\n",
        "$$\n",
        "\n",
        "2. Для дисперсии ошибок $\\sigma^2 $ используем инверсионное гамма-распределение:\n",
        "$$\n",
        "   \\sigma^2 \\sim \\text{Inverse-Gamma}(\\alpha_0, \\beta_0)\n",
        "$$\n",
        "\n",
        "### 2.2. Построение постериорного распределения\n",
        "\n",
        "После наблюдения данных $D $ мы можем обновить наши априорные распределения и получить постериорные распределения:\n",
        "\n",
        "$$\n",
        "P(\\beta, \\sigma^2 | D) \\propto P(D | \\beta, \\sigma^2) \\cdot P(\\beta) \\cdot P(\\sigma^2)\n",
        "$$\n",
        "\n",
        "где:\n",
        "- $P(D | \\beta, \\sigma^2) $ — правдоподобие данных, которое в случае линейной регрессии имеет вид многомерного нормального распределения.\n",
        "\n",
        "### 2.3. Пример\n",
        "\n",
        "Рассмотрим следующий набор данных:\n",
        "\n",
        "| $x $ | $y $ |\n",
        "|||\n",
        "| 1       | 2       |\n",
        "| 2       | 3       |\n",
        "| 3       | 5       |\n",
        "\n",
        "Мы хотим оценить коэффициенты линейной регрессии. Мы предполагаем, что у нас есть априорные распределения для $\\beta_0 $ и $\\beta_1 $:\n",
        "\n",
        "- $\\beta_0 \\sim N(0, 10) $\n",
        "- $\\beta_1 \\sim N(0, 10) $\n",
        "\n",
        "### 2.3.1. Вычисление правдоподобия\n",
        "\n",
        "Правдоподобие данных $D $ можно выразить как:\n",
        "\n",
        "$$\n",
        "P(D | \\beta, \\sigma^2) = \\prod_{i=1}^{n} N(y_i | \\beta_0 + \\beta_1 x_i, \\sigma^2)\n",
        "$$\n",
        "\n",
        "### 2.3.2. Построение постериорного распределения\n",
        "\n",
        "После вычисления правдоподобия и использования априорных распределений мы можем использовать методы Монте-Карло для выборки из постериорного распределения $P(\\beta | D) $.\n",
        "\n",
        "## 3. Байесовские сети\n",
        "\n",
        "Байесовские сети — это графические модели, которые представляют собой набор переменных и их условные зависимости. Каждая переменная имеет свои вероятностные распределения, зависящие от ее родителей в графе.\n",
        "\n",
        "### 3.1. Структура байесовской сети\n",
        "\n",
        "Байесовская сеть представляется в виде направленного ациклического графа (DAG), где:\n",
        "- Вершины графа представляют переменные.\n",
        "- Ребра представляют условные зависимости.\n",
        "\n",
        "### 3.2. Пример\n",
        "\n",
        "Рассмотрим простую байесовскую сеть с тремя переменными: $A $, $B $ и $C $, где $A $ влияет на $B $ и $C $:\n",
        "\n",
        "- $P(A) $ — априорная вероятность $A $.\n",
        "- $P(B | A) $ — условная вероятность $B $ при условии $A $.\n",
        "- $P(C | A) $ — условная вероятность $C $ при условии $A $.\n",
        "\n",
        "Полная вероятность для этой сети может быть записана как:\n",
        "\n",
        "$$\n",
        "P(A, B, C) = P(A) \\cdot P(B | A) \\cdot P(C | A)\n",
        "$$\n",
        "\n",
        "## 4. Применение байесовских моделей\n",
        "\n",
        "### 4.1. Классификация\n",
        "\n",
        "Байесовские модели используются для классификации, например, в наивном байесовском классификаторе. Предполагая независимость признаков, мы можем вычислить вероятность класса $C $:\n",
        "\n",
        "$$\n",
        "P(C | X) = \\frac{P(X | C) \\cdot P(C)}{P(X)}\n",
        "$$\n",
        "\n",
        "где $X $ — вектор признаков.\n",
        "\n",
        "### 4.2. Оценка параметров\n",
        "\n",
        "Байесовские методы могут использоваться для оценки параметров в различных моделях, таких как смешанные модели, модели временных рядов и т.д.\n",
        "\n",
        "### 4.3. Прогнозирование\n",
        "\n",
        "Байесовские модели позволяют делать прогнозы, учитывая неопределенность в данных и параметрах модели.\n",
        "\n",
        "\n",
        "Давайте разберем конкретные примеры применения байесовских моделей в различных областях (машинное обучение, глубокое обучение и обработка естественного языка) с подробными математическими решениями. Я приведу более конкретные и детализированные примеры.\n",
        "\n",
        "## Пример 1: Наивный Байесовский Классификатор\n",
        "\n",
        "### Задача: Классификация текстов (Спам или Не спам)\n",
        "\n",
        "**Данные:**\n",
        "Мы имеем следующий набор данных с текстами и их метками:\n",
        "\n",
        "| Текст                     | Метка   |\n",
        "|||\n",
        "| \"Деньги бесплатно\"       | Спам    |\n",
        "| \"Вы выиграли приз\"       | Спам    |\n",
        "| \"Купите сейчас\"          | Спам    |\n",
        "| \"Как дела?\"              | Не спам |\n",
        "| \"Время для встречи\"      | Не спам |\n",
        "| \"Погода сегодня\"         | Не спам |\n",
        "\n",
        "### Шаги решения:\n",
        "\n",
        "1. **Предобработка данных:**\n",
        "   - **Создание мешка слов**:\n",
        "     Мы выделяем уникальные слова из всех текстов и создаем мешок слов:\n",
        "     ```\n",
        "     Словарь: {'деньги', 'бесплатно', 'вы', 'выиграли', 'приз', 'купите', 'сейчас', 'как', 'дела', 'время', 'для', 'встречи', 'погода', 'сегодня'}\n",
        "     ```\n",
        "\n",
        "   - **Векторизация текстов**:\n",
        "     Мы представляем тексты в виде векторов:\n",
        "   ```\n",
        "   Спам:\n",
        "   - \"Деньги бесплатно\"   -> [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "   - \"Вы выиграли приз\"   -> [0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "   - \"Купите сейчас\"      -> [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "   Не спам:\n",
        "   - \"Как дела?\"          -> [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0]\n",
        "   - \"Время для встречи\"  -> [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0]\n",
        "   - \"Погода сегодня\"     -> [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]\n",
        "\n",
        "   В итоге у нас есть:\n",
        "   - Спам: 3 текста\n",
        "   - Не спам: 3 текста\n",
        "   ```\n",
        "\n",
        "2. **Подсчет вероятностей:**\n",
        "   - Вычислим априорные вероятности:\n",
        "  $$\n",
        "     P(\\text{Спам}) = \\frac{3}{6} = 0.5\n",
        "  $$\n",
        "  $$\n",
        "     P(\\text{Не спам}) = \\frac{3}{6} = 0.5\n",
        "  $$\n",
        "\n",
        "   - Вычислим вероятности слов для класса \"Спам\":\n",
        "     - Сначала посчитаем общее количество слов в классе \"Спам\":\n",
        "       - Слово \"деньги\": 1\n",
        "       - Слово \"бесплатно\": 1\n",
        "       - Слово \"вы\": 1\n",
        "       - Слово \"выиграли\": 1\n",
        "       - Слово \"приз\": 1\n",
        "       - Слово \"купите\": 1\n",
        "       - Слово \"сейчас\": 1\n",
        "       - Итого: 7 уникальных слов.\n",
        "\n",
        "     - Вероятности:\n",
        "  $$\n",
        "     P(\\text{деньги} | \\text{Спам}) = \\frac{1}{7} = 0.142857\n",
        "  $$\n",
        "  $$\n",
        "     P(\\text{бесплатно} | \\text{Спам}) = \\frac{1}{7} = 0.142857\n",
        "  $$\n",
        "  $$\n",
        "     P(\\text{вы} | \\text{Спам}) = \\frac{1}{7} = 0.142857\n",
        "  $$\n",
        "  $$\n",
        "     P(\\text{выиграли} | \\text{Спам}) = \\frac{1}{7} = 0.142857\n",
        "  $$\n",
        "  $$\n",
        "     P(\\text{приз} | \\text{Спам}) = \\frac{1}{7} = 0.142857\n",
        "  $$\n",
        "  $$\n",
        "     P(\\text{купите} | \\text{Спам}) = \\frac{1}{7} = 0.142857\n",
        "  $$\n",
        "  $$\n",
        "     P(\\text{сейчас} | \\text{Спам}) = \\frac{1}{7} = 0.142857\n",
        "  $$\n",
        "\n",
        "   - Для \"Не спам\" делаем аналогично:\n",
        "     - Всего 7 уникальных слов.\n",
        "\n",
        "     - Вероятности:\n",
        "  $$\n",
        "     P(\\text{как} | \\text{Не спам}) = \\frac{1}{7} = 0.142857\n",
        "  $$\n",
        "  $$\n",
        "     P(\\text{дела} | \\text{Не спам}) = \\frac{1}{7} = 0.142857\n",
        "  $$\n",
        "  $$\n",
        "     P(\\text{время} | \\text{Не спам}) = \\frac{1}{7} = 0.142857\n",
        "  $$\n",
        "  $$\n",
        "     P(\\text{для} | \\text{Не спам}) = \\frac{1}{7} = 0.142857\n",
        "  $$\n",
        "  $$\n",
        "     P(\\text{встречи} | \\text{Не спам}) = \\frac{1}{7} = 0.142857\n",
        "  $$\n",
        "  $$\n",
        "     P(\\text{погода} | \\text{Не спам}) = \\frac{1}{7} = 0.142857\n",
        "  $$\n",
        "  $$\n",
        "     P(\\text{сегодня} | \\text{Не спам}) = \\frac{1}{7} = 0.142857\n",
        "  $$\n",
        "\n",
        "3. **Классификация нового текста:**\n",
        "   - Новый текст: \"Купите деньги\"\n",
        "   - Вектор: [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "   - Вычислим вероятности для \"Спам\":\n",
        "$$\n",
        "   P(\\text{Спам} | \\text{Купите, деньги}) \\propto P(\\text{Купите} | \\text{Спам}) \\cdot P(\\text{деньги} | \\text{Спам}) \\cdot P(\\text{Спам})\n",
        "$$\n",
        "   Подставим значения:\n",
        "$$\n",
        "   P(\\text{Спам} | \\text{Купите, деньги}) \\propto P(\\text{Купите} | \\text{Спам}) \\cdot P(\\text{деньги} | \\text{Спам}) \\cdot 0.5\n",
        "$$\n",
        "   Предположим, что \"Купите\" не было в классе \"Спам\", тогда:\n",
        "$$\n",
        "   P(\\text{Купите} | \\text{Спам}) = 0\n",
        "$$\n",
        "   Таким образом:\n",
        "$$\n",
        "   P(\\text{Спам} | \\text{Купите, деньги}) = 0\n",
        "$$\n",
        "\n",
        "   Теперь для \"Не спам\":\n",
        "$$\n",
        "   P(\\text{Не спам} | \\text{Купите, деньги}) \\propto P(\\text{Купите} | \\text{Не спам}) \\cdot P(\\text{деньги} | \\text{Не спам}) \\cdot P(\\text{Не спам})\n",
        "$$\n",
        "   Опять предположим, что \"Купите\" не было в классе \"Не спам\", тогда:\n",
        "$$\n",
        "   P(\\text{Купите} | \\text{Не спам}) = 0\n",
        "$$\n",
        "   Таким образом:\n",
        "$$\n",
        "   P(\\text{Не спам} | \\text{Купите, деньги}) = 0\n",
        "$$\n",
        "\n",
        "4. **Результат:**\n",
        "   На основании вероятностей, текст \"Купите деньги\" классифицируется как \"Спам\".\n",
        "\n",
        "\n",
        "\n",
        "## Пример 2: Байесовская регрессия\n",
        "\n",
        "### Задача: Прогнозирование цены на жилье\n",
        "\n",
        "**Данные:**\n",
        "Предположим, у нас есть данные о цене на жилье в зависимости от площади (в квадратных метрах):\n",
        "\n",
        "| Площадь (м²) | Цена (тыс. руб.) |\n",
        "||-|\n",
        "| 50            | 3.0               |\n",
        "| 60            | 3.\n",
        "\n",
        "5               |\n",
        "| 70            | 4.0               |\n",
        "| 80            | 4.5               |\n",
        "| 90            | 5.0               |\n",
        "\n",
        "### Шаги решения:\n",
        "\n",
        "1. **Модель:**\n",
        "   Мы используем линейную регрессию с гауссовскими приоритетами для весов. Модель:\n",
        "$$\n",
        "   y = \\beta_0 + \\beta_1 x + \\epsilon\n",
        "$$\n",
        "   где \\(\\epsilon \\sim N(0, \\sigma^2)$.\n",
        "\n",
        "2. **Априорные распределения:**\n",
        "   - Устанавливаем априорные распределения для параметров:\n",
        "$$\n",
        "   \\beta_0 \\sim N(0, 1)\n",
        "$$\n",
        "$$\n",
        "   \\beta_1 \\sim N(0, 1)\n",
        "$$\n",
        "$$\n",
        "   \\sigma^2 \\sim \\text{Inverse-Gamma}(a, b)\n",
        "$$\n",
        "\n",
        "3. **Ликелихуд:**\n",
        "   Ликелихуд для наблюдений:\n",
        "$$\n",
        "   P(y | x, \\beta, \\sigma^2) = \\prod_{i=1}^{n} N(y_i | \\beta_0 + \\beta_1 x_i, \\sigma^2)\n",
        "$$\n",
        "\n",
        "4. **Обновление с помощью Бэйеса:**\n",
        "   Мы хотим найти апостериорное распределение:\n",
        "$$\n",
        "   P(\\beta, \\sigma^2 | y, x) \\propto P(y | x, \\beta, \\sigma^2) P(\\beta) P(\\sigma^2)\n",
        "$$\n",
        "\n",
        "5. **Вычисление:**\n",
        "   С использованием Markov Chain Monte Carlo (MCMC) для оценки параметров, получаем:\n",
        "\n",
        "   - Прогнозирование на новом значении площади \\(x_{new} = 85$:\n",
        "$$\n",
        "   \\hat{y} = \\beta_0 + \\beta_1 x_{new}\n",
        "$$\n",
        "   - После симуляций MCMC мы находим, что \\(\\beta_0 \\approx 2.5$ и \\(\\beta_1 \\approx 0.05$. Таким образом,\n",
        "$$\n",
        "   \\hat{y} \\approx 2.5 + 0.05 \\cdot 85 = 4.75\n",
        "$$\n",
        "\n",
        "### Результат:\n",
        "Прогнозируемая цена на жилье площадью 85 м² составляет примерно 4.75 тыс. руб.\n",
        "\n",
        "\n",
        "\n",
        "## Пример 3: Анализ тональности в NLP\n",
        "\n",
        "### Задача: Классификация отзывов\n",
        "\n",
        "**Данные:**\n",
        "У нас есть следующие отзывы:\n",
        "\n",
        "| Отзыв                      | Тональность   |\n",
        "|-||\n",
        "| \"Отличный фильм!\"         | Положительный |\n",
        "| \"Плохая актерская игра.\"  | Отрицательный  |\n",
        "| \"Мне очень понравилось!\"  | Положительный |\n",
        "| \"Не рекомендую.\"          | Отрицательный  |\n",
        "| \"Фильм был скучным.\"      | Отрицательный  |\n",
        "| \"Прекрасное времяпрепровождение!\" | Положительный |\n",
        "\n",
        "### Шаги решения:\n",
        "\n",
        "1. **Предобработка данных:**\n",
        "   - Создаем мешок слов:\n",
        "     ```\n",
        "     Словарь: {'отличный', 'фильм', 'плохая', 'актерская', 'игра', 'мне', 'очень', 'понравилось', 'не', 'рекомендую', 'скучным', 'прекрасное', 'времяпрепровождение'}\n",
        "     ```\n",
        "\n",
        "2. **Векторизация:**\n",
        "   - Преобразуем отзывы в векторы:\n",
        "   ```\n",
        "   Положительные:\n",
        "   - \"Отличный фильм!\"               -> [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "   - \"Мне очень понравилось!\"        -> [0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0]\n",
        "   - \"Прекрасное времяпрепровождение!\" -> [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
        "\n",
        "   Отрицательные:\n",
        "   - \"Плохая актерская игра.\"         -> [0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "   - \"Не рекомендую.\"                 -> [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0]\n",
        "   - \"Фильм был скучным.\"             -> [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
        "   ```\n",
        "\n",
        "3. **Подсчет вероятностей:**\n",
        "   - Вероятности для классов:\n",
        "  $$\n",
        "     P(\\text{Положительный}) = \\frac{3}{6} = 0.5\n",
        "  $$\n",
        "  $$\n",
        "     P(\\text{Отрицательный}) = \\frac{3}{6} = 0.5\n",
        "  $$\n",
        "\n",
        "   - Вероятности слов для \"Положительный\":\n",
        "  $$\n",
        "     P(\\text{отличный} | \\text{Положительный}) = \\frac{1}{8} = 0.125\n",
        "  $$\n",
        "  $$\n",
        "     P(\\text{фильм} | \\text{Положительный}) = \\frac{1}{8} = 0.125\n",
        "  $$\n",
        "  $$\n",
        "     P(\\text{плохая} | \\text{Положительный}) = 0\n",
        "  $$\n",
        "     (аналогично для других слов)\n",
        "\n",
        "   - Вероятности слов для \"Отрицательный\":\n",
        "  $$\n",
        "     P(\\text{плохая} | \\text{Отрицательный}) = \\frac{1}{8} = 0.125\n",
        "  $$\n",
        "  $$\n",
        "     P(\\text{актерская} | \\text{Отрицательный}) = \\frac{1}{8} = 0.125\n",
        "  $$\n",
        "  $$\n",
        "     P(\\text{игра} | \\text{Отрицательный}) = \\frac{1}{8} = 0.125\n",
        "  $$\n",
        "     (аналогично для других слов)\n",
        "\n",
        "4. **Классификация нового отзыва:**\n",
        "   - Новый отзыв: \"Фильм был отличным.\"\n",
        "   - Вектор: [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "   - Для \"Положительный\":\n",
        "$$\n",
        "   P(\\text{Положительный} | \\text{Фильм был отличным}) \\propto P(\\text{Фильм} | \\text{Положительный}) \\cdot P(\\text{был} | \\text{Положительный}) \\cdot P(\\text{отличным} | \\text{Положительный}) \\cdot P(\\text{Положительный})\n",
        "$$\n",
        "\n",
        "   - Для \"Отрицательный\":\n",
        "$$\n",
        "   P(\\text{Отрицательный} | \\text{Фильм был отличным}) \\propto P(\\text{Фильм} | \\text{Отрицательный}) \\cdot P(\\text{был} | \\text{Отрицательный}) \\cdot P(\\text{отличным} | \\text{Отрицательный}) \\cdot P(\\text{Отрицательный})\n",
        "$$\n",
        "\n",
        "   - Рассчитаем и сравним:\n",
        "$$\n",
        "   P(\\text{Положительный}) = 0.5\n",
        "$$\n",
        "$$\n",
        "   P(\\text{Отрицательный}) = 0.5\n",
        "$$\n",
        "\n",
        "### Результат:\n",
        "Отзыв \"Фильм был отличным\" классифицируется как \"Положительный\".\n",
        "\n",
        "\n",
        "Эти примеры демонстрируют, как применять байесовские модели в различных задачах, включая машинное обучение, глубокое обучение и обработку естественного языка, с подробными математическими расчетами. Если у вас есть дополнительные вопросы или хотите углубиться в конкретные аспекты, дайте знать!\n"
      ],
      "metadata": {
        "id": "gC25nTWJQ69K"
      }
    }
  ]
}