{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVqSbImAQtJgoJVmdIVe6Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodeHunterOfficial/AI_DataMining/blob/main/%D0%98%D0%B5%D1%80%D0%B0%D1%80%D1%85%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F_%D0%BA%D0%BB%D0%B0%D1%81%D1%82%D0%B5%D1%80%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Иерархическая кластеризация\n",
        "\n",
        "## Введение\n",
        "\n",
        "Иерархическая кластеризация является одним из наиболее популярных методов группировки данных, позволяющим формировать иерархические структуры. Этот метод полезен в ситуациях, когда требуется понять, как разные объекты связаны друг с другом, и визуализировать эти связи в виде дерева (дендрограммы). Иерархическая кластеризация делится на два основных типа: агломеративную и делительную.\n",
        "\n",
        "### Применение\n",
        "\n",
        "Иерархическая кластеризация применяется в различных областях, включая:\n",
        "\n",
        "- **Биология**: для классификации организмов на основе их генетических данных.\n",
        "- **Социология**: для группировки людей по схожим характеристикам.\n",
        "- **Маркетинг**: для сегментации клиентов на основе покупательских привычек.\n",
        "- **Обработка изображений**: для выявления паттернов и объектов в визуальных данных.\n",
        "\n",
        "## Основные понятия\n",
        "\n",
        "### Кластеризация\n",
        "\n",
        "Кластеризация — это процесс разделения набора данных на группы (кластеры) таким образом, чтобы объекты внутри одной группы были более похожи друг на друга, чем объекты в других группах. Кластеризация помогает в понимании структуры данных, а также в нахождении закономерностей.\n",
        "\n",
        "### Иерархическая структура\n",
        "\n",
        "Иерархическая структура — это способ организации данных в виде дерева, где каждый уровень отражает различные группы и подгруппы объектов. В этой структуре можно визуализировать, как объекты связаны между собой.\n",
        "\n",
        "## Алгоритмы иерархической кластеризации\n",
        "\n",
        "### 1. Агломеративная кластеризация\n",
        "\n",
        "Агломеративная кластеризация — это метод, начинающийся с того, что каждый объект представляет собой отдельный кластер. Затем кластеры последовательно объединяются на основе заданного критерия схожести.\n",
        "\n",
        "#### Шаги агломеративной кластеризации\n",
        "\n",
        "1. **Инициализация**: Каждое наблюдение (объект) рассматривается как отдельный кластер.\n",
        "\n",
        "2. **Определение расстояния между кластерами**: Для вычисления расстояния между кластерами можно использовать различные метрики, такие как:\n",
        "\n",
        "   - **Метрика минимального расстояния (single-linkage)**:\n",
        "     $$\n",
        "     d(A, B) = \\min_{a \\in A, b \\in B} d(a, b)\n",
        "     $$\n",
        "   - **Метрика максимального расстояния (complete-linkage)**:\n",
        "     $$\n",
        "     d(A, B) = \\max_{a \\in A, b \\in B} d(a, b)\n",
        "     $$\n",
        "   - **Метрика среднего расстояния (average-linkage)**:\n",
        "     $$\n",
        "     d(A, B) = \\frac{1}{|A||B|} \\sum_{a \\in A} \\sum_{b \\in B} d(a, b)\n",
        "     $$\n",
        "\n",
        "3. **Объединение кластеров**: На каждом шаге алгоритма объединяются два кластера с наименьшим расстоянием между ними.\n",
        "\n",
        "4. **Обновление матрицы расстояний**: После объединения кластеров необходимо пересчитать расстояния между новыми кластерами и остальными кластерами.\n",
        "\n",
        "5. **Повторение**: Процесс продолжается до тех пор, пока не останется один кластер, который содержит все объекты.\n",
        "\n",
        "### 2. Делительная кластеризация\n",
        "\n",
        "В отличие от агломеративной кластеризации, делительная кластеризация начинается с одного кластера, который включает все объекты, и затем этот кластер последовательно делится на подгруппы.\n",
        "\n",
        "#### Шаги делительной кластеризации\n",
        "\n",
        "1. **Начальное разделение**: Все объекты находятся в одном кластере.\n",
        "\n",
        "2. **Выбор кластера для деления**: Выбирается кластер, который необходимо разделить. На этом этапе обычно используется метрика, подобная k-средним, для нахождения центра кластера.\n",
        "\n",
        "3. **Разделение кластера**: Объекты переносятся в новые кластеры в зависимости от их расстояния до центров.\n",
        "\n",
        "4. **Обновление кластеров**: Обновляются кластеры на основе расстояний, и процесс повторяется, пока не будет достигнуто заданное количество кластеров или пока не произойдут значительные изменения в кластерах.\n",
        "\n",
        "## Математические формулы\n",
        "\n",
        "### Расстояние между объектами\n",
        "\n",
        "Для расчета расстояния между двумя объектами часто используют метрику Евклида:\n",
        "\n",
        "$$\n",
        "d(x, y) = \\sqrt{\\sum_{i=1}^{n} (x_i - y_i)^2}\n",
        "$$\n",
        "\n",
        "где $x$ и $y$ — это векторы объектов, а $n$ — количество признаков.\n",
        "\n",
        "### Метрики оценки качества кластеризации\n",
        "\n",
        "Для оценки качества кластеризации используются различные метрики:\n",
        "\n",
        "1. **Силуэтный коэффициент (Silhouette Coefficient)**:\n",
        "\n",
        "   Силуэтный коэффициент измеряет, насколько близки объекты внутри одного кластера и насколько они удалены от объектов других кластеров. Коэффициент варьируется от -1 до 1, где значения близкие к 1 указывают на хорошее разделение кластеров.\n",
        "\n",
        "   $$\n",
        "   S(i) = \\frac{b(i) - a(i)}{\\max(a(i), b(i))}\n",
        "   $$\n",
        "\n",
        "   где:\n",
        "   - $ a(i) $ — среднее расстояние от точки $ i $ до всех остальных точек в том же кластере.\n",
        "   - $ b(i) $ — минимальное среднее расстояние от точки $ i $ до всех точек в ближайшем кластере.\n",
        "\n",
        "2. **Коэффициент Дэвиса-Боулдина (Davies-Bouldin Index)**:\n",
        "\n",
        "   Коэффициент Дэвиса-Боулдина измеряет степень схожести между кластерами. Чем меньше значение, тем лучше качество кластеризации.\n",
        "\n",
        "   $$\n",
        "   DB = \\frac{1}{n} \\sum_{i=1}^{n} \\max_{j \\neq i} \\left( \\frac{s_i + s_j}{d_{ij}} \\right)\n",
        "   $$\n",
        "\n",
        "   где:\n",
        "   - $ s_i $ — среднее расстояние между точками в кластере $ i $.\n",
        "   - $ d_{ij} $ — расстояние между центрами кластеров $ i $ и $ j $.\n",
        "\n",
        "3. **Коэффициент Ханна-Лейса (Hammond-Leisa Index)**:\n",
        "\n",
        "   Коэффициент Ханна-Лейса используется для оценки качества кластеризации в соответствии с реальными классами, если такие имеются. Он вычисляется как отношение числа правильно классифицированных объектов к общему количеству объектов.\n",
        "\n",
        "## Визуализация результатов кластеризации\n",
        "\n",
        "Для визуализации результатов иерархической кластеризации обычно используются следующие методы:\n",
        "\n",
        "1. **Графики рассеяния (scatter plots)**: Позволяют визуализировать, как объекты распределяются по кластерам.\n",
        "\n",
        "2. **Дендрограммы**: Показывают иерархическую структуру кластеров, наглядно демонстрируя, как объекты объединяются на разных уровнях расстояний.\n",
        "\n",
        "### Пример визуализации дендрограммы\n",
        "\n",
        "Для построения дендрограммы обычно используется алгоритм связки, например, метод Уорда (Ward's method), который минимизирует сумму квадратов расстояний между кластерами.\n",
        "\n",
        "### Заключение\n",
        "\n",
        "Иерархическая кластеризация является мощным инструментом анализа данных, позволяющим глубже понять структуру данных и находить скрытые закономерности. Она универсальна и может применяться в самых разных областях, от биологии до социологии.\n",
        "\n",
        "Используя различные метрики для оценки качества кластеризации и методы визуализации, вы можете более точно понять, насколько хорошо работает ваш алгоритм кластеризации и насколько информативны полученные результаты.\n",
        "\n",
        "\n",
        "Объединяем все кластеры в один:\n",
        "\n",
        "$$\n",
        "\\{A, B, C, D, E\\}\n",
        "$$\n",
        "\n",
        "### Результат\n",
        "\n",
        "Теперь у нас есть окончательный кластер: $\\{A, B, C, D, E\\}$. Дерево, которое мы получили, можно визуализировать как дендрограмму.\n",
        "\n",
        "### Заключение\n",
        "\n",
        "Итак, мы выполнили шаги агломеративной иерархической кластеризации с использованием небольшого набора данных и рассчитали все расстояния между кластерами. Теперь у нас есть единый кластер, в который входят все точки, а также информация о том, как эти точки были объединены на каждом шаге.\n"
      ],
      "metadata": {
        "id": "orvOhmRtAmzG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Давайте реализуем шаги агломеративной иерархической кластеризации на Python. Сначала мы сделаем это без использования готовых библиотек, а затем воспользуемся библиотеками для визуализации.\n",
        "\n",
        "### 1. Реализация без готовых библиотек"
      ],
      "metadata": {
        "id": "xQJOcl1OAtfe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def euclidean_distance(point1, point2):\n",
        "    \"\"\"Вычисление евклидова расстояния между двумя точками\"\"\"\n",
        "    return np.sqrt(np.sum((point1 - point2) ** 2))\n",
        "\n",
        "def find_closest_clusters(distances):\n",
        "    \"\"\"Находит индексы ближайших кластеров и их расстояние\"\"\"\n",
        "    min_dist = np.inf\n",
        "    clusters = (-1, -1)\n",
        "    for i in range(len(distances)):\n",
        "        for j in range(i + 1, len(distances)):\n",
        "            if distances[i, j] < min_dist:\n",
        "                min_dist = distances[i, j]\n",
        "                clusters = (i, j)\n",
        "    return clusters, min_dist\n",
        "\n",
        "def agglomerative_clustering(points):\n",
        "    \"\"\"Агломеративная иерархическая кластеризация\"\"\"\n",
        "    n = len(points)\n",
        "    # Начальная матрица расстояний\n",
        "    distances = np.zeros((n, n))\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            distances[i, j] = euclidean_distance(points[i], points[j])\n",
        "\n",
        "    clusters = [[i] for i in range(n)]  # Инициализация кластеров\n",
        "    dendrogram = []  # Список для хранения дендрограммы\n",
        "\n",
        "    while len(clusters) > 1:\n",
        "        # Находим ближайшие кластеры\n",
        "        (i, j), min_dist = find_closest_clusters(distances)\n",
        "\n",
        "        # Объединяем кластеры\n",
        "        new_cluster = clusters[i] + clusters[j]\n",
        "        dendrogram.append((clusters[i], clusters[j], min_dist))\n",
        "\n",
        "        # Обновляем кластеры\n",
        "        clusters.append(new_cluster)\n",
        "        del clusters[max(i, j)]  # Удаляем старые кластеры\n",
        "\n",
        "        # Пересчитываем расстояния\n",
        "        new_distances = np.zeros((len(clusters), len(clusters)))\n",
        "        for a in range(len(clusters)):\n",
        "            for b in range(a + 1, len(clusters)):\n",
        "                if a == len(clusters) - 1 or b == len(clusters) - 1:  # новый кластер\n",
        "                    # Используем метод single-linkage\n",
        "                    min_distance = np.inf\n",
        "                    for point_a in clusters[a]:\n",
        "                        for point_b in clusters[b]:\n",
        "                            distance = euclidean_distance(points[point_a], points[point_b])\n",
        "                            min_distance = min(min_distance, distance)\n",
        "                    new_distances[a, b] = new_distances[b, a] = min_distance\n",
        "                else:\n",
        "                    new_distances[a, b] = distances[a, b]\n",
        "\n",
        "        distances = new_distances\n",
        "\n",
        "    return clusters[0], dendrogram\n",
        "\n",
        "def plot_dendrogram(dendrogram):\n",
        "    \"\"\"Построение дендрограммы\"\"\"\n",
        "    plt.figure(figsize=(10, 5))\n",
        "\n",
        "    for i, (cluster1, cluster2, dist) in enumerate(dendrogram):\n",
        "        # Расположение кластера\n",
        "        x1 = len(cluster1) + i\n",
        "        x2 = len(cluster2) + i\n",
        "        plt.plot([x1, x2], [dist, dist], color='black')\n",
        "        plt.text((x1 + x2) / 2, dist, str(len(cluster1) + len(cluster2)),\n",
        "                 horizontalalignment='center', verticalalignment='bottom')\n",
        "\n",
        "        # Отображение кластера\n",
        "        for j in cluster1:\n",
        "            plt.text(j, 0, str(j), horizontalalignment='center')\n",
        "        for j in cluster2:\n",
        "            plt.text(j, 0, str(j), horizontalalignment='center')\n",
        "\n",
        "    plt.title('Дендрограмма')\n",
        "    plt.ylabel('Расстояние')\n",
        "    plt.xlabel('Кластеры')\n",
        "    plt.show()\n",
        "\n",
        "def calculate_within_cluster_distance(points, cluster):\n",
        "    \"\"\"Вычисление внутрикластерного расстояния\"\"\"\n",
        "    cluster_points = points[cluster]\n",
        "    distances = [euclidean_distance(p1, p2) for p1 in cluster_points for p2 in cluster_points if not np.array_equal(p1, p2)]\n",
        "    return np.mean(distances)\n",
        "\n",
        "def silhouette_score(points, labels):\n",
        "    \"\"\"Вычисление Silhouette Score\"\"\"\n",
        "    unique_labels = np.unique(labels)\n",
        "    s = 0.0\n",
        "\n",
        "    for label in unique_labels:\n",
        "        cluster_points = points[labels == label]\n",
        "        if len(cluster_points) == 1:\n",
        "            continue\n",
        "\n",
        "        a = calculate_within_cluster_distance(points, cluster_points)\n",
        "\n",
        "        b = np.inf\n",
        "        for other_label in unique_labels:\n",
        "            if other_label != label:\n",
        "                other_cluster_points = points[labels == other_label]\n",
        "                if len(other_cluster_points) > 0:\n",
        "                    dist_to_other = np.mean([euclidean_distance(p, other_p) for p in cluster_points for other_p in other_cluster_points])\n",
        "                    b = min(b, dist_to_other)\n",
        "\n",
        "        s += (b - a) / max(a, b)\n",
        "\n",
        "    return s / len(unique_labels)\n",
        "\n",
        "# Данные\n",
        "points = np.array([\n",
        "    [1, 2],\n",
        "    [2, 3],\n",
        "    [5, 5],\n",
        "    [6, 8],\n",
        "    [8, 8]\n",
        "])\n",
        "\n",
        "# Выполнение кластеризации\n",
        "final_clusters, dendrogram = agglomerative_clustering(points)\n",
        "\n",
        "# Визуализация дендрограммы\n",
        "plot_dendrogram(dendrogram)\n",
        "\n",
        "# Метрики\n",
        "# Определение меток кластеров\n",
        "labels = np.zeros(len(points), dtype=int)\n",
        "for i, cluster in enumerate(final_clusters):\n",
        "    for idx in cluster:\n",
        "        labels[idx] = i\n",
        "\n",
        "# Внутрикластерное расстояние\n",
        "within_cluster_distances = [calculate_within_cluster_distance(points, cluster) for cluster in final_clusters]\n",
        "print(\"Внутрикластерное расстояние:\", within_cluster_distances)\n",
        "\n",
        "# Silhouette Score\n",
        "silhouette = silhouette_score(points, labels)\n",
        "print(\"Silhouette Score:\", silhouette)"
      ],
      "metadata": {
        "id": "bErV5GgYAxmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Реализация с использованием готовых библиотек\n",
        "Теперь давайте использовать библиотеку scipy, которая уже имеет встроенные функции для выполнения агломеративной иерархической кластеризации и построения дендрограммы."
      ],
      "metadata": {
        "id": "MhfEYgqpAxxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Данные\n",
        "points = np.array([\n",
        "    [1, 2],\n",
        "    [2, 3],\n",
        "    [5, 5],\n",
        "    [6, 8],\n",
        "    [8, 8]\n",
        "])\n",
        "\n",
        "# Выполнение агломеративной кластеризации\n",
        "Z = linkage(points, method='single')\n",
        "\n",
        "# Построение дендрограммы\n",
        "plt.figure(figsize=(10, 5))\n",
        "dendrogram(Z)\n",
        "plt.title('Дендрограмма')\n",
        "plt.xlabel('Объекты')\n",
        "plt.ylabel('Расстояние')\n",
        "plt.show()\n",
        "\n",
        "# Определение меток кластеров\n",
        "from scipy.cluster.hierarchy import fcluster\n",
        "\n",
        "# Обозначим количество кластеров, например, 2\n",
        "labels = fcluster(Z, 2, criterion='maxclust')\n",
        "\n",
        "# Внутрикластерное расстояние\n",
        "within_cluster_distances = []\n",
        "for label in np.unique(labels):\n",
        "    cluster_points = points[labels == label]\n",
        "    distances = np.mean([euclidean_distance(p1, p2) for p1 in cluster_points for p2 in cluster_points if not np.array_equal(p1, p2)])\n",
        "    within_cluster_distances.append(distances)\n",
        "\n",
        "print(\"Внутрикластерное расстояние:\", within_cluster_distances)\n",
        "\n",
        "# Silhouette Score\n",
        "silhouette = silhouette_score(points, labels)\n",
        "print(\"Silhouette Score:\", silhouette)"
      ],
      "metadata": {
        "id": "ArUqqbqSA5pN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}