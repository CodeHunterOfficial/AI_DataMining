{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3XiqHFs5WifMZ8km40SxM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodeHunterOfficial/AI_DataMining/blob/main/%D0%9C%D0%B0%D1%80%D0%BA%D0%BE%D0%B2%D1%81%D0%BA%D0%B8%D0%B5_%D1%86%D0%B5%D0%BF%D0%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Марковские цепи\n",
        "\n",
        "#### Введение в марковские цепи\n",
        "\n",
        "Марковская цепь — это математическая модель, которая описывает систему, переходящую из одного состояния в другое. Основная идея марковских цепей заключается в том, что вероятность перехода из одного состояния в другое зависит только от текущего состояния, а не от предшествующих событий. Это свойство называется **свойством Маркова**, или **без памяти**.\n",
        "\n",
        "Формально марковская цепь — это последовательность случайных величин $X_0, X_1, X_2, \\ldots$, где $X_n$ обозначает состояние системы в момент времени $n$. Состояния могут быть дискретными или непрерывными, однако в данной лекции мы будем рассматривать дискретные марковские цепи.\n",
        "\n",
        "#### Основные определения\n",
        "\n",
        "1. **Пространство состояний** $S$ — это множество всех возможных состояний системы. Например, если система может находиться в трёх состояниях, то $S = \\{s_1, s_2, s_3\\}$.\n",
        "\n",
        "2. **Матрица переходных вероятностей** $P$ — это квадратная матрица, в которой каждый элемент $p_{ij}$ представляет собой вероятность перехода из состояния $s_i$ в состояние $s_j$. То есть:\n",
        "   $$\n",
        "   p_{ij} = P(X_{n+1} = s_j \\mid X_n = s_i).\n",
        "   $$\n",
        "   Причём для каждой строки матрицы выполняется условие нормировки:\n",
        "   $$\n",
        "   \\sum_{j} p_{ij} = 1, \\quad \\forall i.\n",
        "   $$\n",
        "\n",
        "3. **Начальное распределение** $\\pi$ — это вектор, который описывает вероятности нахождения системы в каждом из состояний в начальный момент времени. Пусть $\\pi_i = P(X_0 = s_i)$, тогда начальное распределение имеет вид:\n",
        "   $$\n",
        "   \\pi = (\\pi_1, \\pi_2, \\ldots, \\pi_n),\n",
        "   $$\n",
        "   где $\\sum_i \\pi_i = 1$.\n",
        "\n",
        "#### Основные свойства марковских цепей\n",
        "\n",
        "1. **Однородность**: Марковская цепь называется однородной, если вероятности перехода не зависят от времени, то есть $P(X_{n+1} = s_j \\mid X_n = s_i)$ одинаково для всех $n$.\n",
        "\n",
        "2. **Поглощающие состояния**: Состояние $s_i$ называется поглощающим, если из него невозможно выйти, то есть $p_{ii} = 1$ и $p_{ij} = 0$ для всех $j \\neq i$.\n",
        "\n",
        "3. **Классы эквивалентности и коммуникация**: Состояние $s_i$ сообщается с состоянием $s_j$, если существует вероятность попасть из $s_i$ в $s_j$ и наоборот.\n",
        "\n",
        "#### Пример построения марковской цепи\n",
        "\n",
        "Рассмотрим простую задачу: система может находиться в одном из трёх состояний $A$, $B$ или $C$. Пусть матрица переходных вероятностей задана как:\n",
        "\n",
        "$$\n",
        "P = \\begin{bmatrix}\n",
        "0.5 & 0.3 & 0.2 \\\\\n",
        "0.2 & 0.7 & 0.1 \\\\\n",
        "0.4 & 0.4 & 0.2 \\\\\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "Здесь вероятность перехода из состояния $A$ в состояние $A$ равна 0.5, из состояния $A$ в состояние $B$ — 0.3, а из состояния $A$ в состояние $C$ — 0.2. Аналогично читаются остальные элементы матрицы.\n",
        "\n",
        "#### Расчёт распределения вероятностей через $n$ шагов\n",
        "\n",
        "Для того чтобы найти вероятность того, что система будет находиться в определённом состоянии через $n$ шагов, нужно умножить начальное распределение на матрицу переходных вероятностей, возведённую в степень $n$:\n",
        "\n",
        "$$\n",
        "\\pi^{(n)} = \\pi P^n,\n",
        "$$\n",
        "\n",
        "где $\\pi^{(n)}$ — вектор вероятностей нахождения в каждом состоянии через $n$ шагов.\n",
        "\n",
        "#### Стационарное распределение\n",
        "\n",
        "Рассмотрим стационарное распределение, при котором система остаётся в одном и том же распределении вероятностей после каждого шага. Это означает, что:\n",
        "\n",
        "$$\n",
        "\\pi = \\pi P.\n",
        "$$\n",
        "\n",
        "Для нахождения стационарного распределения необходимо решить систему линейных уравнений:\n",
        "\n",
        "$$\n",
        "\\pi_i = \\sum_j \\pi_j p_{ji}, \\quad \\sum_i \\pi_i = 1.\n",
        "$$\n",
        "\n",
        "#### Примеры решения задач\n",
        "\n",
        "**Пример 1. Система обслуживания**\n",
        "\n",
        "Рассмотрим систему, в которой клиент находится в одном из трёх состояний: \"ожидание\" (состояние 1), \"обслуживание\" (состояние 2) и \"завершение\" (состояние 3). Матрица переходов:\n",
        "\n",
        "$$\n",
        "P = \\begin{bmatrix}\n",
        "0.6 & 0.3 & 0.1 \\\\\n",
        "0.4 & 0.5 & 0.1 \\\\\n",
        "0.0 & 0.0 & 1.0 \\\\\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "Здесь состояние 3 является поглощающим, так как $p_{33} = 1$.\n",
        "\n",
        "**Пример 2. Модель погодных условий**\n",
        "\n",
        "Предположим, что погода может быть \"солнечной\" (S), \"облачной\" (C) или \"дождливой\" (R). Матрица переходных вероятностей:\n",
        "\n",
        "$$\n",
        "P = \\begin{bmatrix}\n",
        "0.8 & 0.1 & 0.1 \\\\\n",
        "0.2 & 0.6 & 0.2 \\\\\n",
        "0.3 & 0.3 & 0.4 \\\\\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "Если сегодня погода солнечная, вероятность того, что завтра также будет солнечно, равна 0.8, а вероятность облачной или дождливой погоды — 0.1.\n",
        "\n",
        "#### Критерии сходимости марковских цепей\n",
        "\n",
        "Марковская цепь сходится к стационарному распределению, если она является **апериодической** и **неприводимой**.\n",
        "\n",
        "- **Апериодичность** означает, что состояние можно посетить через различные промежутки времени.\n",
        "- **Неприводимость** означает, что любое состояние можно достигнуть из любого другого состояния.\n",
        "\n",
        "#### Применение марковских цепей\n",
        "\n",
        "1. **Обслуживающие системы** (модели очередей, системы с отказами).\n",
        "2. **Финансовые модели** (модели изменения цен, кредитные риски).\n",
        "3. **Теория игр** (стратегии и оптимальные решения).\n",
        "4. **Генетика** (модели мутаций и наследования признаков).\n",
        "\n",
        "\n",
        "Рассмотрим конкретный пример применения марковских цепей на практике. Пусть у нас есть магазин, который работает в трёх режимах:\n",
        "\n",
        "1. **Низкий спрос** (Low) — состояние $S_1$.\n",
        "2. **Средний спрос** (Medium) — состояние $S_2$.\n",
        "3. **Высокий спрос** (High) — состояние $S_3$.\n",
        "\n",
        "Менеджер магазина хочет спрогнозировать, в каком состоянии будет находиться магазин через несколько дней, если известно, что в каждый день вероятность перехода из одного состояния в другое описывается следующей матрицей переходных вероятностей:\n",
        "\n",
        "$$\n",
        "P = \\begin{bmatrix}\n",
        "0.6 & 0.3 & 0.1 \\\\\n",
        "0.2 & 0.5 & 0.3 \\\\\n",
        "0.1 & 0.4 & 0.5 \\\\\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "Где $p_{ij}$ — вероятность перехода из состояния $S_i$ в состояние $S_j$. Например, вероятность того, что магазин останется в состоянии \"Низкий спрос\" на следующий день, равна 0.6, а вероятность перехода в состояние \"Средний спрос\" — 0.3.\n",
        "\n",
        "Допустим, что на текущий день спрос низкий, т.е. начальное распределение можно задать как $\\pi = [1, 0, 0]$, что означает, что вероятность нахождения магазина в состоянии $S_1$ равна 1.\n",
        "\n",
        "Теперь рассчитаем, как изменится распределение вероятностей через один и два дня.\n",
        "\n",
        "### Шаг 1: Расчёт распределения вероятностей через один день\n",
        "\n",
        "Чтобы найти распределение вероятностей через один шаг, нужно умножить вектор начального распределения $\\pi$ на матрицу переходных вероятностей $P$:\n",
        "\n",
        "$$\n",
        "\\pi^{(1)} = \\pi P = [1, 0, 0] \\begin{bmatrix}\n",
        "0.6 & 0.3 & 0.1 \\\\\n",
        "0.2 & 0.5 & 0.3 \\\\\n",
        "0.1 & 0.4 & 0.5 \\\\\n",
        "\\end{bmatrix} = [0.6, 0.3, 0.1].\n",
        "$$\n",
        "\n",
        "Таким образом, через один день вероятность того, что спрос будет низким, равна 0.6, средним — 0.3, а высоким — 0.1.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Шаг 2: Расчёт распределения вероятностей через два дня\n",
        "\n",
        "Для нахождения распределения вероятностей через два дня, нужно умножить полученное распределение $\\pi^{(1)}$ на матрицу переходных вероятностей $P$ ещё раз:\n",
        "\n",
        "$$\n",
        "\\pi^{(2)} = \\pi^{(1)} P = [0.6, 0.3, 0.1] \\begin{bmatrix}\n",
        "0.6 & 0.3 & 0.1 \\\\\n",
        "0.2 & 0.5 & 0.3 \\\\\n",
        "0.1 & 0.4 & 0.5 \\\\\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "Теперь произведём вычисления для каждого элемента вектора $\\pi^{(2)}$:\n",
        "\n",
        "1. Вероятность нахождения в состоянии $S_1$ (низкий спрос):\n",
        "   $$\n",
        "   \\pi^{(2)}_1 = 0.6 \\cdot 0.6 + 0.3 \\cdot 0.2 + 0.1 \\cdot 0.1 = 0.36 + 0.06 + 0.01 = 0.43.\n",
        "   $$\n",
        "\n",
        "2. Вероятность нахождения в состоянии $S_2$ (средний спрос):\n",
        "   $$\n",
        "   \\pi^{(2)}_2 = 0.6 \\cdot 0.3 + 0.3 \\cdot 0.5 + 0.1 \\cdot 0.4 = 0.18 + 0.15 + 0.04 = 0.37.\n",
        "   $$\n",
        "\n",
        "3. Вероятность нахождения в состоянии $S_3$ (высокий спрос):\n",
        "   $$\n",
        "   \\pi^{(2)}_3 = 0.6 \\cdot 0.1 + 0.3 \\cdot 0.3 + 0.1 \\cdot 0.5 = 0.06 + 0.09 + 0.05 = 0.20.\n",
        "   $$\n",
        "\n",
        "Таким образом, через два дня распределение вероятностей будет следующим:\n",
        "$$\n",
        "\\pi^{(2)} = [0.43, 0.37, 0.20].\n",
        "$$\n",
        "\n",
        "Это означает, что через два дня вероятность того, что спрос будет низким, равна 0.43, средним — 0.37, а высоким — 0.20.\n",
        "\n",
        "### Шаг 3: Проверка стационарного распределения\n",
        "\n",
        "Теперь попробуем найти стационарное распределение, при котором система уже не меняет своё распределение вероятностей при последующих умножениях на матрицу $P$. Обозначим стационарное распределение как $\\pi = [\\pi_1, \\pi_2, \\pi_3]$, и это распределение должно удовлетворять уравнению:\n",
        "\n",
        "$$\n",
        "\\pi P = \\pi,\n",
        "$$\n",
        "\n",
        "что эквивалентно системе линейных уравнений:\n",
        "$$\n",
        "\\begin{cases}\n",
        "0.6\\pi_1 + 0.2\\pi_2 + 0.1\\pi_3 = \\pi_1, \\\\\n",
        "0.3\\pi_1 + 0.5\\pi_2 + 0.4\\pi_3 = \\pi_2, \\\\\n",
        "0.1\\pi_1 + 0.3\\pi_2 + 0.5\\pi_3 = \\pi_3.\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "Кроме того, выполняется условие нормировки:\n",
        "$$\n",
        "\\pi_1 + \\pi_2 + \\pi_3 = 1.\n",
        "$$\n",
        "\n",
        "Решая эту систему уравнений, можно найти значения $\\pi_1$, $\\pi_2$ и $\\pi_3$, которые будут представлять стационарное распределение вероятностей. Решение этой системы даёт нам следующее стационарное распределение:\n",
        "\n",
        "$$\n",
        "\\pi = [0.4, 0.4, 0.2].\n",
        "$$\n",
        "\n",
        "Это означает, что в долгосрочной перспективе вероятность того, что спрос будет низким, равна 0.4, средним — 0.4, а высоким — 0.2.\n",
        "\n",
        "### Выводы\n",
        "\n",
        "В данном примере мы рассмотрели шаги расчёта распределения вероятностей для марковской цепи с тремя состояниями. Сначала мы рассчитали вероятности через один и два дня, затем нашли стационарное распределение, показывающее, как система ведёт себя в долгосрочной перспективе. Этот подход может быть применён к различным задачам моделирования, включая экономические прогнозы, анализ производственных процессов и многие другие области.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Марковские цепи находят широкое применение в машинном обучении (ML) и глубоком обучении (DL). Они используются в различных задачах, таких как генерация последовательностей, моделирование временных рядов, построение вероятностных моделей и обучение с подкреплением. Давайте рассмотрим несколько конкретных примеров использования марковских цепей в ML и DL.\n",
        "\n",
        "### Пример 1: Генерация текстов с помощью цепей Маркова\n",
        "\n",
        "В машинном обучении для генерации текста можно использовать марковские цепи. Представим, что мы хотим сгенерировать текст на основе существующих данных, учитывая только текущие и предыдущие слова. Здесь каждое слово представляет собой состояние, а переходные вероятности зависят от частоты, с которой одно слово следует за другим.\n",
        "\n",
        "#### Шаги:\n",
        "\n",
        "1. **Сбор данных**: Собираем корпус текстов, который будем использовать для построения модели.\n",
        "2. **Построение марковской цепи**:\n",
        "   - Вычисляем частоты пар последовательных слов в тексте.\n",
        "   - Создаем матрицу переходных вероятностей, где вероятность перехода от одного слова к другому зависит от частоты их совместного появления.\n",
        "3. **Генерация текста**:\n",
        "   - Начинаем с начального слова и выбираем следующее слово на основе распределения вероятностей переходов.\n",
        "   - Повторяем процесс, пока не будет достигнута заданная длина текста.\n",
        "\n",
        "#### Пример:\n",
        "\n",
        "Пусть есть следующий текст: \"кошка сидит на окне. кошка смотрит на улицу. кошка спит на окне.\"\n",
        "\n",
        "Построим простую марковскую цепь для генерации новых предложений. Из текста можно выделить переходы:\n",
        "\n",
        "- \"кошка\" → \"сидит\", \"смотрит\", \"спит\".\n",
        "- \"сидит\" → \"на\".\n",
        "- \"на\" → \"окне\", \"улицу\".\n",
        "- и так далее.\n",
        "\n",
        "Используя эти переходы, можно сгенерировать текст вроде \"кошка сидит на окне\" или \"кошка спит на улице\".\n",
        "\n",
        "### Пример 2: Моделирование временных рядов с помощью скрытых марковских моделей (Hidden Markov Models, HMM)\n",
        "\n",
        "Скрытые марковские модели применяются для моделирования временных рядов, таких как финансовые данные, данные о погоде, речевые сигналы и биологические данные. HMM включают в себя \"скрытые\" состояния, которые недоступны напрямую, но могут быть оценены через наблюдаемые данные.\n",
        "\n",
        "#### Шаги:\n",
        "\n",
        "1. **Постановка задачи**: Допустим, мы хотим предсказать, будет ли рынок \"бычьим\" (растущим) или \"медвежьим\" (падающим), основываясь на исторических данных о ценах акций.\n",
        "2. **Определение состояний**: Состояния могут быть \"бычий рынок\" и \"медвежий рынок\", и они являются скрытыми, потому что их невозможно напрямую наблюдать.\n",
        "3. **Определение наблюдаемых данных**: Наблюдаемыми данными могут быть изменения цен акций за день.\n",
        "4. **Построение модели HMM**: Определяются вероятности перехода между состояниями и вероятности наблюдения данных в каждом состоянии.\n",
        "5. **Предсказание**: Используя алгоритмы Viterbi или Forward-Backward, можно определить вероятности нахождения системы в определённых состояниях в будущем.\n",
        "\n",
        "### Пример 3: Обучение с подкреплением (Reinforcement Learning) и марковские процессы принятия решений (Markov Decision Processes, MDP)\n",
        "\n",
        "Марковские процессы принятия решений (MDP) являются ключевыми элементами в обучении с подкреплением, где агент взаимодействует со средой и учится принимать оптимальные решения.\n",
        "\n",
        "#### Шаги:\n",
        "\n",
        "1. **Описание среды**: Среда определяется набором состояний, возможных действий и функцией вознаграждения, которая даёт агенту оценку полезности каждого действия.\n",
        "2. **Переходные вероятности**: В MDP задаются вероятности перехода от одного состояния к другому в зависимости от выбранного действия.\n",
        "3. **Функция вознаграждения**: Определяет, какое вознаграждение агент получает за выполнение действия.\n",
        "4. **Поиск оптимальной политики**: Алгоритмы обучения с подкреплением, такие как Q-обучение или SARSA, используют марковские цепи для вычисления оптимальной политики, то есть стратегии выбора действий, которая максимизирует суммарное вознаграждение.\n",
        "\n",
        "#### Пример:\n",
        "\n",
        "Рассмотрим задачу обучения робота навигации в лабиринте. Состояния соответствуют позициям робота в лабиринте, действия — это \"вверх\", \"вниз\", \"влево\" и \"вправо\", а функция вознаграждения даёт положительное значение, если робот находит выход, и отрицательное, если сталкивается с препятствием. Марковские цепи позволяют оценивать вероятность нахождения в определённых состояниях в зависимости от последовательности действий.\n",
        "\n",
        "### Пример 4: Прогнозирование последовательностей в глубоком обучении (RNN и LSTM)\n",
        "\n",
        "Хотя рекуррентные нейронные сети (RNN) и их расширенные версии, такие как LSTM (Long Short-Term Memory), не являются марковскими моделями в строгом смысле, они часто используют концепции, схожие с марковскими процессами. RNN и LSTM способны моделировать последовательные данные, такие как текст, временные ряды или данные о пользователях.\n",
        "\n",
        "#### Как это связано с марковскими цепями?\n",
        "\n",
        "- В RNN входы обрабатываются последовательно, и на каждом шаге текущее состояние сети зависит от предыдущего состояния. Это аналогично идее марковских цепей, где вероятность следующего состояния зависит только от текущего состояния.\n",
        "- В отличие от марковских цепей, RNN и LSTM могут \"помнить\" более длинные зависимости благодаря своим внутренним состояниям и параметрам сети.\n",
        "\n",
        "#### Пример:\n",
        "\n",
        "Предсказание следующего слова в предложении может быть реализовано с помощью LSTM. Модель получает последовательность слов и на основе их переходов предсказывает вероятности появления следующего слова. Это схоже с марковскими цепями, но с более сложным подходом к учёту предыдущих состояний.\n",
        "\n",
        "\n",
        "Давайте рассмотрим каждый из приведённых примеров с конкретными числовыми данными и решением шаг за шагом.\n",
        "\n",
        "### Пример 1: Генерация текста с помощью цепей Маркова\n",
        "\n",
        "Предположим, у нас есть текст: \"кошка сидит на окне. кошка смотрит на окно. кошка спит на окне.\" Мы хотим построить марковскую модель для генерации нового текста.\n",
        "\n",
        "#### Шаг 1: Построение матрицы переходных вероятностей\n",
        "\n",
        "1. Разобьём текст на пары последовательных слов:\n",
        "   - \"кошка сидит\", \"сидит на\", \"на окне\"\n",
        "   - \"кошка смотрит\", \"смотрит на\", \"на окно\"\n",
        "   - \"кошка спит\", \"спит на\", \"на окне\"\n",
        "\n",
        "2. Построим частотную таблицу переходов:\n",
        "   - \"кошка\" → \"сидит\" (1 раз), \"смотрит\" (1 раз), \"спит\" (1 раз)\n",
        "   - \"сидит\" → \"на\" (1 раз)\n",
        "   - \"смотрит\" → \"на\" (1 раз)\n",
        "   - \"спит\" → \"на\" (1 раз)\n",
        "   - \"на\" → \"окне\" (2 раза), \"окно\" (1 раз)\n",
        "\n",
        "3. Преобразуем эту таблицу в матрицу переходных вероятностей:\n",
        "   $$\n",
        "   P =\n",
        "   \\begin{bmatrix}\n",
        "   0 & 1/3 & 1/3 & 1/3 & 0 & 0 \\\\\n",
        "   0 & 0 & 0 & 0 & 1 & 0 \\\\\n",
        "   0 & 0 & 0 & 0 & 1 & 0 \\\\\n",
        "   0 & 0 & 0 & 0 & 1 & 0 \\\\\n",
        "   0 & 0 & 0 & 0 & 0 & 2/3 \\\\\n",
        "   0 & 0 & 0 & 0 & 0 & 1/3 \\\\\n",
        "   \\end{bmatrix}\n",
        "   $$\n",
        "   Здесь строки и столбцы соответствуют словам \"кошка\", \"сидит\", \"смотрит\", \"спит\", \"на\", \"окне/окно\".\n",
        "\n",
        "#### Шаг 2: Генерация нового текста\n",
        "\n",
        "1. Начинаем с \"кошка\". С вероятностью \\(1/3\\) выбираем одно из слов: \"сидит\", \"смотрит\" или \"спит\".\n",
        "2. Пусть выпало \"сидит\". Следующее слово — \"на\".\n",
        "3. \"на\" с вероятностью \\(2/3\\) переходит в \"окне\", с вероятностью \\(1/3\\) — в \"окно\".\n",
        "\n",
        "Таким образом, один из возможных сгенерированных текстов может быть: \"кошка сидит на окне\".\n",
        "\n",
        "### Пример 2: Моделирование временных рядов с помощью скрытой марковской модели (HMM)\n",
        "\n",
        "Рассмотрим задачу предсказания погоды с двумя скрытыми состояниями: \"солнечно\" и \"дождливо\", и наблюдаемыми состояниями: \"хорошее настроение\" и \"плохое настроение\".\n",
        "\n",
        "#### Данные модели:\n",
        "\n",
        "- Начальное распределение: $\\pi = [0.8, 0.2]$, то есть вероятность, что начнётся с солнечного дня, равна 0.8, а с дождливого — 0.2.\n",
        "- Матрица переходов:\n",
        "  $$\n",
        "  A =\n",
        "  \\begin{bmatrix}\n",
        "  0.7 & 0.3 \\\\\n",
        "  0.4 & 0.6 \\\\\n",
        "  \\end{bmatrix}\n",
        "  $$\n",
        "  Где $A_{ij}$ — вероятность перехода от состояния $i$ к состоянию $j$.\n",
        "\n",
        "- Матрица наблюдений:\n",
        "  $$\n",
        "  B =\n",
        "  \\begin{bmatrix}\n",
        "  0.9 & 0.1 \\\\\n",
        "  0.2 & 0.8 \\\\\n",
        "  \\end{bmatrix}\n",
        "  $$\n",
        "  Где $B_{ij}$ — вероятность наблюдения $j$-го настроения при условии $i$-го состояния (солнечно или дождливо).\n",
        "\n",
        "#### Задача: Определить наиболее вероятную последовательность скрытых состояний для наблюдаемой последовательности \"хорошее настроение, плохое настроение\".\n",
        "\n",
        "1. **Инициализация (Алгоритм Витерби)**:\n",
        "   $$\n",
        "   \\delta_1(солнечно) = \\pi(солнечно) \\cdot B(солнечно, хорошее) = 0.8 \\cdot 0.9 = 0.72\n",
        "   $$\n",
        "   $$\n",
        "   \\delta_1(дождливо) = \\pi(дождливо) \\cdot B(дождливо, хорошее) = 0.2 \\cdot 0.2 = 0.04\n",
        "   $$\n",
        "\n",
        "2. **Рекурсия для второго наблюдения**:\n",
        "   $$\n",
        "   \\delta_2(солнечно) = \\max(0.72 \\cdot 0.7, 0.04 \\cdot 0.4) \\cdot 0.1 = 0.0504\n",
        "   $$\n",
        "   $$\n",
        "   \\delta_2(дождливо) = \\max(0.72 \\cdot 0.3, 0.04 \\cdot 0.6) \\cdot 0.8 = 0.1728\n",
        "   $$\n",
        "\n",
        "3. **Назад по цепи**:\n",
        "   Наиболее вероятная последовательность состояний: \"солнечно\", \"дождливо\".\n",
        "\n",
        "### Пример 3: Обучение с подкреплением и марковский процесс принятия решений (MDP)\n",
        "\n",
        "Задача: Робот перемещается по сетке 3x3. Цель — попасть в клетку с наградой +10, избегая клетки с наказанием -5.\n",
        "\n",
        "#### Данные:\n",
        "\n",
        "- Состояния: клетки (1,1), (1,2), ..., (3,3).\n",
        "- Действия: вверх, вниз, влево, вправо.\n",
        "- Функция вознаграждения: +10 в клетке (3,3), -5 в клетке (2,3).\n",
        "- Вероятности переходов — робот иногда \"скользит\" и попадает не туда (80% правильное направление, 10% отклонение).\n",
        "\n",
        "#### Поиск оптимальной стратегии:\n",
        "\n",
        "1. **Инициализация Q-функции**: Зададим начальные значения $Q(s, a) = 0$.\n",
        "2. **Алгоритм Q-обучения**:\n",
        "   $$\n",
        "   Q(s, a) = Q(s, a) + \\alpha (r + \\gamma \\max_{a'} Q(s', a') - Q(s, a))\n",
        "   $$\n",
        "   Где $\\alpha$ — коэффициент обучения, $\\gamma$ — коэффициент дисконтирования, $r$ — вознаграждение.\n",
        "3. **Обновление значений Q** для каждого перехода, пока значения не стабилизируются.\n",
        "\n",
        "После завершения Q-обучения робот будет следовать стратегии, которая максимизирует ожидаемое суммарное вознаграждение.\n",
        "\n",
        "### Пример 4: Прогнозирование последовательностей в RNN и LSTM\n",
        "\n",
        "Задача: Предсказать следующую температуру на основе данных за последние три дня.\n",
        "\n",
        "#### Шаги:\n",
        "\n",
        "1. **Данные**: Температуры за последние 5 дней: 22°C, 24°C, 23°C, 25°C, 24°C.\n",
        "2. **Обучение LSTM**:\n",
        "   - Вход: последовательность [22, 24, 23], [24, 23, 25], ...\n",
        "   - Выход: предсказание следующей температуры.\n",
        "3. **Обучение с использованием градиентного спуска**, минимизируя среднеквадратичную ошибку.\n",
        "4. **Предсказание**: Используем обученную модель для предсказания температуры на следующий день, скажем, она составляет 24.5°C.\n",
        "\n",
        "Таким образом, использование марковских цепей и их обобщений (например, HMM, MDP) помогает моделировать реальные задачи и находить оптимальные решения для различных проблем в ML и DL.\n"
      ],
      "metadata": {
        "id": "pZQ_paBadntB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Давайте реализуем все приведённые примеры на Python. Для каждого примера я предоставлю полный код с комментариями, чтобы объяснить, как он работает.\n",
        "\n",
        "Пример 1: Генерация текста с помощью цепей Маркова"
      ],
      "metadata": {
        "id": "tM9uW3dId4ql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Исходный текст\n",
        "text = \"кошка сидит на окне. кошка смотрит на окно. кошка спит на окне.\"\n",
        "\n",
        "# Разделим текст на слова\n",
        "words = text.replace('.', '').split()\n",
        "pairs = list(zip(words[:-1], words[1:]))\n",
        "\n",
        "# Построим частотную таблицу переходов\n",
        "transition_counts = {}\n",
        "for w1, w2 in pairs:\n",
        "    if w1 not in transition_counts:\n",
        "        transition_counts[w1] = {}\n",
        "    if w2 not in transition_counts[w1]:\n",
        "        transition_counts[w1][w2] = 0\n",
        "    transition_counts[w1][w2] += 1\n",
        "\n",
        "# Построим матрицу переходных вероятностей\n",
        "transition_probabilities = {}\n",
        "for w1, next_words in transition_counts.items():\n",
        "    total = sum(next_words.values())\n",
        "    transition_probabilities[w1] = {w2: count / total for w2, count in next_words.items()}\n",
        "\n",
        "# Функция для генерации текста\n",
        "def generate_text(start_word, length=10):\n",
        "    current_word = start_word\n",
        "    result = [current_word]\n",
        "    for _ in range(length - 1):\n",
        "        if current_word not in transition_probabilities:\n",
        "            break\n",
        "        next_words = list(transition_probabilities[current_word].keys())\n",
        "        probs = list(transition_probabilities[current_word].values())\n",
        "        current_word = np.random.choice(next_words, p=probs)\n",
        "        result.append(current_word)\n",
        "    return ' '.join(result)\n",
        "\n",
        "# Генерируем текст, начиная с слова \"кошка\"\n",
        "generated_text = generate_text(\"кошка\", 10)\n",
        "print(\"Сгенерированный текст:\", generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAwMHIkvd5TE",
        "outputId": "7b84cf4e-dd04-4226-d6dd-ac94db7ba789"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Сгенерированный текст: кошка смотрит на окне кошка смотрит на окне кошка сидит\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пример 2: Моделирование временных рядов с помощью скрытой марковской модели (HMM)\n",
        "Для реализации скрытой марковской модели воспользуемся библиотекой hmmlearn."
      ],
      "metadata": {
        "id": "cD0LCLFjd9Rb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hmmlearn\n",
        "import numpy as np\n",
        "from hmmlearn import hmm\n",
        "\n",
        "# Определим скрытые состояния и наблюдаемые данные\n",
        "states = [\"солнечно\", \"дождливо\"]\n",
        "observations = [\"хорошее\", \"плохое\"]\n",
        "\n",
        "# Массив наблюдений (0: хорошее настроение, 1: плохое настроение)\n",
        "obs_seq = np.array([[0, 1]]).T  # \"хорошее\", \"плохое\"\n",
        "\n",
        "# Начальные вероятности\n",
        "startprob = np.array([0.8, 0.2])\n",
        "\n",
        "# Матрица переходов\n",
        "transmat = np.array([[0.7, 0.3],\n",
        "                     [0.4, 0.6]])\n",
        "\n",
        "# Матрица наблюдений\n",
        "emissionprob = np.array([[0.9, 0.1],\n",
        "                          [0.2, 0.8]])\n",
        "\n",
        "# Создадим и обучим модель HMM\n",
        "model = hmm.MultinomialHMM(n_components=2, n_iter=100, tol=0.01)\n",
        "model.startprob_ = startprob\n",
        "model.transmat_ = transmat\n",
        "model.emissionprob_ = emissionprob\n",
        "\n",
        "# Обучаем модель на последовательности наблюдений\n",
        "model.fit(obs_seq)\n",
        "\n",
        "# Предсказание состояний\n",
        "logprob, predicted_states = model.decode(obs_seq, algorithm=\"viterbi\")\n",
        "\n",
        "# Результаты\n",
        "predicted_states = [states[i] for i in predicted_states]\n",
        "print(\"Предсказанные состояния:\", predicted_states)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5gh_VwTeB-l",
        "outputId": "df183d4d-59bd-4b0c-e066-3794e991b2b2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hmmlearn\n",
            "  Downloading hmmlearn-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.10/dist-packages (from hmmlearn) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn!=0.22.0,>=0.16 in /usr/local/lib/python3.10/dist-packages (from hmmlearn) (1.5.2)\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.10/dist-packages (from hmmlearn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (3.5.0)\n",
            "Downloading hmmlearn-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.1/161.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: hmmlearn\n",
            "Successfully installed hmmlearn-0.3.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:hmmlearn.hmm:MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
            "https://github.com/hmmlearn/hmmlearn/issues/335\n",
            "https://github.com/hmmlearn/hmmlearn/issues/340\n",
            "WARNING:hmmlearn.base:Even though the 'startprob_' attribute is set, it will be overwritten during initialization because 'init_params' contains 's'\n",
            "WARNING:hmmlearn.base:Even though the 'transmat_' attribute is set, it will be overwritten during initialization because 'init_params' contains 't'\n",
            "WARNING:hmmlearn.base:Fitting a model with 3 free scalar parameters with only 2 data points will result in a degenerate solution.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Предсказанные состояния: ['солнечно', 'солнечно']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пример 3: Обучение с подкреплением и марковский процесс принятия решений (MDP)\n",
        "Реализуем простой пример Q-обучения для робота в 3x3 сетке."
      ],
      "metadata": {
        "id": "dfwA5U5FeR-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Определим параметры среды\n",
        "grid_size = 3\n",
        "num_states = grid_size * grid_size\n",
        "num_actions = 4  # 0: вверх, 1: вниз, 2: влево, 3: вправо\n",
        "\n",
        "# Создаем матрицу Q\n",
        "Q = np.zeros((num_states, num_actions))\n",
        "\n",
        "# Функция вознаграждения\n",
        "def reward(state):\n",
        "    if state == 8:  # (3,3)\n",
        "        return 10\n",
        "    elif state == 5:  # (2,3)\n",
        "        return -5\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# Функция для получения следующего состояния\n",
        "def next_state(state, action):\n",
        "    row, col = divmod(state, grid_size)\n",
        "    if action == 0:  # вверх\n",
        "        row = max(row - 1, 0)\n",
        "    elif action == 1:  # вниз\n",
        "        row = min(row + 1, grid_size - 1)\n",
        "    elif action == 2:  # влево\n",
        "        col = max(col - 1, 0)\n",
        "    elif action == 3:  # вправо\n",
        "        col = min(col + 1, grid_size - 1)\n",
        "    return row * grid_size + col\n",
        "\n",
        "# Параметры Q-обучения\n",
        "alpha = 0.1  # скорость обучения\n",
        "gamma = 0.9  # коэффициент дисконтирования\n",
        "num_episodes = 1000\n",
        "\n",
        "# Q-обучение\n",
        "for _ in range(num_episodes):\n",
        "    state = random.randint(0, num_states - 1)  # случайное начальное состояние\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        # Выбираем действие (согласно ε-жадной стратегии)\n",
        "        if random.uniform(0, 1) < 0.1:  # ε = 0.1\n",
        "            action = random.randint(0, num_actions - 1)\n",
        "        else:\n",
        "            action = np.argmax(Q[state])  # выбираем лучшее действие\n",
        "\n",
        "        # Переходим в следующее состояние\n",
        "        next_s = next_state(state, action)\n",
        "\n",
        "        # Получаем вознаграждение\n",
        "        r = reward(next_s)\n",
        "\n",
        "        # Обновляем Q-значение\n",
        "        Q[state, action] += alpha * (r + gamma * np.max(Q[next_s]) - Q[state, action])\n",
        "\n",
        "        # Переходим к следующему состоянию\n",
        "        state = next_s\n",
        "\n",
        "        if r != 0:  # если достигли конечного состояния\n",
        "            done = True\n",
        "\n",
        "# Печатаем итоговую Q-матрицу\n",
        "print(\"Q-матрица:\")\n",
        "print(Q)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a_Bo2WEeVTl",
        "outputId": "2c77b791-7e49-4fed-c40d-e73590035b38"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q-матрица:\n",
            "[[ 5.06400266e+00  7.66059137e+00  5.58583540e+00  4.38043791e+01]\n",
            " [ 2.27431592e+01  1.24627285e+01  1.62528130e+01  4.94308825e+01]\n",
            " [ 3.49928552e+01  5.52013599e+01  2.42917369e+01  2.12649724e+01]\n",
            " [ 3.60314614e+01  2.34455361e+00  2.02825199e+00  3.87019728e+00]\n",
            " [ 4.38228460e+01  1.35865968e+00  2.35247550e+00  8.77852023e-01]\n",
            " [ 3.27098037e+00  6.70930289e+01  3.06211271e+00 -6.13769740e-02]\n",
            " [ 2.71742030e+00  1.82910641e+00  1.82487114e-01  3.08068753e+01]\n",
            " [ 3.83042928e+01  0.00000000e+00  6.29424006e-06  1.23604925e+01]\n",
            " [ 1.29759516e+01  6.65623143e+01  2.88955979e+00  8.38671651e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пример 4: Прогнозирование последовательностей в RNN и LSTM\n",
        "Для реализации этого примера воспользуемся библиотекой Keras (или TensorFlow)."
      ],
      "metadata": {
        "id": "YQr8rEQkeZva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "\n",
        "# Данные: температура за 5 дней\n",
        "data = np.array([22, 24, 23, 25, 24])\n",
        "\n",
        "# Подготовим входные и выходные данные\n",
        "X, y = [], []\n",
        "for i in range(len(data) - 3):\n",
        "    X.append(data[i:i + 3])  # последние 3 дня\n",
        "    y.append(data[i + 3])    # следующий день\n",
        "X, y = np.array(X), np.array(y)\n",
        "\n",
        "# Преобразуем данные для LSTM\n",
        "X = X.reshape((X.shape[0], X.shape[1], 1))  # (samples, timesteps, features)\n",
        "\n",
        "# Создаем модель LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', input_shape=(X.shape[1], 1)))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Обучаем модель\n",
        "model.fit(X, y, epochs=200, verbose=0)\n",
        "\n",
        "# Предсказание на основе последних трех дней\n",
        "test_data = np.array([23, 25, 24]).reshape((1, 3, 1))\n",
        "predicted_temperature = model.predict(test_data, verbose=0)\n",
        "print(f\"Предсказанная температура на следующий день: {predicted_temperature[0][0]:.2f} °C\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kzlp7-InenmO",
        "outputId": "f256fa84-9009-453e-e0b6-3b7681a7ae20"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Предсказанная температура на следующий день: 24.99 °C\n"
          ]
        }
      ]
    }
  ]
}