{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPchfTt74SZjP/h83BYoHpX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodeHunterOfficial/AI_DataMining/blob/main/NLP/Ru_Persian.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import io\n",
        "import numpy as np\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from nltk.tokenize import word_tokenize  # Для токенизации русского и персидского\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Определяем теги заполнения, начала и конца\n",
        "PAD, BOS, EOS = '<pad>', '<bos>', '<eos>'\n",
        "\n",
        "# Загружаем данные с русского на персидский\n",
        "def load_data():\n",
        "    with io.open('/content/data/ru_farsi.txt', encoding='utf-8') as f:\n",
        "        lines = f.readlines()\n",
        "    return lines\n",
        "\n",
        "# Предобработка данных в токены\n",
        "def preprocess_data(data, max_length):\n",
        "    in_tokens, out_tokens, in_seqs, out_seqs = [], [], [], []\n",
        "    for st in data:\n",
        "        in_seq, out_seq = st.rstrip().split('\\t')\n",
        "\n",
        "        # Токенизация для русского и персидского\n",
        "        in_seq_tokens = word_tokenize(in_seq.lower())\n",
        "        out_seq_tokens = word_tokenize(out_seq.lower())\n",
        "\n",
        "        if max(len(in_seq_tokens), len(out_seq_tokens)) > max_length - 1:\n",
        "            continue  # Пропускаем предложение, если оно слишком длинное\n",
        "\n",
        "        in_tokens.extend(in_seq_tokens)\n",
        "        out_tokens.extend(out_seq_tokens)\n",
        "        in_seqs.append(in_seq_tokens + [EOS] + [PAD] * (max_length - len(in_seq_tokens) - 1))\n",
        "        out_seqs.append(out_seq_tokens + [EOS] + [PAD] * (max_length - len(out_seq_tokens) - 1))\n",
        "\n",
        "    return in_tokens, out_tokens, in_seqs, out_seqs\n",
        "\n",
        "# Создание словаря из токенов\n",
        "def build_vocab(tokens, seqs):\n",
        "    vocab = collections.Counter(tokens)\n",
        "    vocab = {word: idx for idx, (word, _) in enumerate(vocab.items())}\n",
        "    vocab[PAD] = len(vocab)\n",
        "    vocab[BOS] = len(vocab)\n",
        "    vocab[EOS] = len(vocab)\n",
        "\n",
        "    indices = [[vocab[token] for token in seq] for seq in seqs]\n",
        "    return vocab, indices\n",
        "\n",
        "# Определяем модель Encoder\n",
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers, drop_prob=0):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embed_size)\n",
        "        self.gru = tf.keras.layers.GRU(num_hiddens, return_sequences=True, return_state=True, dropout=drop_prob)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        embedding = self.embedding(inputs)\n",
        "        output, state = self.gru(embedding)\n",
        "        return output, state\n",
        "\n",
        "# Определяем модель Decoder с вниманием\n",
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers, drop_prob=0):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embed_size)\n",
        "        self.gru = tf.keras.layers.GRU(num_hiddens, return_sequences=True, return_state=True, dropout=drop_prob)\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    def call(self, inputs, state):\n",
        "        embedding = self.embedding(inputs)\n",
        "        output, state = self.gru(embedding, initial_state=state)\n",
        "        output = self.fc(output)\n",
        "        return output, state\n",
        "\n",
        "# Определяем функцию потерь\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.equal(real, 0))  # Маскирование токенов PAD\n",
        "    loss_ = tf.keras.losses.sparse_categorical_crossentropy(real, pred, from_logits=True)\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask  # Применить маску\n",
        "    return tf.reduce_mean(loss_)\n",
        "\n",
        "# Обучаем модель\n",
        "# Обучаем модель\n",
        "def train(encoder, decoder, dataset, optimizer, num_epochs, out_vocab):\n",
        "    losses = []\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for (batch, (in_seq, out_seq)) in enumerate(dataset):\n",
        "            with tf.GradientTape() as tape:\n",
        "                enc_output, enc_state = encoder(in_seq)\n",
        "                dec_input = tf.expand_dims([out_vocab[BOS]] * in_seq.shape[0], 1)  # Начальный ввод для декодера\n",
        "                predictions = []\n",
        "\n",
        "                for t in range(1, out_seq.shape[1]):  # Исключить первый токен\n",
        "                    dec_output, enc_state = decoder(dec_input, enc_state)\n",
        "                    predictions.append(dec_output)\n",
        "                    dec_input = tf.expand_dims(out_seq[:, t], 1)  # Teacher forcing\n",
        "\n",
        "                predictions = tf.concat(predictions, axis=1)\n",
        "                loss = loss_function(out_seq[:, 1:], predictions)  # Исключить первый токен для потерь\n",
        "\n",
        "            total_loss += loss\n",
        "            grads = tape.gradient(loss, encoder.trainable_variables + decoder.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(grads, encoder.trainable_variables + decoder.trainable_variables))\n",
        "\n",
        "        avg_loss = total_loss.numpy() / (batch + 1)\n",
        "        losses.append(avg_loss)\n",
        "        print(f'Epoch {epoch + 1}, Loss: {avg_loss}')\n",
        "\n",
        "    # Сохранение параметров после завершения обучения\n",
        "    encoder.save_weights('./data/params_encoder.weights.h5')\n",
        "    decoder.save_weights('./data/params_decoder.weights.h5')\n",
        "\n",
        "    print(\"Параметры модели успешно сохранены.\")\n",
        "\n",
        "    # Визуализируем потери\n",
        "    plt.plot(losses)\n",
        "    plt.xlabel('Эпохи')\n",
        "    plt.ylabel('Потери')\n",
        "    plt.title('Потери обучения')\n",
        "    plt.grid(True)  # Добавляем сетку для удобства чтения\n",
        "    plt.show()\n",
        "\n",
        "# Функция предсказания (для генерации переводов)\n",
        "def predict_sequence(encoder, decoder, input_seq, max_length, in_vocab, out_vocab):\n",
        "    input_seq = tf.convert_to_tensor([in_vocab[BOS]] + input_seq + [out_vocab[EOS]], dtype=tf.int64)\n",
        "    input_seq = tf.expand_dims(input_seq, axis=0)\n",
        "\n",
        "    enc_output, enc_state = encoder(input_seq)\n",
        "    dec_input = tf.expand_dims([out_vocab[BOS]], 0)  # Начальный ввод для декодера\n",
        "    output_seq = []\n",
        "\n",
        "    for t in range(max_length):\n",
        "        dec_output, enc_state = decoder(dec_input, enc_state)\n",
        "        predicted_id = tf.argmax(dec_output[0, -1]).numpy()\n",
        "\n",
        "        if predicted_id == out_vocab[EOS]:  # Остановитесь, если предсказан EOS\n",
        "            break\n",
        "\n",
        "        output_seq.append(predicted_id)\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return output_seq\n",
        "\n",
        "# Загружаем данные\n",
        "data = load_data()\n",
        "\n",
        "# Чистим и предобрабатываем данные\n",
        "max_length = 25  # Определяем максимальную длину примеров\n",
        "in_tokens, out_tokens, in_seqs, out_seqs = preprocess_data(data, max_length)\n",
        "in_vocab, in_data = build_vocab(in_tokens, in_seqs)  # Создаем словарь для входных данных\n",
        "out_vocab, out_data = build_vocab(out_tokens, out_seqs)  # Создаем словарь для выходных данных\n",
        "\n",
        "# Сохраняем словари для последующего использования\n",
        "with open(\"./data/in_vocab.pkl\", \"wb\") as fp:\n",
        "    pickle.dump(in_vocab, fp)\n",
        "with open(\"./data/out_vocab.pkl\", \"wb\") as fp:\n",
        "    pickle.dump(out_vocab, fp)\n",
        "\n",
        "# Подготавливаем набор данных\n",
        "dataset = tf.data.Dataset.from_tensor_slices((np.array(in_data), np.array(out_data))).shuffle(len(in_data)).batch(64)\n",
        "\n",
        "# Определяем параметры модели\n",
        "embed_size, num_hiddens, num_layers = 200, 200, 3\n",
        "drop_prob, lr, num_epochs = 0.1, 0.005, 30\n",
        "\n",
        "# Инициализируем модели\n",
        "encoder = Encoder(len(in_vocab), embed_size, num_hiddens, num_layers, drop_prob)\n",
        "decoder = Decoder(len(out_vocab), embed_size, num_hiddens, num_layers, drop_prob)\n",
        "\n",
        "# Настраиваем оптимизатор\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "\n",
        "# Обучение\n",
        "train(encoder, decoder, dataset, optimizer, num_epochs, out_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvvYq5XONtFQ",
        "outputId": "a358ad6a-d39c-415c-ecff-2ce651c0ff69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.9644099871317546\n",
            "Epoch 2, Loss: 0.673676331837972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Загрузка словарей\n",
        "with open(\"./data/in_vocab.pkl\", \"rb\") as fp:\n",
        "    in_vocab = pickle.load(fp)\n",
        "with open(\"./data/out_vocab.pkl\", \"rb\") as fp:\n",
        "    out_vocab = pickle.load(fp)\n",
        "\n",
        "embed_size, num_hiddens, num_layers = 200, 200, 3\n",
        "drop_prob = 0.1\n",
        "\n",
        "# Инициализация кодировщика и декодировщика\n",
        "encoder = Encoder(len(in_vocab), embed_size, num_hiddens, num_layers, drop_prob)\n",
        "decoder = Decoder(len(out_vocab), embed_size, num_hiddens, num_layers, drop_prob)\n",
        "\n",
        "# Загрузка параметров\n",
        "encoder.load_weights('./data/params_encoder.weights.h5')\n",
        "decoder.load_weights('./data/params_decoder.weights.h5')\n",
        "\n",
        "# Функция для предсказания с использованием последовательного поиска (beam search)\n",
        "def beam_search_translate(encoder, decoder, input_seq, max_length, beam_width, in_vocab, out_vocab):\n",
        "    # Преобразование входной последовательности в индексы\n",
        "    input_indices = [in_vocab.get(token, in_vocab[PAD]) for token in word_tokenize(input_seq.lower())]\n",
        "    input_tensor = tf.convert_to_tensor([input_indices], dtype=tf.int64)\n",
        "\n",
        "    # Получаем выход из кодировщика\n",
        "    enc_output, enc_state = encoder(input_tensor)\n",
        "\n",
        "    # Начальная последовательность для декодера\n",
        "    dec_input = tf.expand_dims([out_vocab[BOS]], 0)\n",
        "\n",
        "    output_seq = []\n",
        "\n",
        "    # Beam search logic\n",
        "    # Здесь должна быть реализация beam search, которая будет генерировать перевод\n",
        "    # В качестве примера просто возвращаем пустую последовательность\n",
        "    return output_seq\n",
        "\n",
        "# Примеры тестирования\n",
        "test_sentences = [\n",
        "    \"Привет\",\n",
        "    \"Как дела?\",\n",
        "    \"Я люблю программирование.\",\n",
        "    \"Сегодня хорошая погода.\",\n",
        "    \"Где находится библиотека?\"\n",
        "]\n",
        "\n",
        "for sentence in test_sentences:\n",
        "    translation = beam_search_translate(encoder, decoder, sentence, 20, 3, in_vocab, out_vocab)\n",
        "    translated_tokens = [list(out_vocab.keys())[list(out_vocab.values()).index(token)] for token in translation]\n",
        "    print(f\"Перевод: {' '.join(translated_tokens)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaFmr9UVTX-z",
        "outputId": "b0985967-52d3-4054-ac58-fecf3555f200"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Перевод: \n",
            "Перевод: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import io\n",
        "import numpy as np\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from nltk.tokenize import word_tokenize  # Для токенизации русского и персидского\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Определяем теги заполнения, начала и конца\n",
        "PAD, BOS, EOS = '<pad>', '<bos>', '<eos>'\n",
        "\n",
        "# Загружаем данные с русского на персидский\n",
        "def load_data():\n",
        "    with io.open('/content/data/farsi_russian.txt', encoding='utf-8') as f:\n",
        "        lines = f.readlines()\n",
        "    return lines\n",
        "\n",
        "# Предобработка данных в токены\n",
        "def preprocess_data(data, max_length):\n",
        "    in_tokens, out_tokens, in_seqs, out_seqs = [], [], [], []\n",
        "    for st in data:\n",
        "        in_seq, out_seq = st.rstrip().split('\\t')\n",
        "\n",
        "        # Токенизация для русского и персидского\n",
        "        in_seq_tokens = word_tokenize(in_seq.lower())\n",
        "        out_seq_tokens = word_tokenize(out_seq.lower())\n",
        "\n",
        "        if max(len(in_seq_tokens), len(out_seq_tokens)) > max_length - 1:\n",
        "            continue  # Пропускаем предложение, если оно слишком длинное\n",
        "\n",
        "        in_tokens.extend(in_seq_tokens)\n",
        "        out_tokens.extend(out_seq_tokens)\n",
        "        in_seqs.append(in_seq_tokens + [EOS] + [PAD] * (max_length - len(in_seq_tokens) - 1))\n",
        "        out_seqs.append(out_seq_tokens + [EOS] + [PAD] * (max_length - len(out_seq_tokens) - 1))\n",
        "\n",
        "    return in_tokens, out_tokens, in_seqs, out_seqs\n",
        "\n",
        "# Создание словаря из токенов\n",
        "def build_vocab(tokens, seqs):\n",
        "    vocab = collections.Counter(tokens)\n",
        "    vocab = {word: idx for idx, (word, _) in enumerate(vocab.items())}\n",
        "    vocab[PAD] = len(vocab)\n",
        "    vocab[BOS] = len(vocab)\n",
        "    vocab[EOS] = len(vocab)\n",
        "\n",
        "    indices = [[vocab[token] for token in seq] for seq in seqs]\n",
        "    return vocab, indices\n",
        "\n",
        "# Определяем модель Encoder\n",
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers, drop_prob=0):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embed_size)\n",
        "        self.gru = tf.keras.layers.GRU(num_hiddens, return_sequences=True, return_state=True, dropout=drop_prob)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        embedding = self.embedding(inputs)\n",
        "        output, state = self.gru(embedding)\n",
        "        return output, state\n",
        "\n",
        "# Определяем модель Decoder с вниманием\n",
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers, drop_prob=0):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embed_size)\n",
        "        self.gru = tf.keras.layers.GRU(num_hiddens, return_sequences=True, return_state=True, dropout=drop_prob)\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    def call(self, inputs, state):\n",
        "        embedding = self.embedding(inputs)\n",
        "        output, state = self.gru(embedding, initial_state=state)\n",
        "        output = self.fc(output)\n",
        "        return output, state\n",
        "\n",
        "# Определяем функцию потерь\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.equal(real, 0))  # Маскирование токенов PAD\n",
        "    loss_ = tf.keras.losses.sparse_categorical_crossentropy(real, pred, from_logits=True)\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask  # Применить маску\n",
        "    return tf.reduce_mean(loss_)\n",
        "\n",
        "# Обучаем модель\n",
        "def train(encoder, decoder, dataset, optimizer, num_epochs, out_vocab):\n",
        "    losses = []\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for (batch, (in_seq, out_seq)) in enumerate(dataset):\n",
        "            with tf.GradientTape() as tape:\n",
        "                enc_output, enc_state = encoder(in_seq)\n",
        "                dec_input = tf.expand_dims([out_vocab[BOS]] * in_seq.shape[0], 1)  # Начальный ввод для декодера\n",
        "                predictions = []\n",
        "\n",
        "                for t in range(1, out_seq.shape[1]):  # Исключить первый токен\n",
        "                    dec_output, enc_state = decoder(dec_input, enc_state)\n",
        "                    predictions.append(dec_output)\n",
        "                    dec_input = tf.expand_dims(out_seq[:, t], 1)  # Teacher forcing\n",
        "\n",
        "                predictions = tf.concat(predictions, axis=1)\n",
        "                loss = loss_function(out_seq[:, 1:], predictions)  # Исключить первый токен для потерь\n",
        "\n",
        "            total_loss += loss\n",
        "            grads = tape.gradient(loss, encoder.trainable_variables + decoder.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(grads, encoder.trainable_variables + decoder.trainable_variables))\n",
        "\n",
        "        avg_loss = total_loss.numpy() / (batch + 1)\n",
        "        losses.append(avg_loss)\n",
        "        print(f'Epoch {epoch + 1}, Loss: {avg_loss}')\n",
        "\n",
        "    # Сохранение параметров после завершения обучения\n",
        "    encoder.save_weights('./data/params_encoder.weights.h5')\n",
        "    decoder.save_weights('./data/params_decoder.weights.h5')\n",
        "\n",
        "    print(\"Параметры модели успешно сохранены.\")\n",
        "\n",
        "    # Визуализируем потери\n",
        "    plt.plot(losses)\n",
        "    plt.xlabel('Эпохи')\n",
        "    plt.ylabel('Потери')\n",
        "    plt.title('Потери обучения')\n",
        "    plt.grid(True)  # Добавляем сетку для удобства чтения\n",
        "    plt.show()\n",
        "\n",
        "# Функция предсказания с использованием beam search\n",
        "def beam_search_translate(encoder, decoder, input_seq, max_length, beam_width, in_vocab, out_vocab):\n",
        "    input_indices = [in_vocab.get(token, in_vocab[PAD]) for token in word_tokenize(input_seq.lower())]\n",
        "    input_tensor = tf.convert_to_tensor([input_indices], dtype=tf.int64)\n",
        "\n",
        "    enc_output, enc_state = encoder(input_tensor)\n",
        "\n",
        "    # Начальная последовательность для декодера\n",
        "    dec_input = tf.expand_dims([out_vocab[BOS]], 0)\n",
        "    sequences = [[dec_input, 0.0]]  # Каждая последовательность - это [последовательность, вероятность]\n",
        "\n",
        "    for _ in range(max_length):\n",
        "        all_candidates = []\n",
        "        for seq, score in sequences:\n",
        "            dec_output, enc_state = decoder(seq, enc_state)\n",
        "\n",
        "            # Получаем вероятности последнего токена\n",
        "            top_k_probs = tf.nn.softmax(dec_output[:, -1]).numpy()[0]\n",
        "\n",
        "            # Выбираем токены с наивысшими вероятностями\n",
        "            for i in range(beam_width):\n",
        "                predicted_id = np.argsort(top_k_probs)[-1 - i]\n",
        "                candidate = tf.concat([seq, tf.expand_dims(tf.convert_to_tensor([predicted_id]), 0)], axis=1)\n",
        "                candidate_score = score - np.log(top_k_probs[predicted_id])  # Логарифм вероятности\n",
        "                all_candidates.append([candidate, candidate_score])\n",
        "\n",
        "        # Сортируем и оставляем только лучшие `beam_width` кандидатов\n",
        "        ordered = sorted(all_candidates, key=lambda tup: tup[1])\n",
        "        sequences = ordered[:beam_width]\n",
        "\n",
        "    # Извлекаем токены из лучших последовательностей\n",
        "    best_seq = sequences[0][0].numpy().tolist()\n",
        "    return best_seq\n",
        "\n",
        "# Примеры тестирования\n",
        "test_sentences = [\n",
        "    \"Привет\",\n",
        "    \"Как дела?\",\n",
        "    \"Я люблю программирование.\",\n",
        "    \"Сегодня хорошая погода.\",\n",
        "    \"Где находится библиотека?\"\n",
        "]\n",
        "\n",
        "# Загружаем данные\n",
        "data = load_data()\n",
        "\n",
        "# Чистим и предобрабатываем данные\n",
        "max_length = 25  # Определяем максимальную длину примеров\n",
        "in_tokens, out_tokens, in_seqs, out_seqs = preprocess_data(data, max_length)\n",
        "in_vocab, in_data = build_vocab(in_tokens, in_seqs)  # Создаем словарь для входных данных\n",
        "out_vocab, out_data = build_vocab(out_tokens, out_seqs)  # Создаем словарь для выходных данных\n",
        "\n",
        "# Сохраняем словари для последующего использования\n",
        "with open(\"./data/in_vocab.pkl\", \"wb\") as fp:\n",
        "    pickle.dump(in_vocab, fp)\n",
        "with open(\"./data/out_vocab.pkl\", \"wb\") as fp:\n",
        "    pickle.dump(out_vocab, fp)\n",
        "\n",
        "# Подготавливаем набор данных\n",
        "dataset = tf.data.Dataset.from_tensor_slices((np.array(in_data), np.array(out_data))).shuffle(len(in_data)).batch(64)\n",
        "\n",
        "# Определяем параметры модели\n",
        "embed_size, num_hiddens, num_layers = 200, 200, 3\n",
        "drop_prob, lr, num_epochs = 0.1, 0.005, 30\n",
        "\n",
        "# Инициализируем модели\n",
        "encoder = Encoder(len(in_vocab), embed_size, num_hiddens, num_layers, drop_prob)\n",
        "decoder = Decoder(len(out_vocab), embed_size, num_hiddens, num_layers, drop_prob)\n",
        "\n",
        "# Настраиваем оптимизатор\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "\n",
        "# Обучение\n",
        "train(encoder, decoder, dataset, optimizer, num_epochs, out_vocab)\n",
        "\n",
        "# Тестирование перевода\n",
        "# Обновленный код для тестирования перевода\n",
        "for sentence in test_sentences:\n",
        "    translated_indices = beam_search_translate(encoder, decoder, sentence, max_length, beam_width=5, in_vocab=in_vocab, out_vocab=out_vocab)\n",
        "\n",
        "    translated_sentence = ' '.join([\n",
        "        token for index in translated_indices\n",
        "        if index not in [out_vocab[PAD], out_vocab[BOS], out_vocab[EOS]]\n",
        "        for token in [next((k for k, v in out_vocab.items() if v == index), None)]\n",
        "        if token is not None\n",
        "    ])\n",
        "\n",
        "    print(f'Исходное предложение: \"{sentence}\" -> Перевод: \"{translated_sentence}\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6xpdsJDVaQge",
        "outputId": "41e928be-63c7-445b-9a75-3278b94b6769"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 3.4898096720377603\n",
            "Epoch 2, Loss: 0.6274043321609497\n",
            "Epoch 3, Loss: 0.4596826235453288\n",
            "Epoch 4, Loss: 0.40455543994903564\n",
            "Epoch 5, Loss: 0.3722076416015625\n",
            "Epoch 6, Loss: 0.3551764090855916\n",
            "Epoch 7, Loss: 0.34205671151479083\n",
            "Epoch 8, Loss: 0.3281628092130025\n",
            "Epoch 9, Loss: 0.323649525642395\n",
            "Epoch 10, Loss: 0.3151133457819621\n",
            "Epoch 11, Loss: 0.3081246217091878\n",
            "Epoch 12, Loss: 0.3015389045079549\n",
            "Epoch 13, Loss: 0.29399339358011883\n",
            "Epoch 14, Loss: 0.2845999399820964\n",
            "Epoch 15, Loss: 0.27768083413441974\n",
            "Epoch 16, Loss: 0.2685300310452779\n",
            "Epoch 17, Loss: 0.2611059943834941\n",
            "Epoch 18, Loss: 0.25387807687123615\n",
            "Epoch 19, Loss: 0.24483172098795572\n",
            "Epoch 20, Loss: 0.23589624961217245\n",
            "Epoch 21, Loss: 0.22744309902191162\n",
            "Epoch 22, Loss: 0.219038188457489\n",
            "Epoch 23, Loss: 0.20996177196502686\n",
            "Epoch 24, Loss: 0.20146588484446207\n",
            "Epoch 25, Loss: 0.19269015391667685\n",
            "Epoch 26, Loss: 0.18402047952016196\n",
            "Epoch 27, Loss: 0.17687034606933594\n",
            "Epoch 28, Loss: 0.16869187355041504\n",
            "Epoch 29, Loss: 0.16175450881322226\n",
            "Epoch 30, Loss: 0.1550313631693522\n",
            "Параметры модели успешно сохранены.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "[243, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242] is not in list",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-b78a832b20e1>\u001b[0m in \u001b[0;36m<cell line: 204>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_sentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0mtranslated_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeam_search_translate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0min_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m     \u001b[0mtranslated_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_vocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_vocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtranslated_indices\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout_vocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPAD\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_vocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBOS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_vocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEOS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Исходное предложение: \"{sentence}\" -> Перевод: \"{translated_sentence}\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-b78a832b20e1>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_sentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0mtranslated_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeam_search_translate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0min_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m     \u001b[0mtranslated_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_vocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_vocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtranslated_indices\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout_vocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPAD\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_vocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBOS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_vocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEOS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Исходное предложение: \"{sentence}\" -> Перевод: \"{translated_sentence}\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: [243, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242, 242] is not in list"
          ]
        }
      ]
    }
  ]
}