{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1a1ZTIL3uWEGbTxJ/Vm1Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodeHunterOfficial/AI_DataMining/blob/main/NLP/Lesson%202.%20%20%D0%92%D0%B5%D0%BA%D1%82%D0%BE%D1%80%D0%BD%D1%8B%D0%B5_%D0%BF%D1%80%D0%B5%D0%B4%D1%81%D1%82%D0%B0%D0%B2%D0%BB%D0%B5%D0%BD%D0%B8%D1%8F_%D1%81%D0%BB%D0%BE%D0%B2_(Word2Vec%2CGloVe%2CELMo%2CSkip_Gram)/2_0_6_Unigram_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Unigram-модель в обработке естественного языка**\n",
        "\n",
        "\n",
        "\n",
        "#### Введение\n",
        "\n",
        "В обработке естественного языка (NLP) модели вероятностей играют ключевую роль в решении различных задач, таких как классификация текста, анализ тональности, генерация текста и другие. Одной из базовых моделей является **unigram-модель**. Она является одной из самых простых вероятностных моделей для языковых данных, и часто используется как базовая линия для более сложных методов.\n",
        "\n",
        "Unigram-модель — это статистическая модель языка, которая предполагает, что каждое слово в предложении или тексте появляется независимо от других слов. Это означает, что вероятность появления каждого слова в предложении зависит только от его собственной вероятности, а не от контекста или последовательности предыдущих слов.\n",
        "\n",
        "\n",
        "\n",
        "#### 1. Что такое Unigram?\n",
        "\n",
        "**Unigram** (с латинского *uni* — один) — это модель, где каждый элемент (слово) рассматривается отдельно, без учета контекста других слов. В этой модели вероятность появления слова в тексте не зависит от предыдущих слов.\n",
        "\n",
        "Математически unigram-модель описывается как:\n",
        "\n",
        "$$\n",
        "P(w_1, w_2, \\dots, w_n) = \\prod_{i=1}^{n} P(w_i)\n",
        "$$\n",
        "\n",
        "Здесь:\n",
        "\n",
        "- $w_1, w_2, \\dots, w_n$ — слова в предложении.\n",
        "- $P(w_i)$ — вероятность появления слова $w_i$.\n",
        "\n",
        "Это выражение показывает, что вероятность наблюдения всего текста (последовательности слов) в модели unigram является произведением вероятностей каждого слова в этой последовательности, предполагая, что слова независимы друг от друга.\n",
        "\n",
        "#### 2. Как вычисляется вероятность для unigram-модели?\n",
        "\n",
        "Для вычисления вероятности появления слова $w_i$ в тексте нам нужно рассчитать его частоту появления в языке.\n",
        "\n",
        "Пусть у нас есть корпус текста, содержащий $N$ слов. Если слово $w_i$ появляется $c(w_i)$ раз, то вероятность появления этого слова в unigram-модели можно вычислить как:\n",
        "\n",
        "$$\n",
        "P(w_i) = \\frac{c(w_i)}{N}\n",
        "$$\n",
        "\n",
        "где:\n",
        "\n",
        "- $c(w_i)$ — количество появлений слова $w_i$ в корпусе.\n",
        "- $N$ — общее количество слов в корпусе (то есть сумма всех частот слов).\n",
        "\n",
        "Таким образом, вероятность каждого слова пропорциональна его частоте в корпусе текста.\n",
        "\n",
        "#### 3. Пример вычисления вероятности с использованием unigram-модели\n",
        "\n",
        "Предположим, у нас есть небольшой корпус из 10 слов:\n",
        "\n",
        "$$\n",
        "\\text{\"мать\", \"папа\", \"дочка\", \"мать\", \"папа\", \"мать\", \"дочка\", \"папа\", \"папа\", \"дочка\"}\n",
        "$$\n",
        "\n",
        "- Общее количество слов в корпусе $N = 10$.\n",
        "- Частоты слов:\n",
        "  - \"мать\" — 3 раза.\n",
        "  - \"папа\" — 4 раза.\n",
        "  - \"дочка\" — 3 раза.\n",
        "\n",
        "Теперь мы можем вычислить вероятность каждого слова в unigram-модели:\n",
        "\n",
        "$$\n",
        "P(\\text{\"мать\"}) = \\frac{3}{10} = 0.3\n",
        "$$\n",
        "$$\n",
        "P(\\text{\"папа\"}) = \\frac{4}{10} = 0.4\n",
        "$$\n",
        "$$\n",
        "P(\\text{\"дочка\"}) = \\frac{3}{10} = 0.3\n",
        "$$\n",
        "\n",
        "Таким образом, мы можем использовать эти вероятности для моделирования текста с помощью unigram-модели.\n",
        "\n",
        "\n",
        "\n",
        "#### 4. Применение unigram-модели\n",
        "\n",
        "Unigram-модели могут использоваться в различных задачах обработки естественного языка. Рассмотрим несколько примеров:\n",
        "\n",
        "1. **Классификация текста**:\n",
        "   В задаче классификации текста (например, спам/не-спам) можно использовать unigram-модель для оценки вероятности каждого слова, встречающегося в тексте. На основе этих вероятностей можно построить классификатор, который будет оценивать вероятность того, что сообщение является спамом.\n",
        "\n",
        "2. **Генерация текста**:\n",
        "   Unigram-модель также используется для генерации случайных текстов. Генерация осуществляется путем последовательного выбора слов на основе их вероятностей. Например, для слов, таких как \"мать\", \"папа\" и \"дочка\", модель может случайным образом сгенерировать последовательность, исходя из заданных вероятностей.\n",
        "\n",
        "3. **Прогнозирование следующего слова**:\n",
        "   Хотя unigram-модель не учитывает контекст предыдущих слов, она все равно может использоваться для простого прогнозирования следующего слова на основе вероятностей отдельных слов. Например, модель может предсказать, что вероятнее всего следующее слово будет \"папа\", если это слово появляется чаще в тексте.\n",
        "\n",
        "\n",
        "\n",
        "#### 5. Ограничения unigram-модели\n",
        "\n",
        "Несмотря на свою простоту и эффективность в определенных задачах, unigram-модель имеет ряд ограничений:\n",
        "\n",
        "1. **Отсутствие контекста**:\n",
        "   Unigram-модель не учитывает контекст слов в предложении, что делает её довольно примитивной. Например, слова с одинаковой частотой появления могут иметь разные значения в зависимости от контекста (например, слово \"банк\" может означать \"финансовое учреждение\" или \"берег реки\").\n",
        "\n",
        "2. **Неэффективность для сложных задач**:\n",
        "   В задачах, где требуется учитывать порядок слов или сложные зависимости между ними (например, в машинном переводе или анализе тональности), unigram-модель может быть недостаточной.\n",
        "\n",
        "3. **Вредоносные эффекты редких слов**:\n",
        "   В unigram-модели редко встречающиеся слова (которые имеют низкую вероятность) могут затмевать более важные слова, особенно если корпус ограничен.\n",
        "\n",
        "\n",
        "\n",
        "#### 6. Улучшения и расширения unigram-модели\n",
        "\n",
        "Для улучшения unigram-модели и учета контекста можно использовать более сложные модели, такие как:\n",
        "\n",
        "- **Bigram-модель**: В этой модели вероятность каждого слова зависит от предыдущего слова, то есть учитывается пара слов.\n",
        "  \n",
        "  $$\n",
        "  P(w_1, w_2, \\dots, w_n) = \\prod_{i=1}^{n} P(w_i \\mid w_{i-1})\n",
        "  $$\n",
        "\n",
        "- **Trigram-модель**: Эта модель учитывает три слова (предыдущее и два предыдущих), что позволяет более точно моделировать контекст.\n",
        "\n",
        "- **Модели с нейронными сетями**: Современные методы, такие как LSTM или трансформеры, могут учитывать длинные зависимости в тексте и обеспечивать гораздо более точные прогнозы.\n",
        "\n",
        "\n",
        "\n",
        "#### Заключение\n",
        "\n",
        "Unigram-модель представляет собой простую и эффективную модель для статистического анализа текста, которая может служить хорошей отправной точкой в задачах обработки естественного языка. Несмотря на свою ограниченность в учете контекста, она часто используется как базовая модель для сравнения с более сложными методами.\n",
        "\n",
        "Основное преимущество unigram-модели — это её простота и скорость, что делает её подходящей для быстрого анализа текстовых данных. Тем не менее, для более сложных приложений, таких как машинный перевод или анализ настроений, стоит использовать более продвинутые модели, которые учитывают порядок слов и их контекст."
      ],
      "metadata": {
        "id": "1TcHi22qRVWm"
      }
    }
  ]
}