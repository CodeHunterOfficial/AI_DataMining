{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOp5jnURPpalV4ZT8dWTDwi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodeHunterOfficial/AI_DataMining/blob/main/NLP/Lesson%208.%20Classification/3_0_1_%D0%9D%D0%B0%D0%B8%D0%B2%D0%BD%D1%8B%D0%B9_%D0%B1%D0%B0%D0%B9%D0%B5%D1%81%D0%BE%D0%B2%D1%81%D0%BA%D0%B8%D0%B9_%D0%BA%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%82%D0%BE%D1%80_(Naive_Bayes).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Наивный байесовский классификатор (Naive Bayes)\n",
        "\n",
        "\n",
        "##Введение\n",
        "\n",
        "Наивный байесовский классификатор (Naive Bayes) — это простая, но мощная модель машинного обучения, часто применяемая для задач классификации в обработке естественного языка (NLP). Примеры таких задач включают классификацию текста, фильтрацию спама, анализ тональности и распознавание языка.\n",
        "\n",
        "Модель основывается на **теореме Байеса** и предполагает, что признаки (например, слова в тексте) условно независимы друг от друга. Хотя это предположение редко выполняется на практике, оно существенно упрощает вычисления и часто даёт хорошие результаты.\n",
        "\n",
        "\n",
        "\n",
        "#### Теорема Байеса: Математическая основа\n",
        "\n",
        "Основой модели является теорема Байеса:\n",
        "\n",
        "$$\n",
        "P(C | X) = \\frac{P(X | C) \\cdot P(C)}{P(X)},\n",
        "$$\n",
        "\n",
        "где:\n",
        "- $P(C | X)$ — апостериорная вероятность класса $C$, то есть вероятность того, что объект относится к классу $C$, при наличии наблюдаемых данных $X$.\n",
        "- $P(X | C)$ — правдоподобие данных $X$ при условии, что объект принадлежит классу $C$.\n",
        "- $P(C)$ — априорная вероятность класса $C$, то есть вероятность того, что объект принадлежит $C$ до учета данных.\n",
        "- $P(X)$ — маргинальная вероятность данных $X$, которая служит нормирующей константой.\n",
        "\n",
        "Наивный байесовский классификатор упрощает эту теорему двумя ключевыми допущениями:\n",
        "1. **Условная независимость признаков**: Признаки $X_1, X_2, ..., X_n$ независимы при условии класса $C$.\n",
        "2. **Дискретность признаков** (для мультиномиального варианта): Например, слова в тексте можно представлять как дискретные частоты.\n",
        "\n",
        "С учетом первого предположения правдоподобие $P(X | C)$ раскладывается как:\n",
        "\n",
        "$$\n",
        "P(X | C) = P(X_1, X_2, ..., X_n | C) = \\prod_{i=1}^{n} P(X_i | C),\n",
        "$$\n",
        "\n",
        "где $X_i$ — отдельный признак (например, слово).\n",
        "\n",
        "\n",
        "\n",
        "#### Алгоритм классификации\n",
        "\n",
        "1. **Обучение**:\n",
        "   - Оценить априорные вероятности классов:\n",
        "$$\n",
        "     P(C_k) = \\frac{\\text{число объектов класса } C_k}{\\text{общее число объектов}}.\n",
        "$$\n",
        "   - Оценить условные вероятности признаков $P(X_i | C_k)$:\n",
        "$$\n",
        "     P(X_i | C_k) = \\frac{\\text{число появления } X_i \\text{ в классах } C_k + \\alpha}{\\text{общее число признаков в } C_k + \\alpha V},\n",
        "$$\n",
        "     где $V$ — размер словаря (количество уникальных признаков), а $\\alpha > 0$ — сглаживающий параметр Лапласа (обычно $\\alpha = 1$).\n",
        "\n",
        "2. **Классификация**:\n",
        "   - Для нового объекта вычисляется апостериорная вероятность для каждого класса $C_k$:\n",
        "$$\n",
        "     P(C_k | X) \\propto P(C_k) \\prod_{i=1}^{n} P(X_i | C_k).\n",
        "$$\n",
        "   - Объект относится к классу с максимальной апостериорной вероятностью:\n",
        "$$\n",
        "     \\hat{C} = \\arg\\max_{C_k} P(C_k | X).\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "#### Применение в NLP\n",
        "\n",
        "##### Задача классификации текста\n",
        "Рассмотрим пример задачи — классификацию текста на основе анализа тональности (положительный или отрицательный отзыв).\n",
        "\n",
        "1. **Подготовка данных**:\n",
        "   - Создайте корпус текстов, где каждый текст помечен как «положительный» или «отрицательный».\n",
        "   - Постройте словарь $V$ из уникальных слов в корпусе.\n",
        "\n",
        "2. **Представление текста**:\n",
        "   - Текст преобразуется в вектор признаков $X = (X_1, X_2, ..., X_n)$, где $X_i$ — количество вхождений $i$-го слова из словаря $V$.\n",
        "\n",
        "3. **Обучение модели**:\n",
        "   - Вычислите априорные вероятности классов $P(\\text{положительный})$ и $P(\\text{отрицательный})$.\n",
        "   - Оцените вероятности $P(\\text{слово}_i | \\text{положительный})$ и $P(\\text{слово}_i | \\text{отрицательный})$ с учетом сглаживания.\n",
        "\n",
        "4. **Классификация нового текста**:\n",
        "   - Представьте текст как вектор признаков.\n",
        "   - Вычислите вероятность $P(C | X)$ для каждого класса и выберите наиболее вероятный.\n",
        "\n",
        "#### Преимущества и недостатки\n",
        "\n",
        "**Преимущества**:\n",
        "- Простота и скорость обучения.\n",
        "- Хорошо работает с разреженными данными (например, мешком слов).\n",
        "- Требует небольшого объёма данных для начального обучения.\n",
        "\n",
        "**Недостатки**:\n",
        "- Предположение условной независимости редко выполняется в реальных данных.\n",
        "- Плохо работает с длинными зависимостями в тексте.\n",
        "- Чувствителен к редким словам (можно частично решить с помощью сглаживания).\n",
        "\n",
        "\n",
        "\n",
        "#### Расширения Naive Bayes\n",
        "\n",
        "1. **Мультиномиальный наивный Байес**:\n",
        "   - Используется для текстовых данных, где признаки — это частоты слов.\n",
        "2. **Бернуллиевский наивный Байес**:\n",
        "   - Подходит для двоичных данных (например, слово присутствует или отсутствует).\n",
        "3. **Гауссовский наивный Байес**:\n",
        "   - Применяется для непрерывных данных, предполагая нормальное распределение признаков.\n",
        "\n",
        "\n",
        "\n",
        "##Пример\n",
        "\n",
        "#### Шаг 1: Исходные данные\n",
        "\n",
        "Представим, что мы хотим классифицировать отзывы как **Положительные** или **Отрицательные**. У нас есть следующие данные:\n",
        "\n",
        "| **Текст**               | **Класс**       |\n",
        "|--|--|\n",
        "| \"погода сегодня отличная\" | Положительный  |\n",
        "| \"ужасный день\"           | Отрицательный  |\n",
        "| \"отличный день\"          | Положительный  |\n",
        "| \"ужасная погода\"         | Отрицательный  |\n",
        "\n",
        "\n",
        "\n",
        "#### Шаг 2: Словарь\n",
        "\n",
        "Сначала составим словарь из всех уникальных слов в этих текстах:\n",
        "\n",
        "$$\n",
        "V = \\{\\text{\"погода\", \"сегодня\", \"отличная\", \"ужасный\", \"день\", \"ужасная\", \"отличный\"}\\}.\n",
        "$$\n",
        "\n",
        "Размер словаря $ |V| = 7 $ (в нём 7 уникальных слов).\n",
        "\n",
        "\n",
        "\n",
        "#### Шаг 3: Априорные вероятности\n",
        "\n",
        "**Априорные вероятности** ($P(C_k)$) показывают вероятность принадлежности текста к тому или иному классу **до учёта содержания текста**. Рассчитаем их на основе обучающего набора:\n",
        "\n",
        "1. Общее количество текстов:\n",
        "$$\n",
        "   \\text{Всего текстов} = 4.\n",
        "$$\n",
        "\n",
        "2. Количество текстов в каждом классе:\n",
        "   - Положительный ($C = \\text{Положительный}$): 2 текста.\n",
        "   - Отрицательный ($C = \\text{Отрицательный}$): 2 текста.\n",
        "\n",
        "3. Априорные вероятности:\n",
        "$$\n",
        "   P(\\text{Положительный}) = \\frac{\\text{Число положительных текстов}}{\\text{Всего текстов}} = \\frac{2}{4} = 0.5.\n",
        "$$\n",
        "$$\n",
        "   P(\\text{Отрицательный}) = \\frac{\\text{Число отрицательных текстов}}{\\text{Всего текстов}} = \\frac{2}{4} = 0.5.\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "#### Шаг 4: Условные вероятности\n",
        "\n",
        "Теперь вычислим вероятность каждого слова при условии, что текст принадлежит тому или иному классу ($P(\\text{слово}_i | C)$). Используем сглаживание Лапласа ($\\alpha = 1$) для избежания нулевых вероятностей.\n",
        "\n",
        "1. **Сглаживание Лапласа**:\n",
        "$$\n",
        "   P(\\text{слово}_i | C_k) = \\frac{\\text{Частота слова}_i + \\alpha}{\\text{Общее количество слов в классе} + \\alpha |V|},\n",
        "$$\n",
        "   где $|V|$ — размер словаря (количество уникальных слов).\n",
        "\n",
        "2. Подсчёт частоты слов в текстах:\n",
        "   - **Для положительных текстов** (\"погода сегодня отличная\", \"отличный день\"):\n",
        "     - Слова: {\"погода\": 1, \"сегодня\": 1, \"отличная\": 1, \"отличный\": 1, \"день\": 1}.\n",
        "     - Общее количество слов: $5$.\n",
        "   - **Для отрицательных текстов** (\"ужасный день\", \"ужасная погода\"):\n",
        "     - Слова: {\"ужасный\": 1, \"день\": 1, \"ужасная\": 1, \"погода\": 1}.\n",
        "     - Общее количество слов: $4$.\n",
        "\n",
        "3. Вероятности для положительного класса:\n",
        "$$\n",
        "   P(\\text{\"погода\"} | \\text{Положительный}) = \\frac{1 + 1}{5 + 7} = \\frac{2}{12} = 0.167.\n",
        "$$\n",
        "$$\n",
        "   P(\\text{\"ужасный\"} | \\text{Положительный}) = \\frac{0 + 1}{5 + 7} = \\frac{1}{12} = 0.083.\n",
        "$$\n",
        "   Аналогично вычисляем для остальных слов.\n",
        "\n",
        "4. Вероятности для отрицательного класса:\n",
        "$$\n",
        "   P(\\text{\"ужасный\"} | \\text{Отрицательный}) = \\frac{1 + 1}{4 + 7} = \\frac{2}{11} \\approx 0.182.\n",
        "$$\n",
        "$$\n",
        "   P(\\text{\"погода\"} | \\text{Отрицательный}) = \\frac{1 + 1}{4 + 7} = \\frac{2}{11} \\approx 0.182.\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "#### Шаг 5: Классификация нового текста\n",
        "\n",
        "Допустим, мы хотим классифицировать новый текст: **\"ужасная погода\"**.\n",
        "\n",
        "1. Представление текста как набора слов:\n",
        "   - Слова: {\"ужасная\", \"погода\"}.\n",
        "\n",
        "2. Вычисление апостериорных вероятностей ($P(C_k | X)$) для каждого класса.\n",
        "\n",
        "   - Для $C = \\text{Положительный}$:\n",
        "$$\n",
        "     P(\\text{Положительный} | X) \\propto P(\\text{Положительный}) \\cdot P(\\text{\"ужасная\"} | \\text{Положительный}) \\cdot P(\\text{\"погода\"} | \\text{Положительный}).\n",
        "$$\n",
        "     Подставляем:\n",
        "$$\n",
        "     P(\\text{Положительный}) = 0.5, \\quad P(\\text{\"ужасная\"} | \\text{Положительный}) = 0.083, \\quad P(\\text{\"погода\"} | \\text{Положительный}) = 0.167.\n",
        "$$\n",
        "$$\n",
        "     P(\\text{Положительный} | X) \\propto 0.5 \\cdot 0.083 \\cdot 0.167 \\approx 0.007.\n",
        "$$\n",
        "\n",
        "   - Для $C = \\text{Отрицательный}$:\n",
        "$$\n",
        "     P(\\text{Отрицательный} | X) \\propto P(\\text{Отрицательный}) \\cdot P(\\text{\"ужасная\"} | \\text{Отрицательный}) \\cdot P(\\text{\"погода\"} | \\text{Отрицательный}).\n",
        "$$\n",
        "     Подставляем:\n",
        "$$\n",
        "     P(\\text{Отрицательный}) = 0.5, \\quad P(\\text{\"ужасная\"} | \\text{Отрицательный}) = 0.182, \\quad P(\\text{\"погода\"} | \\text{Отрицательный}) = 0.182.\n",
        "$$\n",
        "$$\n",
        "     P(\\text{Отрицательный} | X) \\propto 0.5 \\cdot 0.182 \\cdot 0.182 \\approx 0.016.\n",
        "$$\n",
        "\n",
        "3. Нормализуем вероятности (чтобы получить относительные значения):\n",
        "   - $$\n",
        "     P(\\text{Положительный} | X) = \\frac{0.007}{0.007 + 0.016} \\approx 0.304.\n",
        "$$\n",
        "   - $$\n",
        "     P(\\text{Отрицательный} | X) = \\frac{0.016}{0.007 + 0.016} \\approx 0.696.\n",
        "$$\n",
        "\n",
        "4. Результат: текст классифицируется как **Отрицательный** (так как $P(\\text{Отрицательный} | X) > P(\\text{Положительный} | X)$).\n",
        "\n",
        "\n",
        "\n",
        "#### Итог\n",
        "\n",
        "- **Априорные вероятности** определяют начальные шансы каждого класса без учёта содержания текста.\n",
        "- **Условные вероятности** учитывают вклад конкретных слов.\n",
        "- Итоговая классификация основывается на комбинированных вероятностях, где учитываются как априорные, так и данные текста.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ixDi4zxjFm7D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UulTXKVn_lgU",
        "outputId": "1abdcb00-c5ba-446e-9ef4-87588a5c33ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.0\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n",
            "F1 Score: 0.0\n",
            "Confusion Matrix:\n",
            " [[0 2]\n",
            " [0 0]]\n",
            "Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Отрицательный       0.00      0.00      0.00       2.0\n",
            "Положительный       0.00      0.00      0.00       0.0\n",
            "\n",
            "     accuracy                           0.00       2.0\n",
            "    macro avg       0.00      0.00      0.00       2.0\n",
            " weighted avg       0.00      0.00      0.00       2.0\n",
            "\n",
            "Текст: ужасная погода -> Класс: Отрицательный\n",
            "Текст: отличный день -> Класс: Положительный\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
        "\n",
        "# Увеличенный набор данных\n",
        "texts = [\n",
        "    \"погода сегодня отличная\",  # Положительный\n",
        "    \"ужасный день\",             # Отрицательный\n",
        "    \"отличный день\",            # Положительный\n",
        "    \"ужасная погода\",           # Отрицательный\n",
        "    \"замечательный день\",       # Положительный\n",
        "    \"плохая погода\",            # Отрицательный\n",
        "    \"я люблю хорошую погоду\",   # Положительный\n",
        "    \"ненавижу дождь\",           # Отрицательный\n",
        "]\n",
        "\n",
        "labels = [\"Положительный\", \"Отрицательный\", \"Положительный\", \"Отрицательный\",\n",
        "          \"Положительный\", \"Отрицательный\", \"Положительный\", \"Отрицательный\"]\n",
        "\n",
        "# Векторизация текста\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(texts)\n",
        "\n",
        "# Разделение на обучение и тестирование\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.25, random_state=42)\n",
        "\n",
        "# Обучение модели\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Прогнозирование и оценка\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Оценка моделей\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, pos_label=\"Положительный\", average='binary')\n",
        "recall = recall_score(y_test, y_pred, pos_label=\"Положительный\", average='binary')\n",
        "f1 = f1_score(y_test, y_pred, pos_label=\"Положительный\", average='binary')\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Прогнозирование нового текста\n",
        "new_texts = [\"ужасная погода\", \"отличный день\"]\n",
        "new_X = vectorizer.transform(new_texts)\n",
        "predictions = model.predict(new_X)\n",
        "\n",
        "for text, label in zip(new_texts, predictions):\n",
        "    print(f\"Текст: {text} -> Класс: {label}\")"
      ]
    }
  ]
}