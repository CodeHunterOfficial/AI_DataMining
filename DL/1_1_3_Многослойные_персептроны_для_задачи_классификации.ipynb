{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNEu+VLNOLYD0K2iHGFrEK5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodeHunterOfficial/AI_DataMining/blob/main/DL/1_1_3_%D0%9C%D0%BD%D0%BE%D0%B3%D0%BE%D1%81%D0%BB%D0%BE%D0%B9%D0%BD%D1%8B%D0%B5_%D0%BF%D0%B5%D1%80%D1%81%D0%B5%D0%BF%D1%82%D1%80%D0%BE%D0%BD%D1%8B_%D0%B4%D0%BB%D1%8F_%D0%B7%D0%B0%D0%B4%D0%B0%D1%87%D0%B8_%D0%BA%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%86%D0%B8%D0%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Многослойные персептроны для задачи классификации\n",
        "\n",
        "## Введение\n",
        "\n",
        "Многослойный персептрон (MLP, от англ. Multilayer Perceptron) — одна из наиболее распространённых архитектур нейронных сетей, используемая для задач классификации, регрессии и других областей. Несмотря на развитие более сложных архитектур, таких как свёрточные сети (CNN) или рекуррентные сети (RNN), MLP остаётся эффективным инструментом благодаря своей универсальности и теоретической основе.\n",
        "\n",
        "MLP состоит из нескольких слоёв нейронов, где каждый нейрон выполняет линейную комбинацию входов, а затем применяет нелинейную активацию. Классификационные задачи подразумевают, что сеть будет предсказывать один из нескольких классов, используя набор входных признаков.\n",
        "\n",
        "### Основные термины:\n",
        "\n",
        "- **Входной слой**: слой, который принимает входные данные (признаки или наблюдения).\n",
        "- **Скрытые слои**: один или несколько слоёв между входным и выходным слоями, которые обрабатывают информацию.\n",
        "- **Выходной слой**: последний слой сети, возвращающий предсказание — класс или вероятность.\n",
        "- **Функция активации**: функция, вводящая нелинейность в модель, позволяя сети решать сложные задачи.\n",
        "- **Функция потерь**: функция, измеряющая, насколько сеть ошибается в своих предсказаниях, и используемая для обновления весов.\n",
        "\n",
        "## Архитектура многослойного персептрона\n",
        "\n",
        "MLP состоит из входного слоя, одного или более скрытых слоёв и выходного слоя. Каждый нейрон внутри слоя связан с каждым нейроном следующего слоя, что делает MLP полностью связанной (fully connected) сетью.\n",
        "\n",
        "Рассмотрим это на примере:\n",
        "\n",
        "1. **Входные данные**: Вектор признаков размером $x = [x_1, x_2, \\dots, x_n]$.\n",
        "2. **Скрытые слои**: Каждый слой содержит несколько нейронов, и каждый нейрон вычисляет взвешенную сумму входных данных с добавлением смещения (bias):\n",
        "   $$\n",
        "   z_j = \\sum_{i=1}^n w_{ij} x_i + b_j\n",
        "   $$\n",
        "   После этого к результату применяется функция активации $\\sigma$, чтобы ввести нелинейность:\n",
        "   $$\n",
        "   a_j = \\sigma(z_j)\n",
        "   $$\n",
        "3. **Выходной слой**: Финальный слой производит одно или несколько предсказаний. В задаче классификации это может быть либо вероятность для каждого класса, либо бинарное решение (например, через сигмоидную функцию).\n",
        "\n",
        "## Функции активации\n",
        "\n",
        "Функции активации добавляют нелинейность в модель, что позволяет решать более сложные задачи, чем линейные модели. Вот несколько популярных функций активации:\n",
        "\n",
        "- **Sigmoid (Сигмоида)**:\n",
        "   $$\n",
        "   \\sigma(x) = \\frac{1}{1 + e^{-x}}\n",
        "   $$\n",
        "   Используется для задач бинарной классификации и возвращает значения в диапазоне [0, 1].\n",
        "\n",
        "- **ReLU (Rectified Linear Unit)**:\n",
        "   $$\n",
        "   \\text{ReLU}(x) = \\max(0, x)\n",
        "   $$\n",
        "   Используется в скрытых слоях. Простой и эффективный выбор, так как помогает решать проблему исчезающего градиента.\n",
        "\n",
        "- **Softmax**:\n",
        "   $$\n",
        "   \\text{Softmax}(z_i) = \\frac{e^{z_i}}{\\sum_{j} e^{z_j}}\n",
        "   $$\n",
        "   Используется в выходном слое для многоклассовой классификации, чтобы предсказать вероятности классов.\n",
        "\n",
        "## Задача классификации\n",
        "\n",
        "Классификация — это задача присвоения одному или нескольким объектам метки (класса) на основе их признаков. Входными данными могут быть любые данные: изображения, текст, временные ряды и т.д. MLP может использоваться для следующих типов классификации:\n",
        "\n",
        "- **Бинарная классификация**: два класса (например, определение, является ли письмо спамом или нет).\n",
        "- **Многоклассовая классификация**: более двух классов (например, распознавание видов цветов).\n",
        "\n",
        "## MLPClassifier в scikit-learn\n",
        "\n",
        "В библиотеке `scikit-learn` имеется класс `MLPClassifier`, который предоставляет реализацию модели многослойного перцептрона для задач классификации. Основные параметры этого класса:\n",
        "\n",
        "1. **hidden_layer_sizes**: Например, `(100,)` — это означает, что модель будет иметь один скрытый слой, содержащий 100 нейронов. Количество слоёв и нейронов в них может существенно влиять на способность модели захватывать сложные зависимости в данных.\n",
        "\n",
        "2. **activation**: `'relu'` — функция активации, используемая в скрытых слоях. ReLU (Rectified Linear Unit) является наиболее распространённым выбором, так как она проста в использовании и помогает избежать проблемы исчезающего градиента.\n",
        "\n",
        "3. **max_iter**: `200` — максимальное количество итераций для обучения модели. Если модель не сойдётся за указанное количество итераций, обучение будет остановлено.\n",
        "\n",
        "4. **random_state**: `42` — этот параметр позволяет контролировать случайность и делает результаты воспроизводимыми. Указывая одно и то же значение, вы можете получить одинаковые результаты при каждом запуске.\n",
        "\n",
        "5. **learning_rate_init**: `0.001` — начальная скорость обучения, которая может быть настроена для оптимизации процесса обучения модели.\n",
        "\n",
        "## Примеры применения MLP для классификации\n",
        "\n",
        "Теперь перейдём к примерам, начиная с простых случаев и постепенно углубляясь в более сложные задачи. Мы рассмотрим, как использовать MLPClassifier для выполнения классификации на различных наборах данных, включая примеры кода и объяснения каждого этапа.\n",
        "\n",
        "### Пример 1: Бинарная классификация\n",
        "\n",
        "(Здесь можно привести пример кода, показывающий, как использовать MLPClassifier для задачи бинарной классификации, например, для определения спама.)\n",
        "\n",
        "### Пример 2: Многоклассовая классификация\n",
        "\n",
        "(В этом разделе можно привести пример использования MLPClassifier для многоклассовой классификации, например, для распознавания цифр из набора данных MNIST.)\n",
        "\n",
        "\n",
        "\n",
        "## Пример 1: Классификация на наборе данных Iris\n",
        "\n",
        "Рассмотрим задачу классификации цветов на базе известного датасета Iris. Этот набор данных содержит 150 примеров, каждый из которых представляет один из трёх видов цветов.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MdWR-U_fFhpr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Шаг 1. Импорт библиотек и загрузка данных\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Загрузка данных\n",
        "iris = load_iris()\n",
        "X = iris.data  # Признаки\n",
        "y = iris.target  # Метки классов\n",
        "\n",
        "# Разделение данных на тренировочную и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Стандартизация данных (приведение к одному масштабу)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "### Шаг 2. Обучение модели MLP\n",
        "\n",
        "# Создание и обучение модели MLP\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(10,), max_iter=1000, random_state=42)\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "'''Здесь мы создали модель с одним скрытым слоем, содержащим 10 нейронов. Мы также установили максимальное количество итераций в 1000.\n",
        "'''\n",
        "### Шаг 3. Оценка модели\n",
        "\n",
        "\n",
        "# Предсказания и оценка\n",
        "y_pred = mlp.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpExFqItGQZX",
        "outputId": "57e0b32c-19d8-4381-924e-ab32e731bd16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ожидается, что точность будет довольно высокой, так как набор данных Iris является простым для решения с помощью MLP.\n",
        "## Пример 2: Применение MLP в NLP (обработка естественного языка)\n",
        "\n",
        "MLP также можно применять для задач обработки текста, например, для классификации текстов (напр., спам или не спам).\n",
        "\n",
        "### Пример: Классификация отзывов на основе текста\n",
        "\n",
        "В этом примере\n",
        "\n",
        " мы классифицируем текстовые отзывы как положительные или отрицательные.\n"
      ],
      "metadata": {
        "id": "QvcG6oHRGQkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Шаг 1. Импорт и подготовка текстовых данных\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Пример текстовых данных\n",
        "texts = [\"The product is great\", \"Very bad experience\", \"I love it\", \"Horrible service\"]\n",
        "labels = [1, 0, 1, 0]  # 1 - положительный отзыв, 0 - отрицательный\n",
        "\n",
        "# Преобразование текста в числовые признаки\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(texts).toarray()\n",
        "\n",
        "# Разделение данных\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "### Шаг 2. Обучение модели MLP\n",
        "\n",
        "# Создание и обучение модели\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(10,), max_iter=500, random_state=42)\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "### Шаг 3. Оценка модели\n",
        "\n",
        "# Предсказания и оценка\n",
        "y_pred = mlp.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wi3TwWC4GZ7z",
        "outputId": "04f77f06-240d-4f04-cf7e-fbfbb7ad4642"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "В этом примере MLP классифицирует текстовые отзывы как положительные или отрицательные на основе их характеристик, представленных через метод TF-IDF (Term Frequency-Inverse Document Frequency).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "N8Us94DlGaIe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задача 1: Классификация спам/не спам (NLP)\n",
        "Мы будем решать задачу бинарной классификации текста — определение, является ли сообщение спамом или нет. Для этого используем простой датасет, а также метод векторизации текста TF-IDF и обучим многослойный персептрон (MLP)."
      ],
      "metadata": {
        "id": "HVTOB9NzJE2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class SpamClassifier:\n",
        "    def __init__(self):\n",
        "        self.vectorizer = TfidfVectorizer()\n",
        "        self.model = MLPClassifier(hidden_layer_sizes=(10,), max_iter=500, random_state=42)\n",
        "\n",
        "    def train(self, data):\n",
        "        df = pd.DataFrame(data)\n",
        "        X = self.vectorizer.fit_transform(df['text']).toarray()\n",
        "        y = df['label']\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "        self.model.fit(X_train, y_train)\n",
        "        y_pred = self.model.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "    def predict(self, new_texts):\n",
        "        X_new = self.vectorizer.transform(new_texts).toarray()\n",
        "        predictions = self.model.predict(X_new)\n",
        "        return predictions\n",
        "\n",
        "# Пример использования:\n",
        "data = {\n",
        "    'text': [\"Free money now!!!\",\n",
        "             \"Hi, let's meet tomorrow\",\n",
        "             \"Cheap loans available\",\n",
        "             \"Your order has been shipped\",\n",
        "             \"You won a lottery!\"],\n",
        "    'label': [1, 0, 1, 0, 1]\n",
        "}\n",
        "\n",
        "spam_classifier = SpamClassifier()\n",
        "spam_classifier.train(data)\n",
        "\n",
        "# Тестирование на новых текстах\n",
        "new_texts = [\"You have won a prize!\", \"Let's schedule a meeting\"]\n",
        "predictions = spam_classifier.predict(new_texts)\n",
        "print(\"Predictions for new texts:\", predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KrroVEcJI8M",
        "outputId": "4354db1b-1ddb-4746-d203-2a2defeaba76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.00\n",
            "Predictions for new texts: [1 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задача 2: Классификация текста по категориям\n",
        "Теперь задача многоклассовой классификации: мы будем классифицировать новости по темам, таким как \"спорт\", \"политика\", \"экономика\". В качестве метода векторизации также используется TF-IDF."
      ],
      "metadata": {
        "id": "vDJOsWAlJPK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class NewsClassifier:\n",
        "    def __init__(self):\n",
        "        self.vectorizer = TfidfVectorizer()\n",
        "        self.model = MLPClassifier(hidden_layer_sizes=(20,), max_iter=500, random_state=42)\n",
        "\n",
        "    def train(self, data):\n",
        "        df = pd.DataFrame(data)\n",
        "        X = self.vectorizer.fit_transform(df['text']).toarray()\n",
        "        y = df['label']\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "        self.model.fit(X_train, y_train)\n",
        "        y_pred = self.model.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "    def predict(self, new_texts):\n",
        "        X_new = self.vectorizer.transform(new_texts).toarray()\n",
        "        predictions = self.model.predict(X_new)\n",
        "        return predictions\n",
        "\n",
        "# Пример использования:\n",
        "data = {\n",
        "    'text': [\n",
        "        \"The football match ended in a draw.\",\n",
        "        \"The president gave a speech on economic reform.\",\n",
        "        \"Stock markets saw a huge rise today.\",\n",
        "        \"The tennis player won his fifth grand slam.\",\n",
        "        \"The government introduced new policies.\"\n",
        "    ],\n",
        "    'label': [0, 1, 2, 0, 1]  # 0 - спорт, 1 - политика, 2 - экономика\n",
        "}\n",
        "\n",
        "news_classifier = NewsClassifier()\n",
        "news_classifier.train(data)\n",
        "\n",
        "# Тестирование на новых текстах\n",
        "new_texts = [\"The basketball game was exciting\", \"New economic measures were introduced\"]\n",
        "predictions = news_classifier.predict(new_texts)\n",
        "print(\"Predictions for new texts:\", predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfn4f3lbJUCy",
        "outputId": "c5f055e3-3944-4cca-b62b-7aea3bfe326f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.00\n",
            "Predictions for new texts: [0 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задача 3: Определение тональности текста (Sentiment Analysis)\n",
        "Эта задача нацелена на анализ тональности текстов — позитивный, негативный или нейтральный отзыв. Мы используем TF-IDF для векторизации текстов и MLP для классификации."
      ],
      "metadata": {
        "id": "tJOuPjosJY75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class SentimentAnalyzer:\n",
        "    def __init__(self):\n",
        "        self.vectorizer = TfidfVectorizer()\n",
        "        self.model = MLPClassifier(hidden_layer_sizes=(15,), max_iter=500, random_state=42)\n",
        "\n",
        "    def train(self, data):\n",
        "        df = pd.DataFrame(data)\n",
        "        X = self.vectorizer.fit_transform(df['text']).toarray()\n",
        "        y = df['label']\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "        self.model.fit(X_train, y_train)\n",
        "        y_pred = self.model.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "    def predict(self, new_texts):\n",
        "        X_new = self.vectorizer.transform(new_texts).toarray()\n",
        "        predictions = self.model.predict(X_new)\n",
        "        return predictions\n",
        "\n",
        "# Пример использования:\n",
        "data = {\n",
        "    'text': [\n",
        "        \"I absolutely love this product!\",\n",
        "        \"This is the worst experience ever.\",\n",
        "        \"I'm very happy with the service.\",\n",
        "        \"I hate this item.\",\n",
        "        \"Not great, but not terrible either.\"\n",
        "    ],\n",
        "    'label': [1, 0, 1, 0, 0]  # 1 - позитивный, 0 - негативный\n",
        "}\n",
        "\n",
        "sentiment_analyzer = SentimentAnalyzer()\n",
        "sentiment_analyzer.train(data)\n",
        "\n",
        "# Тестирование на новых текстах\n",
        "new_texts = [\"I really like this service\", \"This is disappointing\"]\n",
        "predictions = sentiment_analyzer.predict(new_texts)\n",
        "print(\"Predictions for new texts:\", predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gi1_eRKJdUU",
        "outputId": "6b19fceb-6124-4d5f-9049-8575f5cb33e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.00\n",
            "Predictions for new texts: [1 0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задача 4: Классификация сообщений в чатах по настроению (Multiclass Sentiment Analysis)\n",
        "Эта задача немного сложнее — мы будем классифицировать сообщения по трём категориям настроений: позитивные, негативные и нейтральные."
      ],
      "metadata": {
        "id": "6d1kdKgsJith"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class ChatSentimentClassifier:\n",
        "    def __init__(self):\n",
        "        self.vectorizer = TfidfVectorizer()\n",
        "        self.model = MLPClassifier(hidden_layer_sizes=(20,), max_iter=500, random_state=42)\n",
        "\n",
        "    def train(self, data):\n",
        "        df = pd.DataFrame(data)\n",
        "        X = self.vectorizer.fit_transform(df['text']).toarray()\n",
        "        y = df['label']\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "        self.model.fit(X_train, y_train)\n",
        "        y_pred = self.model.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "    def predict(self, new_texts):\n",
        "        X_new = self.vectorizer.transform(new_texts).toarray()\n",
        "        predictions = self.model.predict(X_new)\n",
        "        return predictions\n",
        "\n",
        "# Пример использования:\n",
        "data = {\n",
        "    'text': [\n",
        "        \"I'm so happy today!\",\n",
        "        \"This is really bad.\",\n",
        "        \"Not sure how I feel about this.\",\n",
        "        \"I'm loving it!\",\n",
        "        \"This was a horrible experience.\"\n",
        "    ],\n",
        "    'label': [1, 0, 2, 1, 0]  # 1 - позитивный, 0 - негативный, 2 - нейтральный\n",
        "}\n",
        "\n",
        "chat_sentiment_classifier = ChatSentimentClassifier()\n",
        "chat_sentiment_classifier.train(data)\n",
        "\n",
        "# Тестирование на новых текстах\n",
        "new_texts = [\"This is amazing!\", \"I'm not sure what to think.\", \"This is terrible.\"]\n",
        "predictions = chat_sentiment_classifier.predict(new_texts)\n",
        "print(\"Predictions for new texts:\", predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZdpENrOJoS5",
        "outputId": "920773e4-3b92-40f7-d386-eb8c603f0baf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.00\n",
            "Predictions for new texts: [0 2 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задачи умножения\n",
        "\n",
        "Для решения задачи умножения с использованием многослойного персептрона (MLP), нам нужно сначала подготовить данные для обучения. Задача заключается в том, чтобы обучить модель прогнозировать результат умножения двух чисел."
      ],
      "metadata": {
        "id": "0Uat6VEhKre2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "class MultiplicationMLP:\n",
        "    def __init__(self, hidden_layer_sizes=(128, 128, 128), max_iter=2000):\n",
        "        \"\"\"\n",
        "        Инициализация модели MLP для умножения.\n",
        "\n",
        "        :param hidden_layer_sizes: Кортеж с размерами скрытых слоев.\n",
        "        :param max_iter: Максимальное количество итераций для обучения.\n",
        "        \"\"\"\n",
        "        self.hidden_layer_sizes = hidden_layer_sizes\n",
        "        self.max_iter = max_iter\n",
        "        self.model = MLPRegressor(hidden_layer_sizes=self.hidden_layer_sizes,\n",
        "                                   activation='tanh',\n",
        "                                   max_iter=self.max_iter,\n",
        "                                   random_state=42)\n",
        "\n",
        "    def generate_data(self, start=1, end=20):\n",
        "        \"\"\"\n",
        "        Генерация данных для таблицы умножения.\n",
        "\n",
        "        :param start: Начальное число для генерации (включительно).\n",
        "        :param end: Конечное число для генерации (включительно).\n",
        "        :return: Входные и выходные данные.\n",
        "        \"\"\"\n",
        "        X = []\n",
        "        y = []\n",
        "        for i in range(start, end + 1):\n",
        "            for j in range(start, end + 1):\n",
        "                X.append([i, j])\n",
        "                y.append(i * j)\n",
        "        return np.array(X), np.array(y)\n",
        "\n",
        "    def train(self, X, y):\n",
        "        \"\"\"\n",
        "        Обучение модели на заданных данных.\n",
        "\n",
        "        :param X: Входные данные.\n",
        "        :param y: Выходные данные.\n",
        "        \"\"\"\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "        self.model.fit(X_train, y_train)\n",
        "        y_pred = self.model.predict(X_test)\n",
        "        mse = mean_squared_error(y_test, y_pred)\n",
        "        print(f'MSE на тестовой выборке: {mse}')\n",
        "\n",
        "    def predict(self, a, b):\n",
        "        \"\"\"\n",
        "        Прогнозирование произведения двух чисел.\n",
        "\n",
        "        :param a: Первое число.\n",
        "        :param b: Второе число.\n",
        "        :return: Предсказанное произведение.\n",
        "        \"\"\"\n",
        "        example = np.array([[a, b]])\n",
        "        return self.model.predict(example)[0]\n",
        "\n",
        "# Пример использования\n",
        "if __name__ == \"__main__\":\n",
        "    multiplication_model = MultiplicationMLP()\n",
        "    X, y = multiplication_model.generate_data(start=1, end=20)\n",
        "    multiplication_model.train(X, y)\n",
        "\n",
        "    # Пример предсказания\n",
        "    result = multiplication_model.predict(7, 8)\n",
        "    print(f'Предсказанный результат для 7 * 8: {result}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqayEu_WHH1V",
        "outputId": "bb068b37-5d82-48cc-c442-d31589476aee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE на тестовой выборке: 170.1460629793565\n",
            "Предсказанный результат для 7 * 8: 56.02676660992348\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Заключение\n",
        "\n",
        "Многослойный персептрон — это мощный инструмент для решения задач классификации в различных областях, начиная с простых задач классификации на структурированных данных и заканчивая более сложными задачами, такими как обработка временных рядов и текстов. Он использует нелинейные функции активации и полносвязную архитектуру для построения сложных зависимостей между входными данными и предсказаниями.\n",
        "\n",
        "Хотя для более специализированных задач существуют более сложные модели, такие как CNN для изображений или RNN для временных рядов, MLP продолжает оставаться важной частью арсенала инструментов для решения задач машинного обучения."
      ],
      "metadata": {
        "id": "bXOoSYriKxBe"
      }
    }
  ]
}