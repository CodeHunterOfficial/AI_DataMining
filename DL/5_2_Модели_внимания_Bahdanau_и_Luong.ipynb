{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPbiKSdIxocDi1sFA7Xx374",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodeHunterOfficial/AI_DataMining/blob/main/DL/5_2_%D0%9C%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8_%D0%B2%D0%BD%D0%B8%D0%BC%D0%B0%D0%BD%D0%B8%D1%8F_Bahdanau_%D0%B8_Luong.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Модели внимания Bahdanau и Luong\n",
        "#Модель внимания Bahdanau\n",
        "\n",
        "Модель внимания Bahdanau (или модель soft attention) была предложена Дзяфрагмом Баданау (Dzmitry Bahdanau) и его коллегами в 2015 году в статье \"Neural Machine Translation by Jointly Learning to Align and Translate\". Она направлена на решение проблемы длинных зависимостей в задачах машинного перевода, улучшая традиционные рекуррентные нейронные сети (RNN), которые теряли важную информацию при обработке длинных последовательностей.\n",
        "\n",
        "Основной идеей механизма внимания является выделение наиболее важных частей входной последовательности для каждого элемента выходной последовательности.\n",
        "\n",
        "### Модель машинного перевода с механизмом внимания\n",
        "\n",
        "Модель Bahdanau включает две основные части:\n",
        "1. **Кодировщик** (encoder), который обрабатывает входную последовательность.\n",
        "2. **Декодировщик** (decoder), который генерирует выходную последовательность.\n",
        "\n",
        "#### Кодировщик\n",
        "\n",
        "Кодировщик — это RNN (например, LSTM или GRU), которая обрабатывает последовательность входных токенов. Пусть входная последовательность представлена как:\n",
        "\n",
        "$$\n",
        "X = (x_1, x_2, \\dots, x_T)\n",
        "$$\n",
        "\n",
        "где $x_i$ — это вектор представления i-го токена во входной последовательности, а $T$ — длина последовательности.\n",
        "\n",
        "Кодировщик генерирует скрытые состояния для каждого элемента входной последовательности:\n",
        "\n",
        "$$\n",
        "h_t = \\text{RNN}(h_{t-1}, x_t)\n",
        "$$\n",
        "\n",
        "где $h_t$ — это скрытое состояние на шаге $t$, зависящее от предыдущего состояния $h_{t-1}$ и текущего входа $x_t$.\n",
        "\n",
        "Итоговые скрытые состояния кодировщика $H = (h_1, h_2, \\dots, h_T)$ будут использоваться декодировщиком для генерации выходной последовательности с учетом механизма внимания.\n",
        "\n",
        "#### Декодировщик\n",
        "\n",
        "Декодировщик также является RNN и генерирует последовательность выходных токенов $Y = (y_1, y_2, \\dots, y_N)$, где $y_j$ — это сгенерированный токен на шаге $j$, а $N$ — длина выходной последовательности. Основное отличие модели Bahdanau от традиционного декодера состоит в использовании механизма внимания, который позволяет декодеру сосредоточиться на релевантных частях входной последовательности при каждом шаге.\n",
        "\n",
        "На каждом шаге декодирования декодер обновляет своё скрытое состояние:\n",
        "\n",
        "$$\n",
        "s_j = \\text{RNN}(s_{j-1}, y_{j-1}, c_j)\n",
        "$$\n",
        "\n",
        "где $s_j$ — скрытое состояние декодера на шаге $j$, $y_{j-1}$ — предыдущий сгенерированный токен, а $c_j$ — контекстный вектор, который кодирует информацию о входной последовательности и вычисляется с использованием механизма внимания.\n",
        "\n",
        "#### Механизм внимания\n",
        "\n",
        "Для каждого шага декодирования $j$ контекстный вектор $c_j$ представляет собой взвешенную сумму скрытых состояний кодировщика:\n",
        "\n",
        "$$\n",
        "c_j = \\sum_{t=1}^{T} \\alpha_{jt} h_t\n",
        "$$\n",
        "\n",
        "где $\\alpha_{jt}$ — это вес внимания, который определяет, насколько важно скрытое состояние кодировщика $h_t$ для генерации выходного токена $y_j$.\n",
        "\n",
        "##### Вычисление весов внимания\n",
        "\n",
        "Вес внимания $\\alpha_{jt}$ вычисляется через так называемую **оценочную функцию внимания** (alignment function), которая сопоставляет текущее скрытое состояние декодера $s_{j-1}$ и скрытое состояние кодировщика $h_t$. В модели Bahdanau оценочная функция основана на нейронной сети и выглядит следующим образом:\n",
        "\n",
        "$$\n",
        "e_{jt} = v_a^\\top \\tanh(W_a s_{j-1} + U_a h_t)\n",
        "$$\n",
        "\n",
        "где:\n",
        "- $e_{jt}$ — это ненормализованная оценка внимания (оценка важности состояния $h_t$ для текущего шага декодера),\n",
        "- $W_a$ и $U_a$ — обучаемые матрицы весов,\n",
        "- $v_a$ — обучаемый вектор.\n",
        "\n",
        "Далее оценка внимания нормализуется с помощью softmax:\n",
        "\n",
        "$$\n",
        "\\alpha_{jt} = \\frac{\\exp(e_{jt})}{\\sum_{t'=1}^{T} \\exp(e_{jt'})}\n",
        "$$\n",
        "\n",
        "Таким образом, веса внимания $\\alpha_{jt}$ нормализуются так, что их сумма по всем шагам $t$ будет равна единице:\n",
        "\n",
        "$$\n",
        "\\sum_{t=1}^{T} \\alpha_{jt} = 1\n",
        "$$\n",
        "\n",
        "#### Генерация выхода\n",
        "\n",
        "На каждом шаге декодирования декодер обновляет своё скрытое состояние $s_j$ с учетом предыдущего состояния $s_{j-1}$, предыдущего сгенерированного токена $y_{j-1}$ и контекстного вектора $c_j$. Затем сгенерированный выходной токен $y_j$ вычисляется с помощью функции, которая обычно является линейной трансформацией скрытого состояния декодера:\n",
        "\n",
        "$$\n",
        "y_j = \\text{argmax}(\\text{softmax}(W_o s_j + b_o))\n",
        "$$\n",
        "\n",
        "где $W_o$ и $b_o$ — обучаемые параметры линейной трансформации.\n",
        "\n",
        "### Общий алгоритм\n",
        "\n",
        "1. **Кодировщик**: Пропустить входную последовательность $X = (x_1, x_2, \\dots, x_T)$ через RNN и получить скрытые состояния $H = (h_1, h_2, \\dots, h_T)$.\n",
        "2. **Инициализация декодера**: Инициализировать декодер начальным состоянием $s_0$.\n",
        "3. Для каждого шага $j = 1, 2, \\dots, N$ (где $N$ — длина выходной последовательности):\n",
        "   - Вычислить веса внимания $\\alpha_{jt}$ для каждого состояния кодировщика $h_t$, используя текущее состояние декодера $s_{j-1}$.\n",
        "   - Вычислить контекстный вектор $c_j$ как взвешенную сумму скрытых состояний кодировщика.\n",
        "   - Обновить состояние декодера $s_j = \\text{RNN}(s_{j-1}, y_{j-1}, c_j)$.\n",
        "   - Сгенерировать выходной токен $y_j$, используя текущее состояние декодера $s_j$.\n",
        "\n",
        "### Преимущества модели внимания\n",
        "\n",
        "1. **Гибкость в обработке длинных последовательностей**: Механизм внимания позволяет модели фокусироваться на разных частях входной последовательности, улучшая обработку длинных текстов.\n",
        "2. **Интерпретируемость**: Веса внимания $\\alpha_{jt}$ позволяют интерпретировать, какие части входного текста наиболее важны для генерации каждого выходного токена.\n",
        "3. **Эффективное обучение**: В отличие от классических RNN, модель внимания Bahdanau позволяет быстрее и эффективнее обучаться на задачах с длинными зависимостями.\n",
        "\n",
        "\n",
        "Для того чтобы продемонстрировать, как работает модель Bahdanau на конкретном примере, давай рассмотрим следующую задачу: у нас есть входная последовательность из трёх элементов, и нам нужно сгенерировать выходную последовательность длиной два элемента. Для простоты используем небольшие векторы и округлим значения.\n",
        "\n",
        "### Заданные параметры\n",
        "\n",
        "1. Входная последовательность $X = (x_1, x_2, x_3)$, где:\n",
        "   - $x_1 = [1, 0]$\n",
        "   - $x_2 = [0, 1]$\n",
        "   - $x_3 = [1, 1]$\n",
        "   \n",
        "2. Исходные скрытые состояния кодировщика $H = (h_1, h_2, h_3)$, где:\n",
        "   - $h_1 = [0.5, 0.2]$\n",
        "   - $h_2 = [0.1, 0.4]$\n",
        "   - $h_3 = [0.3, 0.8]$\n",
        "\n",
        "3. Начальное состояние декодера $s_0 = [0.0, 0.0]$.\n",
        "\n",
        "4. Параметры внимания:\n",
        "   - $W_a = \\begin{bmatrix} 0.1 & 0.2 \\\\ 0.3 & 0.4 \\end{bmatrix}$\n",
        "   - $U_a = \\begin{bmatrix} 0.1 & 0.0 \\\\ 0.0 & 0.1 \\end{bmatrix}$\n",
        "   - $v_a = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$\n",
        "\n",
        "### Шаг 1: Вычисление весов внимания для первого выхода ($y_1$)\n",
        "\n",
        "На первом шаге декодирования мы используем начальное состояние декодера $s_0 = [0.0, 0.0]$ для вычисления весов внимания $\\alpha_{1t}$ для каждого скрытого состояния кодировщика $h_t$, где $t = 1, 2, 3$.\n",
        "\n",
        "#### Для $h_1$:\n",
        "$$\n",
        "e_{11} = v_a^\\top \\tanh(W_a s_0 + U_a h_1) = \\begin{bmatrix} 1 & 1 \\end{bmatrix}^\\top \\tanh \\left( \\begin{bmatrix} 0.1 & 0.2 \\\\ 0.3 & 0.4 \\end{bmatrix} \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix} + \\begin{bmatrix} 0.1 & 0.0 \\\\ 0.0 & 0.1 \\end{bmatrix} \\begin{bmatrix} 0.5 \\\\ 0.2 \\end{bmatrix} \\right)\n",
        "$$\n",
        "\n",
        "$$\n",
        "= \\begin{bmatrix} 1 & 1 \\end{bmatrix}^\\top \\tanh \\left( \\begin{bmatrix} 0.05 \\\\ 0.02 \\end{bmatrix} \\right) = 1 \\times \\tanh(0.05) + 1 \\times \\tanh(0.02) \\approx 1 \\times 0.05 + 1 \\times 0.02 = 0.07\n",
        "$$\n",
        "\n",
        "#### Для $h_2$:\n",
        "$$\n",
        "e_{12} = v_a^\\top \\tanh(W_a s_0 + U_a h_2) = \\begin{bmatrix} 1 & 1 \\end{bmatrix}^\\top \\tanh \\left( \\begin{bmatrix} 0.1 & 0.2 \\\\ 0.3 & 0.4 \\end{bmatrix} \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix} + \\begin{bmatrix} 0.1 & 0.0 \\\\ 0.0 & 0.1 \\end{bmatrix} \\begin{bmatrix} 0.1 \\\\ 0.4 \\end{bmatrix} \\right)\n",
        "$$\n",
        "\n",
        "$$\n",
        "= \\begin{bmatrix} 1 & 1 \\end{bmatrix}^\\top \\tanh \\left( \\begin{bmatrix} 0.01 \\\\ 0.04 \\end{bmatrix} \\right) = 1 \\times \\tanh(0.01) + 1 \\times \\tanh(0.04) \\approx 1 \\times 0.01 + 1 \\times 0.04 = 0.05\n",
        "$$\n",
        "\n",
        "#### Для $h_3$:\n",
        "$$\n",
        "e_{13} = v_a^\\top \\tanh(W_a s_0 + U_a h_3) = \\begin{bmatrix} 1 & 1 \\end{bmatrix}^\\top \\tanh \\left( \\begin{bmatrix} 0.1 & 0.2 \\\\ 0.3 & 0.4 \\end{bmatrix} \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix} + \\begin{bmatrix} 0.1 & 0.0 \\\\ 0.0 & 0.1 \\end{bmatrix} \\begin{bmatrix} 0.3 \\\\ 0.8 \\end{bmatrix} \\right)\n",
        "$$\n",
        "\n",
        "$$\n",
        "= \\begin{bmatrix} 1 & 1 \\end{bmatrix}^\\top \\tanh \\left( \\begin{bmatrix} 0.03 \\\\ 0.08 \\end{bmatrix} \\right) = 1 \\times \\tanh(0.03) + 1 \\times \\tanh(0.08) \\approx 1 \\times 0.03 + 1 \\times 0.08 = 0.11\n",
        "$$\n",
        "\n",
        "#### Нормализация весов внимания:\n",
        "\n",
        "Теперь применим softmax, чтобы нормализовать веса внимания:\n",
        "\n",
        "$$\n",
        "\\alpha_{11} = \\frac{\\exp(0.07)}{\\exp(0.07) + \\exp(0.05) + \\exp(0.11)} = \\frac{1.0725}{1.0725 + 1.0513 + 1.1163} \\approx 0.329\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\alpha_{12} = \\frac{\\exp(0.05)}{\\exp(0.07) + \\exp(0.05) + \\exp(0.11)} = \\frac{1.0513}{1.0725 + 1.0513 + 1.1163} \\approx 0.323\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\alpha_{13} = \\frac{\\exp(0.11)}{\\exp(0.07) + \\exp(0.05) + \\exp(0.11)} = \\frac{1.1163}{1.0725 + 1.0513 + 1.1163} \\approx 0.348\n",
        "$$\n",
        "\n",
        "### Шаг 2: Вычисление контекстного вектора $c_1$\n",
        "\n",
        "Контекстный вектор $c_1$ вычисляется как взвешенная сумма скрытых состояний кодировщика:\n",
        "\n",
        "$$\n",
        "c_1 = \\alpha_{11} h_1 + \\alpha_{12} h_2 + \\alpha_{13} h_3\n",
        "$$\n",
        "\n",
        "$$\n",
        "c_1 = 0.329 \\times \\begin{bmatrix} 0.5 \\\\ 0.2 \\end{bmatrix} + 0.323 \\times \\begin{bmatrix} 0.1 \\\\ 0.4 \\end{bmatrix} + 0.348 \\times \\begin{bmatrix} 0.3 \\\\ 0.8 \\end{bmatrix}\n",
        "$$\n",
        "\n",
        "$$\n",
        "c_1 = \\begin{bmatrix} 0.1645 \\\\ 0.0658 \\end{bmatrix} + \\begin{bmatrix} 0.0323 \\\\ 0.1292 \\end{bmatrix} + \\begin{bmatrix} 0.1044 \\\\ 0.2784 \\end{bmatrix} = \\begin{bmatrix} 0.3012 \\\\ 0.4734 \\end{bmatrix}\n",
        "$$\n",
        "\n",
        "### Шаг 3: Обновление состояния декодера $s_1$\n",
        "\n",
        "Теперь обновим состояние декодера с учётом предыдущего состояния $s_0$, предыдущего выхода (пусть $y_0 = 0$) и контекстного вектора $c_1$. Предположим, что декодер — это простая RNN, и функция обновления состояния задаётся следующим образом:\n",
        "\n",
        "$$\n",
        "s_1 = \\tanh(W_s s_0 + U_s y_0 + V_s c_1)\n",
        "$$\n",
        "\n",
        "Пусть:\n",
        "- $W_s = \\begin{bmatrix} 0.5 & 0.1 \\\\ 0.3 & 0.7 \\end{bmatrix}$,\n",
        "- $U_s = \\begin{bmatrix} 0.2 \\\\ 0.1 \\end{bmatrix}$,\n",
        "- $V_s = \\begin{bmatrix} 0.1 & 0.2 \\\\ 0.3 & 0.4 \\end{bmatrix}$.\n",
        "\n",
        "Тогда:\n",
        "\n",
        "$$\n",
        "s_1 = \\tanh \\left( \\begin{bmatrix} 0.5 &\n",
        "\n",
        " 0.1 \\\\ 0.3 & 0.7 \\end{bmatrix} \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix} + \\begin{bmatrix} 0.2 \\\\ 0.1 \\end{bmatrix} \\times 0 + \\begin{bmatrix} 0.1 & 0.2 \\\\ 0.3 & 0.4 \\end{bmatrix} \\begin{bmatrix} 0.3012 \\\\ 0.4734 \\end{bmatrix} \\right)\n",
        "$$\n",
        "\n",
        "$$\n",
        "s_1 = \\tanh \\left( \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix} + \\begin{bmatrix} 0.1 \\times 0.3012 + 0.2 \\times 0.4734 \\\\ 0.3 \\times 0.3012 + 0.4 \\times 0.4734 \\end{bmatrix} \\right) = \\tanh \\left( \\begin{bmatrix} 0.1248 \\\\ 0.3091 \\end{bmatrix} \\right)\n",
        "$$\n",
        "\n",
        "$$\n",
        "s_1 \\approx \\begin{bmatrix} 0.1243 \\\\ 0.2998 \\end{bmatrix}\n",
        "$$\n",
        "\n",
        "### Шаг 4: Генерация первого выхода $y_1$\n",
        "\n",
        "Теперь сгенерируем первый выходной токен $y_1$ с использованием обновлённого состояния декодера $s_1$. Пусть функция генерации выхода задаётся как:\n",
        "\n",
        "$$\n",
        "y_1 = \\text{argmax}(\\text{softmax}(W_o s_1 + b_o))\n",
        "$$\n",
        "\n",
        "Пусть $W_o = \\begin{bmatrix} 1 & -1 \\\\ -1 & 1 \\end{bmatrix}$ и $b_o = \\begin{bmatrix} 0.1 \\\\ 0.2 \\end{bmatrix}$. Тогда:\n",
        "\n",
        "$$\n",
        "y_1 = \\text{softmax} \\left( \\begin{bmatrix} 1 & -1 \\\\ -1 & 1 \\end{bmatrix} \\begin{bmatrix} 0.1243 \\\\ 0.2998 \\end{bmatrix} + \\begin{bmatrix} 0.1 \\\\ 0.2 \\end{bmatrix} \\right)\n",
        "$$\n",
        "\n",
        "$$\n",
        "y_1 = \\text{softmax} \\left( \\begin{bmatrix} 1 \\times 0.1243 - 1 \\times 0.2998 \\\\ -1 \\times 0.1243 + 1 \\times 0.2998 \\end{bmatrix} + \\begin{bmatrix} 0.1 \\\\ 0.2 \\end{bmatrix} \\right)\n",
        "$$\n",
        "\n",
        "$$\n",
        "y_1 = \\text{softmax} \\left( \\begin{bmatrix} -0.1755 + 0.1 \\\\ 0.1755 + 0.2 \\end{bmatrix} \\right) = \\text{softmax} \\left( \\begin{bmatrix} -0.0755 \\\\ 0.3755 \\end{bmatrix} \\right)\n",
        "$$\n",
        "\n",
        "$$\n",
        "y_1 = \\begin{bmatrix} \\frac{\\exp(-0.0755)}{\\exp(-0.0755) + \\exp(0.3755)} \\\\ \\frac{\\exp(0.3755)}{\\exp(-0.0755) + \\exp(0.3755)} \\end{bmatrix} \\approx \\begin{bmatrix} 0.406 \\\\ 0.594 \\end{bmatrix}\n",
        "$$\n",
        "\n",
        "Значение $y_1 = 1$, так как 0.594 больше 0.406.\n",
        "\n",
        "### Шаг 5: Повторение для $y_2$\n",
        "\n",
        "Далее можно повторить процесс для второго токена $y_2$, начиная с обновленного состояния декодера $s_1$.\n",
        "\n",
        "\n",
        "\n",
        "Таким образом, шаг за шагом был продемонстрирован процесс вычисления выхода в модели Bahdanau. Мы прошли через этапы вычисления весов внимания, контекстного вектора, обновления состояния декодера и генерации выхода, что иллюстрирует, как работает механизм внимания в этой модели.\n",
        "\n",
        "Давай реализуем шаги модели внимания Bahdanau на Python. Мы будем использовать библиотеку NumPy для математических вычислений и библиотеку Matplotlib для визуализации внимания на каждом шаге.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "g_P_gMsvb1nZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        },
        "id": "HW2IWReVW8Jf",
        "outputId": "62dd11c5-7294-42fc-8b73-76eaf6951d9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1:\n",
            "Attention Weights: [0.33102814 0.32448069 0.34449117]\n",
            "Context Vector: [0.30130949 0.47159084]\n",
            "Decoder State: [0.1238106  0.27200633]\n",
            "Generated Output: 1\n",
            "\n",
            "\n",
            "Step 2:\n",
            "Attention Weights: [0.33127182 0.32463763 0.34409055]\n",
            "Context Vector: [0.30132684 0.47138186]\n",
            "Decoder State: [0.39145314 0.54165754]\n",
            "Generated Output: 1\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Устанавливаем параметры для визуализации\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Входная последовательность (x1, x2, x3)\n",
        "X = np.array([[1, 0], [0, 1], [1, 1]])\n",
        "\n",
        "# Скрытые состояния кодировщика (h1, h2, h3)\n",
        "H = np.array([[0.5, 0.2], [0.1, 0.4], [0.3, 0.8]])\n",
        "\n",
        "# Начальное состояние декодера\n",
        "s_0 = np.array([0.0, 0.0])\n",
        "\n",
        "# Параметры для вычисления внимания\n",
        "W_a = np.array([[0.1, 0.2], [0.3, 0.4]])\n",
        "U_a = np.array([[0.1, 0.0], [0.0, 0.1]])\n",
        "v_a = np.array([1, 1])\n",
        "\n",
        "# Параметры декодера\n",
        "W_s = np.array([[0.5, 0.1], [0.3, 0.7]])\n",
        "U_s = np.array([0.2, 0.1])\n",
        "V_s = np.array([[0.1, 0.2], [0.3, 0.4]])\n",
        "\n",
        "# Параметры выхода\n",
        "W_o = np.array([[1, -1], [-1, 1]])\n",
        "b_o = np.array([0.1, 0.2])\n",
        "\n",
        "# Softmax функция\n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum(axis=0)\n",
        "\n",
        "# Функция вычисления внимания\n",
        "def attention(s_prev, H):\n",
        "    e = np.zeros(H.shape[0])\n",
        "    for t in range(H.shape[0]):\n",
        "        e[t] = np.dot(v_a, np.tanh(np.dot(W_a, s_prev) + np.dot(U_a, H[t])))\n",
        "    alpha = softmax(e)\n",
        "    return alpha\n",
        "\n",
        "# Функция обновления состояния декодера\n",
        "def update_decoder_state(s_prev, y_prev, c):\n",
        "    return np.tanh(np.dot(W_s, s_prev) + U_s * y_prev + np.dot(V_s, c))\n",
        "\n",
        "# Функция генерации выхода\n",
        "def generate_output(s):\n",
        "    return softmax(np.dot(W_o, s) + b_o)\n",
        "\n",
        "# Механизм внимания и декодирование\n",
        "def decode(H, s_0, num_steps=2):\n",
        "    s = s_0\n",
        "    y_prev = 0  # Начальный вход декодера\n",
        "    attention_weights = []\n",
        "\n",
        "    for step in range(num_steps):\n",
        "        # 1. Вычисляем веса внимания\n",
        "        alpha = attention(s, H)\n",
        "        attention_weights.append(alpha)\n",
        "\n",
        "        # 2. Вычисляем контекстный вектор\n",
        "        c = np.sum(alpha[:, np.newaxis] * H, axis=0)\n",
        "\n",
        "        # 3. Обновляем состояние декодера\n",
        "        s = update_decoder_state(s, y_prev, c)\n",
        "\n",
        "        # 4. Генерируем выход\n",
        "        output = generate_output(s)\n",
        "        y_prev = np.argmax(output)\n",
        "\n",
        "        print(f\"Step {step + 1}:\")\n",
        "        print(f\"Attention Weights: {alpha}\")\n",
        "        print(f\"Context Vector: {c}\")\n",
        "        print(f\"Decoder State: {s}\")\n",
        "        print(f\"Generated Output: {y_prev}\")\n",
        "        print(\"\\n\")\n",
        "\n",
        "    return attention_weights\n",
        "\n",
        "# Запускаем декодирование\n",
        "attention_weights = decode(H, s_0)\n",
        "\n",
        "# Визуализация весов внимания\n",
        "def plot_attention(attention_weights):\n",
        "    fig, ax = plt.subplots(1, len(attention_weights), figsize=(10, 5))\n",
        "\n",
        "    for i, weights in enumerate(attention_weights):\n",
        "        sns.heatmap(weights[np.newaxis, :], cmap='Blues', cbar=False, ax=ax[i])\n",
        "        ax[i].set_title(f\"Step {i + 1}\")\n",
        "        ax[i].set_xlabel(\"Input Sequence\")\n",
        "        ax[i].set_xticks([0.5, 1.5, 2.5])\n",
        "        ax[i].set_xticklabels([\"h1\", \"h2\", \"h3\"])\n",
        "        ax[i].set_yticks([])\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Визуализируем\n",
        "plot_attention(attention_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Заключение\n",
        "\n",
        "Модель внимания Bahdanau представляет собой мощное расширение для стандартных моделей на основе RNN, предоставляя гибкий механизм для работы с длинными последовательностями и улучшая качество генерации последовательностей.\n",
        "\n",
        "\n",
        "\n",
        "### Вопросы для самопроверки\n",
        "\n",
        "1. В чем заключается основная идея механизма внимания в нейронных сетях?\n",
        "2. Какие задачи решает модель Bahdanau и какие её ключевые особенности?\n",
        "3. Какое назначение у контекстного вектора в модели внимания?\n",
        "4. Какие параметры используются в вычислении внимания и как они влияют на результат?\n",
        "5. Какое уравнение используется для вычисления весов внимания в модели Bahdanau?\n",
        "6. Как работает softmax и почему он используется для нормализации весов внимания?\n",
        "7. Как происходит обновление состояния декодера в модели с механизмом внимания?\n",
        "8. В чем разница между моделью Bahdanau и базовыми рекуррентными нейронными сетями (RNN)?\n",
        "9. Каково назначение матриц $W_a$, $U_a$ и вектора $v_a$ в механизме внимания?\n",
        "10. Как используется начальное состояние декодера в вычислении внимания?\n",
        "11. Чем модель Bahdanau отличается от модели Luong в части механизма внимания?\n",
        "12. Как контекстный вектор помогает декодеру делать прогнозы на выходе?\n",
        "13. Почему модель Bahdanau считается улучшенной версией seq2seq-моделей?\n",
        "14. Какое влияние оказывают параметры $W_s$, $U_s$ и $V_s$ на процесс декодирования?\n",
        "15. Как можно визуализировать работу механизма внимания? Какую информацию можно получить из тепловых карт (heatmaps)?\n",
        "\n",
        "\n",
        "### Задачи для самостоятельной работы\n",
        "\n",
        "1. Дана входная последовательность из 4 векторов и скрытые состояния кодировщика. Вычислите веса внимания для каждого вектора при начальном состоянии декодера.\n",
        "2. Найдите контекстный вектор для следующего состояния декодера при условии, что известно распределение весов внимания и скрытые состояния кодировщика.\n",
        "3. Определите следующее состояние декодера $s_1$ для модели Bahdanau, если заданы начальное состояние, предыдущий выход и контекстный вектор.\n",
        "4. Постройте softmax-распределение для весов внимания, если даны значения $e_1 = 0.3$, $e_2 = 0.7$, $e_3 = 1.0$.\n",
        "5. Дана матрица $W_a$ и вектор состояния декодера $s_0$. Вычислите значение активации внимания $e_{11}$ для первого скрытого состояния кодировщика.\n",
        "6. Рассчитайте веса внимания для модели, если скрытые состояния кодировщика заданы в виде $H = \\{[0.2, 0.4], [0.5, 0.6], [0.7, 0.1]\\}$, а начальное состояние декодера равно нулевому вектору.\n",
        "7. Изучите, как изменятся веса внимания при изменении матрицы $W_a$, и постройте соответствующую таблицу для нескольких значений.\n",
        "8. Рассчитайте контекстный вектор $c_2$ на втором шаге декодирования для последовательности из 3 скрытых состояний.\n",
        "9. Постройте последовательную визуализацию изменения весов внимания для последовательности из 5 скрытых состояний на 4 шагах декодирования.\n",
        "10. Определите выход декодера $y_1$, если известно состояние $s_1$ и параметры $W_o$, $b_o$.\n",
        "11. Найдите контекстный вектор для модели внимания, если веса внимания $\\alpha = [0.1, 0.3, 0.6]$, а скрытые состояния заданы в виде $H = \\{[1.0, 0.5], [0.4, 0.3], [0.2, 0.8]\\}$.\n",
        "12. Как изменится контекстный вектор, если все веса внимания одинаковы? Рассчитайте для последовательности из 3 скрытых состояний.\n",
        "13. Примените softmax-функцию к распределению из отрицательных значений: $e_1 = -0.5$, $e_2 = -0.1$, $e_3 = -1.0$. Постройте график.\n",
        "14. Решите задачу декодирования для последовательности длиной 5, сгенерировав выходные токены и промежуточные состояния декодера.\n",
        "15. Рассчитайте новое состояние декодера $s_2$, если задано состояние $s_1$, выход $y_1 = 0$ и контекстный вектор $c_1 = [0.2, 0.3]$.\n",
        "16. Визуализируйте динамику весов внимания при декодировании последовательности из 3 скрытых состояний в течение 4 шагов.\n",
        "17. Определите, как изменится распределение softmax, если одно из значений активации внимания сильно увеличится. Рассчитайте для $e = [0.1, 2.0, 0.5]$.\n",
        "18. Рассчитайте первое состояние декодера, если начальное состояние $s_0 = [0, 0]$, матрица $W_s = \\{[0.2, 0.1], [0.3, 0.4]\\}$, контекстный вектор $c_1 = [0.3, 0.2]$.\n",
        "19. Постройте график зависимости контекстного вектора от изменения весов внимания для последовательности длиной 3.\n",
        "20. Рассчитайте веса внимания на втором шаге декодирования, если состояние декодера $s_1 = [0.1, 0.2]$ и скрытые состояния кодировщика даны в виде $H = \\{[0.5, 0.1], [0.2, 0.3], [0.1, 0.4]\\}$.\n",
        "21. Сравните динамику изменения весов внимания в модели Bahdanau и модели Luong на одном и том же наборе данных.\n",
        "22. Проведите эксперимент: зафиксируйте одно скрытое состояние кодировщика и изменяйте начальное состояние декодера $s_0$. Как изменятся веса внимания?\n",
        "23. Постройте график зависимости состояния декодера от контекстного вектора для трёх различных шагов декодирования.\n",
        "24. Определите изменение весов внимания при изменении параметров матрицы $U_a$. Рассчитайте для последовательности длиной 4.\n",
        "25. Рассчитайте вес внимания $e_{13}$, если состояние декодера $s_0 = [0.1, 0.2]$, скрытое состояние $h_3 = [0.3, 0.8]$, матрицы $W_a$ и $U_a$ заданы.\n",
        "26. Решите задачу декодирования для последовательности длиной 6: найдите выходные токены и визуализируйте распределение весов внимания на каждом шаге.\n",
        "27. Рассчитайте контекстный вектор на третьем шаге декодирования, если задано распределение весов внимания и скрытые состояния.\n",
        "28. Примените механизм внимания для двух различных начальных состояний декодера и сравните результаты по контекстным векторам.\n",
        "29. Найдите веса внимания, если известно состояние декодера и скрытые состояния заданы как $h_1 = [0.3, 0.7]$, $h_2 = [0.2, 0.1]$, $h_3 = [0.5, 0.9]$.\n",
        "30. Проанализируйте, как изменится выход декодера при увеличении значений активации внимания. Рассчитайте для нескольких примеров.\n",
        "\n"
      ],
      "metadata": {
        "id": "jRIRamMAaAr0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Модели Luong\n",
        "\n",
        "Модели Luong (Luong Attention) — это один из методов, используемых в области обработки естественного языка, в частности, в задачах машинного перевода и других задачах, связанных с последовательными данными. Модель Luong, предложенная Minh-Thang Luong и его коллегами, является одним из подходов к механизму внимания (attention mechanism) в рекуррентных нейронных сетях (RNN). В данной лекции мы подробно рассмотрим эту модель, её математическое описание и ключевые формулы.\n",
        "\n",
        "## 1. Введение в механизм внимания\n",
        "\n",
        "Перед тем как перейти к моделям Luong, важно понимать, что такое механизм внимания. Механизм внимания позволяет модели сосредоточиться на определённых частях входной последовательности при генерации каждой части выходной последовательности.\n",
        "\n",
        "### 1.1. Основные компоненты\n",
        "\n",
        "- **Входная последовательность** $X = (x_1, x_2, \\ldots, x_T)$ длиной $T$.\n",
        "- **Выходная последовательность** $Y = (y_1, y_2, \\ldots, y_S)$ длиной $S$.\n",
        "- **Скрытые состояния** RNN на каждом шаге $t$: $h_t$.\n",
        "\n",
        "### 1.2. Задача внимания\n",
        "\n",
        "Задача механизма внимания состоит в том, чтобы вычислить контекстный вектор $c_t$ на каждом шаге генерации $y_t$. Этот вектор содержит информацию о значимости различных входных элементов при формировании текущего выхода $y_t$.\n",
        "\n",
        "## 2. Модели Luong\n",
        "\n",
        "Модели Luong представляют собой разновидность механизмов внимания, которые можно разделить на несколько типов: \"dot-product\" (скалярное произведение), \"general\" (общее) и \"concat\" (конкатенация). Рассмотрим каждую из этих моделей.\n",
        "\n",
        "### 2.1. Скалярное произведение (Dot-product Attention)\n",
        "\n",
        "В этой модели контекстный вектор вычисляется на основе скалярного произведения скрытого состояния декодера и скрытых состояний энкодера.\n",
        "\n",
        "#### 2.1.1. Формулы\n",
        "\n",
        "1. **Вычисление весов внимания**:\n",
        "\n",
        "$$\n",
        "e_{tj} = \\text{score}(h_t, \\overline{h}_j) = h_t^T \\overline{h}_j\n",
        "$$\n",
        "\n",
        "где:\n",
        "- $e_{tj}$ — это энергия внимания для текущего выхода $t$ и входа $j$,\n",
        "- $h_t$ — скрытое состояние декодера на шаге $t$,\n",
        "- $\\overline{h}_j$ — скрытое состояние энкодера на шаге $j$.\n",
        "\n",
        "2. **Нормализация весов**:\n",
        "\n",
        "$$\n",
        "\\alpha_{tj} = \\frac{\\exp(e_{tj})}{\\sum_{k=1}^{T} \\exp(e_{tk})}\n",
        "$$\n",
        "\n",
        "где:\n",
        "- $\\alpha_{tj}$ — вес внимания для входа $j$ на шаге $t$.\n",
        "\n",
        "3. **Вычисление контекстного вектора**:\n",
        "\n",
        "$$\n",
        "c_t = \\sum_{j=1}^{T} \\alpha_{tj} \\overline{h}_j\n",
        "$$\n",
        "\n",
        "где $c_t$ — контекстный вектор на шаге $t$.\n",
        "\n",
        "### 2.2. Общее внимание (General Attention)\n",
        "\n",
        "В модели общего внимания используется матрица весов $W_a$ для преобразования скрытых состояний перед вычислением скалярного произведения.\n",
        "\n",
        "#### 2.2.1. Формулы\n",
        "\n",
        "1. **Преобразование скрытых состояний**:\n",
        "\n",
        "$$\n",
        "\\tilde{h}_j = W_a \\overline{h}_j\n",
        "$$\n",
        "\n",
        "где $W_a$ — матрица весов.\n",
        "\n",
        "2. **Вычисление весов внимания**:\n",
        "\n",
        "$$\n",
        "e_{tj} = \\text{score}(h_t, \\tilde{h}_j) = h_t^T \\tilde{h}_j\n",
        "$$\n",
        "\n",
        "3. **Нормализация весов и контекстный вектор** остаются аналогичными.\n",
        "\n",
        "### 2.3. Конкатенация (Concat Attention)\n",
        "\n",
        "В модели конкатенации скрытое состояние декодера и скрытое состояние энкодера объединяются (конкатенируются) перед вычислением скалярного произведения.\n",
        "\n",
        "#### 2.3.1. Формулы\n",
        "\n",
        "1. **Конкатенация**:\n",
        "\n",
        "$$\n",
        "\\tilde{h}_{tj} = [h_t; \\overline{h}_j]\n",
        "$$\n",
        "\n",
        "где $[\\cdot; \\cdot]$ — операция конкатенации.\n",
        "\n",
        "2. **Вычисление весов внимания**:\n",
        "\n",
        "$$\n",
        "e_{tj} = \\text{score}(\\tilde{h}_{tj}) = v^T \\tanh(W_c \\tilde{h}_{tj})\n",
        "$$\n",
        "\n",
        "где:\n",
        "- $v$ — вектор весов,\n",
        "- $W_c$ — матрица весов.\n",
        "\n",
        "3. **Нормализация весов и контекстный вектор** остаются аналогичными.\n",
        "\n",
        "## 3. Выход на основе контекста\n",
        "\n",
        "На основе вычисленного контекстного вектора $c_t$ и скрытого состояния декодера $h_t$ можно сформировать выходной вектор:\n",
        "\n",
        "$$\n",
        "y_t = \\text{softmax}(W_y [h_t; c_t])\n",
        "$$\n",
        "\n",
        "где:\n",
        "- $W_y$ — матрица весов для генерации выхода,\n",
        "- $y_t$ — предсказанный выход на шаге $t$.\n",
        "\n",
        "\n",
        "\n",
        "Давайте рассмотрим числовой пример для модели **Luong с механизмом внимания на основе скалярного произведения (dot-product attention)**. Мы пройдем по всем шагам, начиная с вычисления весов внимания и заканчивая генерацией выходного значения.\n",
        "\n",
        "## Условия задачи\n",
        "\n",
        "Предположим, что у нас есть:\n",
        "- Декодер и энкодер работают с векторами размерности 2.\n",
        "- Входная последовательность состоит из **трех элементов**: $X = (x_1, x_2, x_3)$.\n",
        "- Скрытые состояния энкодера на каждом шаге следующие:\n",
        "\n",
        "$$\n",
        "\\overline{h}_1 = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}, \\quad \\overline{h}_2 = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}, \\quad \\overline{h}_3 = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}\n",
        "$$\n",
        "\n",
        "- Скрытое состояние декодера на текущем шаге $t$ равно:\n",
        "\n",
        "$$\n",
        "h_t = \\begin{pmatrix} 1 \\\\ 0.5 \\end{pmatrix}\n",
        "$$\n",
        "\n",
        "## Шаг 1: Вычисление энергий внимания $e_{tj}$\n",
        "\n",
        "Механизм внимания на основе скалярного произведения вычисляет энергии внимания для каждого состояния энкодера по формуле:\n",
        "\n",
        "$$\n",
        "e_{tj} = h_t^T \\overline{h}_j\n",
        "$$\n",
        "\n",
        "Для каждого элемента $j$ вычисляем:\n",
        "\n",
        "1. $e_{t1} = h_t^T \\overline{h}_1 = \\begin{pmatrix} 1 & 0.5 \\end{pmatrix} \\cdot \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = 1$\n",
        "2. $e_{t2} = h_t^T \\overline{h}_2 = \\begin{pmatrix} 1 & 0.5 \\end{pmatrix} \\cdot \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} = 0.5$\n",
        "3. $e_{t3} = h_t^T \\overline{h}_3 = \\begin{pmatrix} 1 & 0.5 \\end{pmatrix} \\cdot \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = 1.5$\n",
        "\n",
        "Итак, энергии внимания:\n",
        "\n",
        "$$\n",
        "e_t = \\begin{pmatrix} 1, 0.5, 1.5 \\end{pmatrix}\n",
        "$$\n",
        "\n",
        "## Шаг 2: Нормализация энергий — вычисление весов внимания $\\alpha_{tj}$\n",
        "\n",
        "Используем softmax для нормализации весов:\n",
        "\n",
        "$$\n",
        "\\alpha_{tj} = \\frac{\\exp(e_{tj})}{\\sum_{k=1}^{T} \\exp(e_{tk})}\n",
        "$$\n",
        "\n",
        "1. Сначала вычисляем экспоненты энергий:\n",
        "\n",
        "$$\n",
        "\\exp(e_{t1}) = \\exp(1) \\approx 2.718, \\quad \\exp(e_{t2}) = \\exp(0.5) \\approx 1.649, \\quad \\exp(e_{t3}) = \\exp(1.5) \\approx 4.482\n",
        "$$\n",
        "\n",
        "2. Находим сумму экспонент:\n",
        "\n",
        "$$\n",
        "\\sum_{j=1}^{3} \\exp(e_{tj}) = 2.718 + 1.649 + 4.482 = 8.849\n",
        "$$\n",
        "\n",
        "3. Теперь можем вычислить нормализованные веса:\n",
        "\n",
        "$$\n",
        "\\alpha_{t1} = \\frac{2.718}{8.849} \\approx 0.307, \\quad \\alpha_{t2} = \\frac{1.649}{8.849} \\approx 0.186, \\quad \\alpha_{t3} = \\frac{4.482}{8.849} \\approx 0.507\n",
        "$$\n",
        "\n",
        "Итак, веса внимания:\n",
        "\n",
        "$$\n",
        "\\alpha_t = \\begin{pmatrix} 0.307, 0.186, 0.507 \\end{pmatrix}\n",
        "$$\n",
        "\n",
        "## Шаг 3: Вычисление контекстного вектора $c_t$\n",
        "\n",
        "Контекстный вектор вычисляется как взвешенная сумма скрытых состояний энкодера:\n",
        "\n",
        "$$\n",
        "c_t = \\sum_{j=1}^{T} \\alpha_{tj} \\overline{h}_j\n",
        "$$\n",
        "\n",
        "Рассчитаем каждую компоненту контекстного вектора:\n",
        "\n",
        "1. $\\alpha_{t1} \\overline{h}_1 = 0.307 \\cdot \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 0.307 \\\\ 0 \\end{pmatrix}$\n",
        "2. $\\alpha_{t2} \\overline{h}_2 = 0.186 \\cdot \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0.186 \\end{pmatrix}$\n",
        "3. $\\alpha_{t3} \\overline{h}_3 = 0.507 \\cdot \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 0.507 \\\\ 0.507 \\end{pmatrix}$\n",
        "\n",
        "Теперь складываем все компоненты:\n",
        "\n",
        "$$\n",
        "c_t = \\begin{pmatrix} 0.307 \\\\ 0 \\end{pmatrix} + \\begin{pmatrix} 0 \\\\ 0.186 \\end{pmatrix} + \\begin{pmatrix} 0.507 \\\\ 0.507 \\end{pmatrix} = \\begin{pmatrix} 0.814 \\\\ 0.693 \\end{pmatrix}\n",
        "$$\n",
        "\n",
        "Контекстный вектор $c_t$:\n",
        "\n",
        "$$\n",
        "c_t = \\begin{pmatrix} 0.814 \\\\ 0.693 \\end{pmatrix}\n",
        "$$\n",
        "\n",
        "## Шаг 4: Генерация выходного значения $y_t$\n",
        "\n",
        "На последнем этапе, выходное значение $y_t$ на шаге $t$ вычисляется на основе скрытого состояния декодера $h_t$ и контекстного вектора $c_t$. Выход формируется через полносвязный слой с последующей softmax-активацией:\n",
        "\n",
        "$$\n",
        "y_t = \\text{softmax}(W_y [h_t; c_t])\n",
        "$$\n",
        "\n",
        "Для простоты предположим, что $W_y$ — это просто единичная матрица (без дополнительного взвешивания), и вычислим результат:\n",
        "\n",
        "1. Конкатенируем векторы $h_t$ и $c_t$:\n",
        "\n",
        "$$\n",
        "[h_t; c_t] = \\begin{pmatrix} 1 \\\\ 0.5 \\\\ 0.814 \\\\ 0.693 \\end{pmatrix}\n",
        "$$\n",
        "\n",
        "2. Применяем softmax:\n",
        "\n",
        "$$\n",
        "y_t = \\text{softmax}\\left(\\begin{pmatrix} 1 \\\\ 0.5 \\\\ 0.814 \\\\ 0.693 \\end{pmatrix}\\right)\n",
        "$$\n",
        "\n",
        "Для вычисления softmax:\n",
        "\n",
        "1. Сначала вычисляем экспоненты каждого значения:\n",
        "\n",
        "$$\n",
        "\\exp(1) \\approx 2.718, \\quad \\exp(0.5) \\approx 1.649, \\quad \\exp(0.814) \\approx 2.257, \\quad \\exp(0.693) \\approx 2.0\n",
        "$$\n",
        "\n",
        "2. Сумма экспонент:\n",
        "\n",
        "$$\n",
        "\\sum = 2.718 + 1.649 + 2.257 + 2.0 = 8.624\n",
        "$$\n",
        "\n",
        "3. Вычисляем нормализованные значения:\n",
        "\n",
        "$$\n",
        "y_{t1} = \\frac{2.718}{8.624} \\approx 0.315, \\quad y_{t2} = \\frac{1.649}{8.624} \\approx 0.191, \\quad y_{t3} = \\frac{2.257}{8.624} \\approx 0.262, \\quad y_{t4} = \\frac{2.0}{8.624} \\approx 0.232\n",
        "$$\n",
        "\n",
        "Итак, выходное значение:\n",
        "\n",
        "$$\n",
        "y_t = \\begin{pmatrix} 0.315, 0.191, 0.262, 0.232 \\end{pmatrix}\n",
        "$$\n",
        "\n",
        "Таким образом, мы шаг за шагом прошли через все этапы механизма внимания в модели Luong на основе скалярного произведения. На каждом этапе были применены соответствующие математические операции: вычисление энергий внимания, нормализация весов, вычисление контекстного вектора и генерация выходного значения.\n",
        "\n"
      ],
      "metadata": {
        "id": "rB7fnSKjb6Oc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Входные данные\n",
        "hidden_encoder_states = np.array([\n",
        "    [1, 0],   # h_1\n",
        "    [0, 1],   # h_2\n",
        "    [1, 1]    # h_3\n",
        "])\n",
        "\n",
        "hidden_decoder_state = np.array([1, 0.5])  # h_t\n",
        "\n",
        "# Шаг 1: Вычисление энергий внимания (скалярное произведение)\n",
        "def compute_attention_scores(encoder_states, decoder_state):\n",
        "    scores = np.dot(encoder_states, decoder_state)\n",
        "    return scores\n",
        "\n",
        "# Шаг 2: Применение softmax для нормализации\n",
        "def softmax(x):\n",
        "    exp_x = np.exp(x - np.max(x))  # для численной стабильности\n",
        "    return exp_x / exp_x.sum(axis=0)\n",
        "\n",
        "# Шаг 3: Вычисление контекстного вектора\n",
        "def compute_context_vector(encoder_states, attention_weights):\n",
        "    context_vector = np.sum(encoder_states.T * attention_weights, axis=1)\n",
        "    return context_vector\n",
        "\n",
        "# Шаг 4: Генерация выходного значения (простое вычисление)\n",
        "def generate_output(decoder_state, context_vector):\n",
        "    concatenated = np.concatenate([decoder_state, context_vector])\n",
        "    output = softmax(concatenated)  # Применяем softmax для генерации вероятностей\n",
        "    return output\n",
        "\n",
        "# 1. Вычисляем энергии внимания\n",
        "attention_scores = compute_attention_scores(hidden_encoder_states, hidden_decoder_state)\n",
        "print(f\"Attention Scores (Energy): {attention_scores}\")\n",
        "\n",
        "# 2. Применяем softmax к энергиям внимания\n",
        "attention_weights = softmax(attention_scores)\n",
        "print(f\"Attention Weights (Normalized): {attention_weights}\")\n",
        "\n",
        "# 3. Вычисляем контекстный вектор\n",
        "context_vector = compute_context_vector(hidden_encoder_states, attention_weights)\n",
        "print(f\"Context Vector: {context_vector}\")\n",
        "\n",
        "# 4. Генерация выходного значения\n",
        "output = generate_output(hidden_decoder_state, context_vector)\n",
        "print(f\"Output (Softmax probabilities): {output}\")\n",
        "\n",
        "# Визуализация весов внимания\n",
        "def plot_attention(attention_weights):\n",
        "    fig, ax = plt.subplots()\n",
        "    sns.heatmap(attention_weights.reshape(1, -1), annot=True, cmap='Blues', cbar=False, ax=ax)\n",
        "    ax.set_xticklabels(['x1', 'x2', 'x3'])\n",
        "    ax.set_yticklabels([''])\n",
        "    ax.set_title(\"Attention Weights\")\n",
        "    plt.show()\n",
        "\n",
        "# Визуализируем\n",
        "plot_attention(attention_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "0gwYSkEjaA6T",
        "outputId": "cb14c4b1-30ce-4332-9479-e11376b71708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention Scores (Energy): [1.  0.5 1.5]\n",
            "Attention Weights (Normalized): [0.30719589 0.18632372 0.50648039]\n",
            "Context Vector: [0.81367628 0.69280411]\n",
            "Output (Softmax probabilities): [0.31525433 0.19121142 0.26166263 0.23187162]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 4. Заключение\n",
        "\n",
        "Модели Luong предоставляют эффективный способ использования механизма внимания для обработки последовательных данных в задачах машинного перевода и других областях. Основное преимущество данных моделей заключается в их способности адаптивно фокусироваться на наиболее значимых частях входной последовательности, что улучшает качество генерируемых выходов.\n",
        "\n",
        "С помощью предложенных формул и подходов можно значительно улучшить производительность нейронных сетей в задачах, связанных с последовательной обработкой данных.\n",
        "\n",
        "\n",
        "\n",
        "### Вопросы для самопроверки\n",
        "\n",
        "1. Что такое механизм внимания в контексте нейронных сетей и машинного перевода?\n",
        "2. Чем отличается механизм внимания Luong от классического внимания Bahdanau?\n",
        "3. Какие типы механизмов внимания описаны в модели Luong?\n",
        "4. Какое математическое выражение используется для вычисления энергии внимания в модели Luong на основе скалярного произведения (dot-product attention)?\n",
        "5. Как нормализуются энергии внимания в модели Luong?\n",
        "6. Что такое контекстный вектор, и как он вычисляется в модели внимания Luong?\n",
        "7. В чем разница между моделями Luong с \"general\" и \"dot-product\" механизмами внимания?\n",
        "8. Как вычисляется внимание в модели Luong с механизмом \"concat\" (конкатенации)?\n",
        "9. Какие параметры скрытых состояний энкодера и декодера участвуют в механизме внимания?\n",
        "10. Какое значение принимает функция softmax и почему она используется для нормализации весов внимания?\n",
        "11. Какие задачи решает механизм внимания в задачах перевода и генерации текста?\n",
        "12. Как связаны контекстный вектор и выход декодера при генерации итогового выхода?\n",
        "13. Какое значение имеет матрица $W_a$ в модели Luong с общим вниманием (general attention)?\n",
        "14. В каких случаях механизм внимания Luong может быть полезнее, чем традиционные RNN и LSTM без внимания?\n",
        "15. Какие ключевые шаги необходимо выполнить для построения модели внимания Luong?\n",
        "\n",
        "\n",
        "### Задачи для самостоятельной работы\n",
        "\n",
        "1. Даны скрытые состояния энкодера $\\overline{h}_1 = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}, \\overline{h}_2 = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}, \\overline{h}_3 = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$ и состояние декодера $h_t = \\begin{pmatrix} 0.5 \\\\ 0.5 \\end{pmatrix}$. Вычислите энергии внимания.\n",
        "   \n",
        "2. Нормализуйте энергии внимания из задачи 1, используя softmax.\n",
        "\n",
        "3. Для скрытых состояний энкодера $\\overline{h}_1 = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}, \\overline{h}_2 = \\begin{pmatrix} 3 \\\\ 4 \\end{pmatrix}$ и декодера $h_t = \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix}$, вычислите контекстный вектор, используя внимание на основе скалярного произведения.\n",
        "\n",
        "4. Реализуйте вычисление внимания по модели Luong с общим вниманием (general attention), где матрица $W_a = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix}$.\n",
        "\n",
        "5. Пусть скрытые состояния энкодера заданы как $\\overline{h}_1 = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}, \\overline{h}_2 = \\begin{pmatrix} 2 \\\\ 3 \\end{pmatrix}$, а состояние декодера как $h_t = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$. Используйте модель внимания на основе конкатенации (concat attention), чтобы вычислить вес внимания $e_{tj}$.\n",
        "\n",
        "6. Напишите функцию для вычисления контекстного вектора в модели Luong с использованием механизма внимания \"dot-product\" в Python.\n",
        "\n",
        "7. Даны скрытые состояния энкодера: $\\overline{h}_1 = [0.3, 0.6], \\overline{h}_2 = [0.1, 0.9], \\overline{h}_3 = [0.5, 0.5]$, а состояние декодера: $h_t = [0.4, 0.4]$. Рассчитайте контекстный вектор.\n",
        "\n",
        "8. Пусть декодер имеет скрытое состояние $h_t = \\begin{pmatrix} 1 \\\\ 0.5 \\end{pmatrix}$, а энкодер имеет состояния $\\overline{h}_1 = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$ и $\\overline{h}_2 = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$. Используйте внимание \"general attention\", где $W_a = \\begin{pmatrix} 2 & 0 \\\\ 0 & 1 \\end{pmatrix}$.\n",
        "\n",
        "9. Протестируйте механизм внимания Luong на выборке входных данных размерности 3x2 с различными весами внимания, используя softmax и визуализируя веса на графике.\n",
        "\n",
        "10. Реализуйте на Python программу для вычисления выхода $y_t$ на основе механизма внимания Luong, начиная с генерации скрытых состояний энкодера и декодера, вычисления энергий внимания и завершая вычислением выходного значения через softmax.\n",
        "\n",
        "11. Напишите программу, которая принимает на вход скрытые состояния энкодера и декодера, вычисляет веса внимания, контекстный вектор и возвращает визуализацию весов внимания в виде тепловой карты.\n",
        "\n",
        "12. Рассчитайте веса внимания для декодера с состоянием $h_t = [2, 1]$ и энкодера с состояниями $\\overline{h}_1 = [0, 1], \\overline{h}_2 = [1, 0]$, используя механизм внимания на основе скалярного произведения.\n",
        "\n",
        "13. Вычислите контекстный вектор для энкодера с состояниями $\\overline{h}_1 = \\begin{pmatrix} 0.2 \\\\ 0.8 \\end{pmatrix}, \\overline{h}_2 = \\begin{pmatrix} 0.9 \\\\ 0.1 \\end{pmatrix}$ и декодера $h_t = \\begin{pmatrix} 0.4 \\\\ 0.6 \\end{pmatrix}$ через механизм внимания \"dot-product\".\n",
        "\n",
        "14. Вычислите веса внимания и контекстный вектор для последовательности длины 4 и векторов размерности 3.\n",
        "\n",
        "15. Пусть в модели Luong используется общий механизм внимания с матрицей весов $W_a = \\begin{pmatrix} 1 & 0.5 \\\\ 0.5 & 1 \\end{pmatrix}$. Рассчитайте значения $e_{tj}$ для заданных состояний энкодера и декодера.\n",
        "\n",
        "16. Примените механизм внимания Luong к выборке последовательностей различной длины и сравните полученные контекстные векторы.\n",
        "\n",
        "17. Для векторов скрытых состояний энкодера и декодера задайте случайные значения и проведите эксперимент по вычислению весов внимания, используя разные виды механизмов внимания (dot-product, general, concat).\n",
        "\n",
        "18. Напишите функцию для генерации входных и выходных векторов, которая на каждом шаге будет вычислять контекстные векторы с помощью модели внимания Luong.\n",
        "\n",
        "19. Рассчитайте веса внимания для энкодера с 5 состояниями размерности 4 и декодера с состоянием размерности 4, используя механизм общего внимания.\n",
        "\n",
        "20. Пусть скрытые состояния декодера задаются как $h_1 = [0.1, 0.5], h_2 = [0.6, 0.7]$, а состояния энкодера $\\overline{h}_1 = [1, 0], \\overline{h}_2 = [0, 1], \\overline{h}_3 = [1, 1]$. Вычислите итоговые контекстные векторы.\n",
        "\n",
        "21. Для механизма внимания \"general attention\" реализуйте программу на Python, которая вычисляет веса внимания для входных векторов различной размерности.\n",
        "\n",
        "22. Постройте график, показывающий зависимость итогового контекстного вектора от изменения весов внимания.\n",
        "\n",
        "23. Реализуйте генерацию выходных значений для последовательностей длины 5, где каждый шаг основан на механизме внимания Luong.\n",
        "\n",
        "24. Задайте состояние декодера $h_t = [0.3, 0.7]$ и вычислите веса внимания и контекстный вектор для энкодера с состояниями $\\overline{h}_1 = [0.6, 0.2], \\overline{h}_2 = [0.4, 0.9]$.\n",
        "\n",
        "25. Используя модель внимания \"concat attention\", напишите программу для вычисления весов для случайных векторов длины 4.\n",
        "\n",
        "26. Протестируйте производительность механизма внимания для векторов скрытых состояний разной размерности, начиная от 2 и выше.\n",
        "\n",
        "27. Реализуйте алгоритм вычисления весов внимания для декодера и энкодера, который на каждом шаге будет выводить промежуточные результаты (энергии, веса и контекстный вектор).\n",
        "\n",
        "28. Для модели Luong реализуйте функцию, которая на основе входных последовательностей и заданных состояний декодера и энкодера вычисляет контекстный вектор и возвращает его.\n",
        "\n",
        "29. Напишите программу, которая сравнивает производительность различных механизмов внимания (dot-product, general, concat) на одной и той же выборке данных, визуализируя результаты.\n",
        "\n",
        "30. Реализуйте механизм внимания, который будет учитывать дополнительные параметры, такие как длина последовательности и размерность скрытых состояний, и протестируйте его на реальных данных."
      ],
      "metadata": {
        "id": "A9yyntQ3bydz"
      }
    }
  ]
}